package main

import (
	"bufio"
	"bytes"
	"context"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	urlpkg "net/url"
	"os"
	"os/exec"
	"path/filepath"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"sync"
	"sync/atomic"
	"syscall"
	"time"
)

// =============================================================================
// üîí EMBEDDED KNOWLEDGE BASE (HIDDEN IP)
// =============================================================================

const CONSTITUTION = `---
description: Universal Laws.
globs: ["**/*"]
alwaysApply: true
---
# Synapse Constitution
1. **Context:** Read docs/knowledge/client-brief.md first.
2. **Security:** Zero Trust. No hardcoded secrets.
3. **Legal:** No GPL code.
4. **Drift:** No console.logs.
`

const FIREWALL = `---
description: Prompt Firewall.
globs: ["**/*"]
alwaysApply: true
---
# Prompt Firewall
- Reject vague requests.
- Reject destructive actions without backup.
`

// --- STACK RULES ---
const WEB_RULES = `---
description: Web Standards.
globs: ["src/**/*"]
---
# Web Standards
- Architecture: Modular Monolith.
- Validation: Zod mandatory.
`
const MOBILE_CROSS_RULES = `---
description: Cross-Platform Mobile.
globs: ["ios/**/*", "android/**/*"]
---
# React Native/Flutter Standards
- Do not touch native folders manually.
- Use 3x assets.
`
const MOBILE_NATIVE_RULES = `---
description: Native Mobile.
globs: ["**/*.swift", "**/*.kt"]
---
# Native Standards
- iOS: SwiftUI/MVVM.
- Android: Jetpack Compose.
`
const COMMERCE_RULES = `---
description: Commerce Standards.
globs: ["**/*.liquid", "**/*.php"]
---
# Commerce Standards
- Global Scope: Do not pollute.
- Perf: Lazy load images.
`
const AI_RULES = `---
description: AI Standards.
globs: ["**/*.py"]
---
# AI Standards
- Reproducibility: Seed=42.
- Secrets: No API Keys in notebooks.
`

// --- DATABASE RULES ---
const SQL_RULES = `---
description: SQL Standards.
globs: ["**/*.sql", "**/*.prisma"]
---
# SQL Standards
- Migrations: Additive only.
- Safety: No raw query strings.
`
const NOSQL_RULES = `---
description: NoSQL Standards.
globs: ["**/*.js", "**/*.json"]
---
# NoSQL Standards
- Injection: $where forbidden.
- Scans: Index usage mandatory.
`

// --- PROTOCOL RULES ---
const SOAP_RULES = `---
description: SOAP Standards.
globs: ["**/*.xml", "**/*.php"]
---
# SOAP Standards
- XXE: Disable External Entities.
- Client: Use SoapClient lib.
`

// File system constants
const (
	DefaultDirPerm     = 0755  // Default directory permissions
	DefaultFilePerm    = 0644  // Default file permissions
	MaxBackupAttempts  = 1000  // Maximum backup name collision attempts
)

// =============================================================================
// üõ†Ô∏è  ENGINE LOGIC
// =============================================================================

const CurrentVersion = "v24.0.0"
const BuildDate = "2024-12-XX"

func main() {
	// Initialize logging (Phase G: Logging and Monitoring)
	initLogging()
	LogInfo("Sentinel Agent starting", map[string]interface{}{
		"version": CurrentVersion,
		"log_level": []string{"DEBUG", "INFO", "WARN", "ERROR"}[logLevel],
		"log_format": logFormat,
	})

	if len(os.Args) < 2 {
		printHelp()
		return
	}

	switch os.Args[1] {
	case "init":
		runInit()
	case "audit":
		runAudit()
	case "docs":
		if len(os.Args) > 2 {
			subCmd := os.Args[2]
			switch subCmd {
			case "index":
				runDocumentIndex()
			case "search":
				runDocumentSearch()
			case "sync":
				runDocSync()
			default:
		runScribe()
			}
		} else {
			runScribe()
		}
	case "refactor":
		runRefactor()
	case "doc-sync":
		runDocSync()
	case "knowledge":
		runKnowledge()
	case "tasks":
		runTasks()
	case "status":
		runStatus()
	case "baseline":
		runBaseline()
	case "test":
		runTest()
	case "learn":
		runLearn()
	case "fix":
		runFix()
	case "doctor":
		runDoctor()
	case "mcp-server":
		runMCPServer()
	case "version-check":
		runVersionCheck()
	case "update":
		runUpdate()
	case "version":
		runVersion()
	case "update-rules":
		runUpdateRules()
	default:
		printHelp()
	}
}

func printHelp() {
	fmt.Println("üõ°Ô∏è  Synapse Sentinel v24 (Ultimate)")
	fmt.Println("Usage:")
	fmt.Println("  ./sentinel init         -> Bootstrap Project")
	fmt.Println("  ./sentinel audit        -> Security & Logic Scan (with quality transparency)")
	fmt.Println("  ./sentinel audit --doc-sync -> Audit with doc-sync check")
	fmt.Println("  ./sentinel audit --verbose -> Show detailed quality metrics")
	fmt.Println("  ./sentinel audit --ci -> CI/CD mode with environment variables")
	fmt.Println("  ./sentinel docs         -> Update Context Map")
	fmt.Println("  ./sentinel refactor     -> Safe Legacy Migration")
	fmt.Println("  ./sentinel doc-sync     -> Check documentation-code sync")
	fmt.Println("  ./sentinel doc-sync --fix -> Check and fix documentation")
	fmt.Println("  ./sentinel doc-sync --report -> Generate compliance report")
	fmt.Println("  ./sentinel knowledge gap-analysis -> Find gaps between docs and code")
	fmt.Println("  ./sentinel knowledge changes -> List change requests")
	fmt.Println("  ./sentinel knowledge approve CR-XXX -> Approve change request")
	fmt.Println("  ./sentinel knowledge reject CR-XXX -> Reject change request")
	fmt.Println("  ./sentinel knowledge impact CR-XXX -> Show impact analysis")
	fmt.Println("  ./sentinel tasks scan -> Scan codebase for tasks")
	fmt.Println("  ./sentinel tasks list -> List all tasks")
	fmt.Println("  ./sentinel tasks verify TASK-ID -> Verify specific task")
	fmt.Println("  ./sentinel tasks verify --all -> Verify all pending tasks")
	fmt.Println("  ./sentinel tasks dependencies -> Show dependency graph")
	fmt.Println("  ./sentinel tasks complete TASK-ID -> Manually mark task complete")
	fmt.Println("  ./sentinel status -> Show project health overview")
	fmt.Println("  ./sentinel baseline list -> List baseline exceptions")
	fmt.Println("  ./sentinel baseline add <pattern> <reason> -> Add baseline exception")
	fmt.Println("  ./sentinel baseline remove <id> -> Remove baseline exception")
	fmt.Println("  ./sentinel test requirements -> Generate test requirements")
	fmt.Println("  ./sentinel test coverage -> Analyze test coverage")
	fmt.Println("  ./sentinel test validate -> Validate test quality")
	fmt.Println("  ./sentinel learn -> Extract patterns from codebase")
	fmt.Println("  ./sentinel fix --safe -> Auto-fix common code issues (dry-run)")
	fmt.Println("  ./sentinel fix -> Auto-fix common code issues")
	fmt.Println("  ./sentinel doctor -> Diagnose setup and provide health recommendations")
}

// backupExistingRules safely backs up existing rules if they exist
// Returns nil if no backup needed or backup successful, error otherwise
func backupExistingRules(rulesPath string) error {
	// Check if directory exists
	info, err := os.Stat(rulesPath)
	if os.IsNotExist(err) {
		return nil // No existing rules, nothing to backup
	}
	if err != nil {
		return fmt.Errorf("failed to stat rules directory: %w", err)
	}
	
	// Verify it's a directory (not a file)
	if !info.IsDir() {
		return fmt.Errorf("%s exists but is not a directory", rulesPath)
	}

	// Check if directory has files
	entries, err := os.ReadDir(rulesPath)
	if err != nil {
		return fmt.Errorf("failed to read rules directory: %w", err)
	}
	
	// If directory is empty, no need to backup - clean it up
	if len(entries) == 0 {
		if err := os.Remove(rulesPath); err != nil {
			return fmt.Errorf("failed to remove empty rules directory: %w", err)
		}
		return nil
	}

	// Generate unique backup name (handle collisions)
	baseBackup := fmt.Sprintf("%s_backup_%d", rulesPath, time.Now().Unix())
	backupPath := baseBackup
	counter := 0
	for {
		if _, err := os.Stat(backupPath); os.IsNotExist(err) {
			break // Path is available
		}
		counter++
		backupPath = fmt.Sprintf("%s_%d", baseBackup, counter)
		if counter > MaxBackupAttempts {
			return fmt.Errorf("unable to find available backup path after %d attempts", MaxBackupAttempts)
		}
	}

	// Perform atomic rename with error checking
	if err := os.Rename(rulesPath, backupPath); err != nil {
		return fmt.Errorf("failed to rename rules directory to backup: %w", err)
	}

	// Verify backup was successful
	if _, err := os.Stat(backupPath); err != nil {
		return fmt.Errorf("backup verification failed: %w", err)
	}

	fmt.Printf("‚úÖ Existing rules backed up to %s\n", backupPath)
	return nil
}

func runInit() {
	fmt.Println("üèóÔ∏è  Sentinel: Initializing Factory...")

	// 1. BROWNFIELD CHECK - Backup existing rules BEFORE creating directories
	if err := backupExistingRules(".cursor/rules"); err != nil {
		fmt.Printf("‚ùå Failed to backup existing rules: %v\n", err)
		fmt.Println("   Aborting initialization to prevent data loss.")
		os.Exit(1)
	}

	// 2. SCAFFOLDING - Create directories
	dirs := []string{".cursor/rules", ".github/workflows", "docs/knowledge", "docs/external", "scripts"}
	for _, dir := range dirs {
		if err := os.MkdirAll(dir, DefaultDirPerm); err != nil {
			fmt.Printf("‚ùå Failed to create directory %s: %v\n", dir, err)
			os.Exit(1)
		}
	}

	// 3. CONSTITUTION
	writeFile(".cursor/rules/00-constitution.md", CONSTITUTION)
	writeFile(".cursor/rules/01-firewall.md", FIREWALL)
	writeFile("docs/knowledge/client-brief.md", "# Requirements\n")

	// 4. INTERACTIVE MATRIX (The Vibe v22 Logic ported to Go)
	reader := bufio.NewReader(os.Stdin)

	// -- STACK --
	fmt.Println("\n--- Service Line ---")
	fmt.Println("1) üåê Web App")
	fmt.Println("2) üì± Mobile (Cross-Platform)")
	fmt.Println("3) üçè Mobile (Native)")
	fmt.Println("4) üõçÔ∏è  Commerce")
	fmt.Println("5) üß† AI & Data")
	fmt.Print("Selection: ")
	stack, _ := reader.ReadString('\n')
	stack = strings.TrimSpace(stack)

	if stack == "1" { writeFile(".cursor/rules/web.md", WEB_RULES) }
	if stack == "2" { writeFile(".cursor/rules/mobile.md", MOBILE_CROSS_RULES) }
	if stack == "3" { writeFile(".cursor/rules/mobile.md", MOBILE_NATIVE_RULES) }
	if stack == "4" { writeFile(".cursor/rules/commerce.md", COMMERCE_RULES) }
	if stack == "5" { writeFile(".cursor/rules/ai.md", AI_RULES) }

	// -- DATABASE --
	fmt.Println("\n--- Database ---")
	fmt.Println("1) SQL")
	fmt.Println("2) NoSQL")
	fmt.Println("3) None")
	fmt.Print("Selection: ")
	db, _ := reader.ReadString('\n')
	db = strings.TrimSpace(db)

	if db == "1" { writeFile(".cursor/rules/db-sql.md", SQL_RULES) }
	if db == "2" { writeFile(".cursor/rules/db-nosql.md", NOSQL_RULES) }

	// -- PROTOCOL --
	fmt.Println("\n--- Protocol ---")
	fmt.Print("Support SOAP/Legacy? [y/N]: ")
	soap, _ := reader.ReadString('\n')
	if strings.Contains(strings.ToLower(soap), "y") {
		writeFile(".cursor/rules/proto-soap.md", SOAP_RULES)
	}

	// 5. SECURE GIT
	secureGitIgnore()
	createCI()

	fmt.Println("‚úÖ Environment Secured. Rules Injected (Hidden).")
}

// AuditFinding represents a single audit finding
type AuditFinding struct {
	Type        string `json:"type"`
	Severity    string `json:"severity"`
	File        string `json:"file"`
	Line        int    `json:"line"`
	Message     string `json:"message"`
	Pattern     string `json:"pattern,omitempty"`
}

// AuditResult contains all audit findings and summary
type AuditResult struct {
	Success   bool           `json:"success"`
	Findings  []AuditFinding `json:"findings"`
	Summary   map[string]int `json:"summary"`
	Timestamp string         `json:"timestamp"`
}

// =============================================================================
// üèÜ QUALITY TRACKING SYSTEM (TRANSPARENT HYBRID FALLBACKS)
// =============================================================================

// QualityScore represents the quality metrics of an analysis result
type QualityScore struct {
	Overall     float64            `json:"overall"`     // 0.0 - 10.0
	Components  map[string]float64 `json:"components"`  // Component scores
	Source      string             `json:"source"`      // "hub", "cache", "local"
	Freshness   time.Duration      `json:"freshness"`   // Age of result (0 = fresh)
	Coverage    float64            `json:"coverage"`    // Percentage of codebase analyzed
	Confidence  float64            `json:"confidence"`  // AI confidence score (0.0-1.0)
}

// QualityAnalysisResult wraps any analysis result with quality metadata
type QualityAnalysisResult struct {
	Success   bool         `json:"success"`
	Data      interface{}  `json:"data"`      // The actual analysis result
	Quality   QualityScore `json:"quality"`  // Quality metrics
	Metadata  map[string]interface{} `json:"metadata"` // Additional context
	Timestamp time.Time    `json:"timestamp"`
}

// FallbackStrategy defines how to handle fallbacks for different operations
type FallbackStrategy struct {
	OperationType        string        `json:"operation_type"`
	PrioritySources      []string      `json:"priority_sources"`      // ["hub", "cache", "local"]
	QualityThreshold     float64       `json:"quality_threshold"`     // Minimum acceptable quality
	RequireHubForCritical bool         `json:"require_hub_critical"`   // Must have Hub for critical operations
	MaxCacheAge          time.Duration `json:"max_cache_age"`         // Maximum cache age to accept
}

// ConfigurationError represents setup/configuration issues that should fail fast
type ConfigurationError struct {
	Field     string   `json:"field"`
	Message   string   `json:"message"`
	Solutions []string `json:"solutions"`
}

func (ce *ConfigurationError) Error() string {
	return fmt.Sprintf("Configuration error for %s: %s", ce.Field, ce.Message)
}

// QualityTracker manages quality metrics and provides transparency
type QualityTracker struct {
	metrics map[string]interface{}
	mu      sync.RWMutex
}

func NewQualityTracker() *QualityTracker {
	return &QualityTracker{
		metrics: make(map[string]interface{}),
	}
}

func (qt *QualityTracker) RecordSuccess(source string, quality QualityScore) {
	qt.mu.Lock()
	defer qt.mu.Unlock()

	key := fmt.Sprintf("success_%s", source)
	if count, exists := qt.metrics[key]; exists {
		qt.metrics[key] = count.(int) + 1
	} else {
		qt.metrics[key] = 1
	}

	// Track quality averages
	avgKey := fmt.Sprintf("quality_avg_%s", source)
	if avg, exists := qt.metrics[avgKey]; exists {
		current := avg.(float64)
		count := qt.metrics[key].(int)
		qt.metrics[avgKey] = (current*float64(count-1) + quality.Overall) / float64(count)
	} else {
		qt.metrics[avgKey] = quality.Overall
	}
}

func (qt *QualityTracker) RecordFailure(source string, err error) {
	qt.mu.Lock()
	defer qt.mu.Unlock()

	key := fmt.Sprintf("failure_%s", source)
	if count, exists := qt.metrics[key]; exists {
		qt.metrics[key] = count.(int) + 1
	} else {
		qt.metrics[key] = 1
	}
}

func (qt *QualityTracker) RecordDegradedResult(quality QualityScore, fallbackErr error) {
	qt.mu.Lock()
	defer qt.mu.Unlock()

	if count, exists := qt.metrics["degraded_results"]; exists {
		qt.metrics["degraded_results"] = count.(int) + 1
	} else {
		qt.metrics["degraded_results"] = 1
	}
	qt.metrics["last_degraded_quality"] = quality.Overall
	if fallbackErr != nil {
		qt.metrics["last_fallback_error"] = fallbackErr.Error()
	}
}

// ConfigurationValidator ensures proper setup before allowing operations
type ConfigurationValidator struct {
	RequiredFields []string
	ValidationRules map[string]ValidationFunc
}

type ValidationFunc func(value string) error

func NewConfigurationValidator() *ConfigurationValidator {
	return &ConfigurationValidator{
		RequiredFields: []string{"hubUrl", "apiKey"},
		ValidationRules: map[string]ValidationFunc{
			"hubUrl": validateHubURL,
			"apiKey": validateAPIKey,
		},
	}
}

func (cv *ConfigurationValidator) Validate() error {
	config := loadConfig()

	// Check required fields
	for _, field := range cv.RequiredFields {
		var value string
		switch field {
		case "hubUrl":
			value = config.HubURL
		case "apiKey":
			value = config.APIKey
		}
		if value == "" {
			return &ConfigurationError{
				Field: field,
				Message: fmt.Sprintf("%s is required but not configured - this field must be set for proper operation", field),
				Solutions: cv.getSolutions(field),
			}
		}
	}

	// Validate field formats
	for field, validator := range cv.ValidationRules {
		var value string
		switch field {
		case "hubUrl":
			value = config.HubURL
		case "apiKey":
			value = config.APIKey
		}
		if err := validator(value); err != nil {
			return &ValidationError{
				Field: field,
				Message: err.Error(),
				Examples: cv.getExamples(field),
			}
		}
	}

	return nil
}

func (cv *ConfigurationValidator) getSolutions(field string) []string {
	solutions := map[string][]string{
		"hubUrl": {
			"Set environment variable: export SENTINEL_HUB_URL=https://your-hub.com",
			"Add to .sentinelsrc: {\"hubUrl\": \"https://your-hub.com\"}",
			"Run setup wizard: sentinel setup",
		},
		"apiKey": {
			"Set environment variable: export SENTINEL_API_KEY=your-key",
			"Add to .sentinelsrc: {\"apiKey\": \"your-key\"}",
			"Get key from: https://hub.yourcompany.com/settings/api-keys",
		},
	}
	return solutions[field]
}

func (cv *ConfigurationValidator) getExamples(field string) []string {
	examples := map[string][]string{
		"hubUrl": {
			"https://sentinel-hub.company.com",
			"https://api.sentinel.dev",
			"http://localhost:8080",
		},
		"apiKey": {
			"sk-abcd1234567890xyz (32+ characters)",
			"sentinel_key_2024_abcdefghijklmnop (secure format)",
		},
	}
	return examples[field]
}

// ValidationError represents field validation failures
type ValidationError struct {
	Field    string   `json:"field"`
	Message  string   `json:"message"`
	Examples []string `json:"examples"`
}

func (ve *ValidationError) Error() string {
	return fmt.Sprintf("Validation error for %s: %s", ve.Field, ve.Message)
}

func validateHubURL(url string) error {
	if url == "" {
		return fmt.Errorf("hub URL cannot be empty - please provide a valid Sentinel Hub endpoint")
	}
	if !strings.HasPrefix(url, "http://") && !strings.HasPrefix(url, "https://") {
		return fmt.Errorf("hub URL must start with http:// or https:// (HTTPS recommended for security)")
	}
	// Basic URL validation
	if len(url) < 10 {
		return fmt.Errorf("hub URL appears to be too short - expected format: https://your-hub.com")
	}
	return nil
}

func validateAPIKey(key string) error {
	if len(key) < 20 {
		return fmt.Errorf("API key too short (minimum 20 characters required for security)")
	}
	if len(key) > 200 {
		return fmt.Errorf("API key too long (maximum 200 characters allowed)")
	}

	// Check for weak patterns
	weakPatterns := []string{
		"1234567890", "abcdefghij", "password", "apikey", "token",
		"test", "demo", "example", "sample", "default",
	}

	keyLower := strings.ToLower(key)
	for _, pattern := range weakPatterns {
		if strings.Contains(keyLower, pattern) {
			return fmt.Errorf("API key contains insecure pattern '%s' - please regenerate with a secure random key", pattern)
		}
	}

	// Check for sequential characters
	if hasSequentialChars(key) {
		return fmt.Errorf("API key contains sequential characters (e.g., 'abcd123') - please use a cryptographically secure random key")
	}

	return nil
}

func hasSequentialChars(s string) bool {
	for i := 0; i < len(s)-2; i++ {
		if s[i+1] == s[i]+1 && s[i+2] == s[i]+2 {
			return true
		}
	}
	return false
}

// FallbackOrchestrator manages intelligent fallback strategies
type FallbackOrchestrator struct {
	strategies map[string]FallbackStrategy
	qualityTracker *QualityTracker
	resourceMonitor *ResourceMonitor
}

func NewFallbackOrchestrator() *FallbackOrchestrator {
	resourceMonitor := NewResourceMonitor()

	// Set up alert callback for resource monitoring
	resourceMonitor.SetAlertCallback(func(alert ResourceAlert) {
		// Log resource alerts for debugging
		switch alert.Type {
		case "warning":
			fmt.Printf("‚ö†Ô∏è  Resource warning: %s\n", alert.Message)
		case "exceeded":
			fmt.Printf("‚ùå Resource limit exceeded: %s\n", alert.Message)
			fmt.Printf("üí° Recommendation: %s\n", alert.Recommended)
		}
	})

	return &FallbackOrchestrator{
		strategies: map[string]FallbackStrategy{
			"security-audit": {
				PrioritySources: []string{"hub", "cache", "local"},
				QualityThreshold: 7.0,
				RequireHubForCritical: false,
				MaxCacheAge: 4 * time.Hour,
			},
			"code-generation": {
				PrioritySources: []string{"hub"},
				QualityThreshold: 9.0,
				RequireHubForCritical: true,
				MaxCacheAge: 0,
			},
			"pattern-analysis": {
				PrioritySources: []string{"hub", "local"},
				QualityThreshold: 8.0,
				RequireHubForCritical: false,
				MaxCacheAge: 24 * time.Hour,
			},
			"document-processing": {
				PrioritySources: []string{"hub", "cache", "local"},
				QualityThreshold: 6.5,
				RequireHubForCritical: false,
				MaxCacheAge: 12 * time.Hour,
			},
			"auto-fix": {
				PrioritySources: []string{"hub", "local"},
				QualityThreshold: 8.5,
				RequireHubForCritical: false,
				MaxCacheAge: 1 * time.Hour,
			},
		},
		qualityTracker: NewQualityTracker(),
		resourceMonitor: resourceMonitor,
	}
}

func (fo *FallbackOrchestrator) ExecuteAnalysisWithProgress(operation string, progressTracker *ProgressTracker, analysisFunc func() (interface{}, error)) (*QualityAnalysisResult, error) {
	progressTracker.StartPhase("init")
	progressTracker.UpdateProgress("init", "Initializing analysis", operation)

	// Check resource limits early and determine strategy
	shouldDegrade, degradationStrategy := fo.resourceMonitor.ShouldDegrade()
	var strategy FallbackStrategy
	if shouldDegrade {
		progressTracker.UpdateProgress("init", "Resource constraints detected", "Applying graceful degradation")
		strategy = fo.adaptStrategyForResources(operation, degradationStrategy)
	} else {
		strategy = fo.getStrategy(operation)
	}

	progressTracker.StartPhase("config")
	progressTracker.UpdateProgress("config", "Validating configuration", "Checking Hub and API key")

	// Validate critical configuration first
	if strategy.RequireHubForCritical {
		if err := validateHubConfiguration(); err != nil {
			progressTracker.UpdateProgress("config", "Configuration validation failed", err.Error())
			return nil, &CriticalConfigurationError{
				Operation: operation,
				Cause: err,
				Solutions: getHubSetupSolutions(),
			}
		}
	}

	progressTracker.CompletePhase("config")
	progressTracker.StartPhase("scan")
	progressTracker.UpdateProgress("scan", "Scanning codebase", "Analyzing files and patterns")

	var lastError error
	var bestResult interface{}
	var bestQuality QualityScore

	// Try sources in priority order
	for _, source := range strategy.PrioritySources {
		var result interface{}
		var err error

		switch source {
		case "hub":
			progressTracker.UpdateProgress("scan", "Connecting to Sentinel Hub", "Attempting Hub analysis")
			result, err = analysisFunc() // This is the Hub-based function
		case "cache":
			progressTracker.UpdateProgress("fallback", "Checking cached results", "Looking for previous analysis")
			result, err = fo.tryCacheFallback(operation)
		case "local":
			progressTracker.UpdateProgress("fallback", "Running local analysis", "Using built-in analysis engine")
			result, err = fo.tryLocalFallback(operation, analysisFunc)
		default:
			continue
		}

		if err != nil {
			lastError = err
			fo.qualityTracker.RecordFailure(source, err)
			progressTracker.UpdateProgress("fallback", fmt.Sprintf("%s failed, trying alternatives", strings.Title(source)), err.Error())
			continue
		}

		progressTracker.StartPhase("analyze")
		progressTracker.UpdateProgress("analyze", fmt.Sprintf("Analyzing %s results", source), "Processing findings")

		// Calculate quality for this result
		quality := fo.calculateQualityScore(result, source, operation)

		progressTracker.StartPhase("quality")
		progressTracker.UpdateProgress("quality", "Calculating quality metrics", fmt.Sprintf("%.1f/10 quality score", quality.Overall))

		// Check cache freshness for cached results
		if source == "cache" && quality.Freshness > strategy.MaxCacheAge {
			fo.qualityTracker.RecordFailure("cache", fmt.Errorf("cache too stale: %v", quality.Freshness))
			progressTracker.UpdateProgress("quality", "Cache results too stale", "Skipping outdated results")
			continue
		}

		// Keep track of best result
		if bestResult == nil || quality.Overall > bestQuality.Overall {
			bestResult = result
			bestQuality = quality
		}

		// If we meet quality threshold, use this result
		if quality.Overall >= strategy.QualityThreshold {
			progressTracker.CompletePhase("analyze")
			progressTracker.CompletePhase("quality")
			progressTracker.StartPhase("complete")
			progressTracker.UpdateProgress("complete", "Analysis successful", fmt.Sprintf("Using %s results", source))

			qualityResult := &QualityAnalysisResult{
				Success:   true,
				Data:      result,
				Quality:   quality,
				Metadata:  map[string]interface{}{"source": source, "fallback_used": source != "hub"},
				Timestamp: time.Now(),
			}
			fo.qualityTracker.RecordSuccess(source, quality)
			return qualityResult, nil
		}
	}

	// Return best available result with quality transparency
	if bestResult != nil {
		progressTracker.CompletePhase("analyze")
		progressTracker.CompletePhase("quality")
		progressTracker.CompletePhase("complete")

		bestQualityResult := &QualityAnalysisResult{
			Success:   true,
			Data:      bestResult,
			Quality:   bestQuality,
			Metadata:  map[string]interface{}{"source": bestQuality.Source, "degraded": true, "last_error": lastError.Error()},
			Timestamp: time.Now(),
		}
		fo.qualityTracker.RecordDegradedResult(bestQuality, lastError)
		return bestQualityResult, nil
	}

	// Complete failure
	progressTracker.UpdateProgress("complete", "Analysis failed", "No suitable analysis source available")
	return nil, &NoSourceAvailableError{
		Operation: operation,
		TriedSources: strategy.PrioritySources,
		LastError: lastError,
		Solutions: fo.generateRecoverySolutions(operation, lastError),
	}
}

func (fo *FallbackOrchestrator) ExecuteAnalysis(operation string, analysisFunc func() (interface{}, error)) (*QualityAnalysisResult, error) {
	// Create a silent progress tracker for backward compatibility
	silentTracker := NewProgressTracker()
	return fo.ExecuteAnalysisWithProgress(operation, silentTracker, analysisFunc)
}

func (fo *FallbackOrchestrator) tryFallbackSource(source string, operation string, originalFunc func() (interface{}, error)) (interface{}, error) {
	switch source {
	case "cache":
		return fo.tryCacheFallback(operation)
	case "local":
		return fo.tryLocalFallback(operation, originalFunc)
	default:
		return nil, fmt.Errorf("unknown fallback source: %s", source)
	}
}

func (fo *FallbackOrchestrator) tryCacheFallback(operation string) (interface{}, error) {
	// Check if we have cached results for this operation
	cacheKey := fmt.Sprintf("analysis_%s", operation)
	if result, exists := getCachedResult(cacheKey); exists {
		return result, nil
	}
	return nil, fmt.Errorf("no cached result available")
}

func (fo *FallbackOrchestrator) tryLocalFallback(operation string, originalFunc func() (interface{}, error)) (interface{}, error) {
	// For local fallback, we run a simplified version of the analysis
	// Each operation type has its own local implementation
	switch operation {
	case "security-audit":
		return runLocalSecurityAudit()
	case "pattern-analysis":
		return runLocalPatternAnalysis()
	default:
		return nil, fmt.Errorf("no local fallback available for operation: %s", operation)
	}
}

func (fo *FallbackOrchestrator) calculateQualityScore(result interface{}, source string, operation string) QualityScore {
	score := QualityScore{
		Source: source,
		Components: make(map[string]float64),
	}

	// Base quality by source
	switch source {
	case "hub":
		score.Overall = 9.5
		score.Components["analysis"] = 10.0
		score.Components["coverage"] = 95.0
		score.Confidence = 0.95
	case "cache":
		score.Overall = 8.0
		// For cache results, freshness is determined by the actual cached data age
		// This will be set by the cache retrieval logic
		score.Freshness = 0 // Will be overridden by actual cache age
		score.Components["staleness"] = 10.0 // Assume fresh unless proven otherwise
	case "local":
		score.Overall = 6.5
		score.Components["analysis"] = 7.0
		score.Components["coverage"] = 85.0
		score.Confidence = 0.70
	}

	// Adjust for operation-specific factors
	switch operation {
	case "security-audit":
		if source == "local" {
			score.Components["security_depth"] = 6.0
		} else {
			score.Components["security_depth"] = 9.0
		}
	case "code-generation":
		if source == "hub" {
			score.Components["creativity"] = 9.5
			score.Components["accuracy"] = 9.0
		}
	}

	// Calculate coverage based on result data
	if auditResult, ok := result.(*AuditResult); ok {
		fileCount := len(auditResult.Findings)
		if fileCount > 0 {
			score.Coverage = 90.0 // Assume good coverage if we have findings
		} else {
			score.Coverage = 75.0 // Lower if no findings (might be incomplete scan)
		}
	} else {
		score.Coverage = 80.0 // Default coverage
	}

	return score
}

func (fo *FallbackOrchestrator) getStrategy(operation string) FallbackStrategy {
	if strategy, exists := fo.strategies[operation]; exists {
		return strategy
	}

	// Default strategy
	return FallbackStrategy{
		PrioritySources: []string{"hub", "cache", "local"},
		QualityThreshold: 6.0,
		RequireHubForCritical: false,
		MaxCacheAge: 8 * time.Hour,
	}
}

func (fo *FallbackOrchestrator) generateRecoverySolutions(operation string, lastError error) []string {
	solutions := []string{
		"Check your network connection and try again",
		"Verify Sentinel Hub is running and accessible",
		"Run 'sentinel doctor' to diagnose configuration issues",
	}

	if strings.Contains(lastError.Error(), "timeout") {
		solutions = append(solutions, "Increase timeout with --hub-timeout flag")
	}

	if strings.Contains(lastError.Error(), "unauthorized") {
		solutions = append(solutions, "Verify your API key is correct and has proper permissions")
	}

	return solutions
}

// CriticalConfigurationError represents critical setup issues that block operations
type CriticalConfigurationError struct {
	Operation string   `json:"operation"`
	Cause     error    `json:"cause"`
	Solutions []string `json:"solutions"`
}

func (cce *CriticalConfigurationError) Error() string {
	return fmt.Sprintf("Critical configuration error for %s: %s", cce.Operation, cce.Cause.Error())
}

// NoSourceAvailableError represents complete failure of all sources
type NoSourceAvailableError struct {
	Operation    string   `json:"operation"`
	TriedSources []string `json:"tried_sources"`
	LastError    error    `json:"last_error"`
	Solutions    []string `json:"solutions"`
}

func (nsae *NoSourceAvailableError) Error() string {
	return fmt.Sprintf("No analysis source available for %s after trying: %v. Last error: %s",
		nsae.Operation, nsae.TriedSources, nsae.LastError.Error())
}

// =============================================================================
// HUB HEALTH MONITORING SYSTEM
// =============================================================================

// HubHealth represents the current health status of the Sentinel Hub
type HubHealth struct {
	Available     bool          `json:"available"`
	ResponseTime  time.Duration `json:"response_time"`
	StatusCode    int           `json:"status_code"`
	Error         string        `json:"error,omitempty"`
	LastChecked   time.Time     `json:"last_checked"`
	Services      []ServiceStatus `json:"services"`
}

// ServiceStatus represents the status of individual Hub services
type ServiceStatus struct {
	Name    string `json:"name"`
	Status  string `json:"status"` // "healthy", "degraded", "unavailable"
	Message string `json:"message,omitempty"`
}

// HubMonitor provides comprehensive Hub health monitoring
type HubMonitor struct {
	healthCheckURL string
	apiKey         string
	lastHealth     *HubHealth
	mu             sync.RWMutex
}

func NewHubMonitor() *HubMonitor {
	config := loadConfig()

	return &HubMonitor{
		healthCheckURL: config.HubURL + "/health",
		apiKey:         config.APIKey,
	}
}

// CheckHealth performs comprehensive Hub health check
func (hm *HubMonitor) CheckHealth() *HubHealth {
	hm.mu.Lock()
	defer hm.mu.Unlock()

	health := &HubHealth{
		LastChecked: time.Now(),
	}

	if hm.healthCheckURL == "" || hm.apiKey == "" {
		health.Available = false
		health.Error = "Hub not configured"
		hm.lastHealth = health
		return health
	}

	// Test basic connectivity with timeout
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	start := time.Now()
	req, err := http.NewRequestWithContext(ctx, "GET", hm.healthCheckURL, nil)
	if err != nil {
		health.Available = false
		health.Error = fmt.Sprintf("Invalid request: %v", err)
		hm.lastHealth = health
		return health
	}

	req.Header.Set("Authorization", "Bearer "+hm.apiKey)
	req.Header.Set("User-Agent", "Sentinel-Client/v24")

	resp, err := http.DefaultClient.Do(req)
	health.ResponseTime = time.Since(start)

	if err != nil {
		health.Available = false
		health.Error = fmt.Sprintf("Connection failed: %v", err)
		hm.lastHealth = health
		return health
	}
	defer resp.Body.Close()

	health.StatusCode = resp.StatusCode

	if resp.StatusCode >= 200 && resp.StatusCode < 300 {
		health.Available = true
		// Parse detailed health response
		if resp.StatusCode == 200 {
			hm.parseDetailedHealth(resp, health)
		}
	} else {
		health.Available = false
		health.Error = fmt.Sprintf("HTTP %d: %s", resp.StatusCode, resp.Status)
	}

	hm.lastHealth = health
	return health
}

// parseDetailedHealth parses detailed health information from Hub response
func (hm *HubMonitor) parseDetailedHealth(resp *http.Response, health *HubHealth) {
	var healthResponse struct {
		Status   string          `json:"status"`
		Services []ServiceStatus `json:"services"`
		Message  string          `json:"message,omitempty"`
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		// Log the error but continue with basic health info
		// This is not a critical failure for health checking
		return
	}

	if err := json.Unmarshal(body, &healthResponse); err != nil {
		// Log the JSON parsing error but continue with basic health info
		// Hub may return non-JSON responses or different formats
		return
	}

	health.Services = healthResponse.Services
}

// GetHealth returns the last known health status
func (hm *HubMonitor) GetHealth() *HubHealth {
	hm.mu.RLock()
	defer hm.mu.RUnlock()

	if hm.lastHealth == nil {
		return hm.CheckHealth()
	}

	// Return cached health if recent (within 5 minutes)
	if time.Since(hm.lastHealth.LastChecked) < 5*time.Minute {
		return hm.lastHealth
	}

	// Health is stale, check again
	hm.mu.RUnlock()
	return hm.CheckHealth()
}

// IsHealthy returns true if Hub is available and responsive
func (hm *HubMonitor) IsHealthy() bool {
	health := hm.GetHealth()
	return health.Available && health.ResponseTime < 5*time.Second
}

// GetHealthDescription returns a human-readable health description
func (hm *HubMonitor) GetHealthDescription() string {
	health := hm.GetHealth()

	if !health.Available {
		return fmt.Sprintf("‚ùå Unavailable (%s)", health.Error)
	}

	responseTime := health.ResponseTime
	var performance string
	if responseTime < 500*time.Millisecond {
		performance = "Excellent"
	} else if responseTime < 2*time.Second {
		performance = "Good"
	} else {
		performance = "Slow"
	}

	return fmt.Sprintf("‚úÖ %s (%dms)", performance, responseTime.Milliseconds())
}

// Helper functions for configuration validation
func validateHubConfiguration() error {
	config := loadConfig()
	if config.HubURL == "" {
		return fmt.Errorf("hub URL not configured")
	}
	if config.APIKey == "" {
		return fmt.Errorf("API key not configured")
	}

	monitor := NewHubMonitor()
	health := monitor.CheckHealth()

	if !health.Available {
		return fmt.Errorf("hub unavailable: %s", health.Error)
	}

	return nil
}

func getHubSetupSolutions() []string {
	return []string{
		"Run 'sentinel setup' to configure your Hub connection",
		"Set SENTINEL_HUB_URL environment variable",
		"Set SENTINEL_API_KEY environment variable",
		"Check that Sentinel Hub service is running",
	}
}

// =============================================================================
// üé® QUALITY DISPLAY SYSTEM (TRANSPARENT UI)
// =============================================================================

// QualityDisplay handles showing quality information to users
type QualityDisplay struct {
	Verbose bool
	CIMode  bool
}

func NewQualityDisplay(verbose, ciMode bool) *QualityDisplay {
	return &QualityDisplay{
		Verbose: verbose,
		CIMode:  ciMode,
	}
}

func (qd *QualityDisplay) ShowQualityReport(result *QualityAnalysisResult) {
	if qd.CIMode {
		qd.showCIMetrics(result)
		return
	}

	qd.showInteractiveReport(result)
}

func (qd *QualityDisplay) showInteractiveReport(result *QualityAnalysisResult) {
	quality := result.Quality

	fmt.Println("üîç Analysis Complete")
	fmt.Println("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")

	// Quality score
	scoreColor := qd.getScoreColor(quality.Overall)
	fmt.Printf("üìä Quality Score: %s%.1f/10%s (%s)\n",
			   scoreColor, quality.Overall, "\033[0m", qd.getSourceDescription(quality.Source))

	// Freshness indicator
	if quality.Freshness > 0 {
		ageColor := qd.getAgeColor(quality.Freshness)
		fmt.Printf("‚è∞ Result Age: %s%s%s\n", ageColor, qd.formatDuration(quality.Freshness), "\033[0m")
	} else {
		fmt.Printf("‚è∞ Result Age: %sFresh%s\n", "\033[32m", "\033[0m")
	}

	// Coverage
	coverageColor := qd.getCoverageColor(quality.Coverage)
	fmt.Printf("üéØ Coverage: %s%.0f%%%s of codebase analyzed\n",
			   coverageColor, quality.Coverage, "\033[0m")

	// Performance indicator
	perfIndicator := qd.getPerformanceIndicator(quality.Source)
	fmt.Printf("‚ö° Performance: %s\n", perfIndicator)

	// Confidence (for AI-powered results)
	if quality.Confidence > 0 {
		confColor := qd.getConfidenceColor(quality.Confidence)
		fmt.Printf("üß† AI Confidence: %s%.0f%%%s\n",
				   confColor, quality.Confidence*100, "\033[0m")
	}

	// Component scores (if verbose)
	if qd.Verbose && len(quality.Components) > 0 {
		fmt.Println("")
		fmt.Println("üìà Component Scores:")
		for component, score := range quality.Components {
			fmt.Printf("  ‚Ä¢ %s: %.1f/10\n", qd.formatComponentName(component), score)
		}
	}

	// Show metadata if available and verbose
	if qd.Verbose && len(result.Metadata) > 0 {
		fmt.Println("")
		fmt.Println("üìã Metadata:")
		for key, value := range result.Metadata {
			fmt.Printf("  ‚Ä¢ %s: %v\n", key, value)
		}
	}

	// Suggestions
	suggestions := qd.generateSuggestions(result)
	if len(suggestions) > 0 {
		fmt.Println("")
		fmt.Println("üí° Suggestions:")
		for _, suggestion := range suggestions {
			fmt.Printf("‚Ä¢ %s\n", suggestion)
		}
	}

	// Status
	status := qd.getOverallStatus(result)
	fmt.Println("")
	fmt.Printf("‚úÖ %s\n", status)
}

func (qd *QualityDisplay) showCIMetrics(result *QualityAnalysisResult) {
	quality := result.Quality

	// CI-friendly output format
	fmt.Printf("SENTINEL_QUALITY_SCORE=%.1f\n", quality.Overall)
	fmt.Printf("SENTINEL_QUALITY_SOURCE=%s\n", quality.Source)
	fmt.Printf("SENTINEL_COVERAGE_PERCENT=%.0f\n", quality.Coverage)

	if quality.Confidence > 0 {
		fmt.Printf("SENTINEL_AI_CONFIDENCE=%.2f\n", quality.Confidence)
	}

	if quality.Freshness > 0 {
		fmt.Printf("SENTINEL_RESULT_AGE_SECONDS=%.0f\n", quality.Freshness.Seconds())
	}

	// Component scores as individual metrics
	for component, score := range quality.Components {
		envKey := fmt.Sprintf("SENTINEL_%s_SCORE", strings.ToUpper(strings.ReplaceAll(component, "-", "_")))
		fmt.Printf("%s=%.1f\n", envKey, score)
	}

	// Status indicators
	fmt.Printf("SENTINEL_ANALYSIS_SUCCESS=%t\n", result.Success)
	if degraded, exists := result.Metadata["degraded"]; exists && degraded.(bool) {
		fmt.Printf("SENTINEL_DEGRADED_MODE=true\n")
		fmt.Printf("SENTINEL_DEGRADED_REASON=%s\n", result.Metadata["last_error"])
	} else {
		fmt.Printf("SENTINEL_DEGRADED_MODE=false\n")
	}
}

func (qd *QualityDisplay) generateSuggestions(result *QualityAnalysisResult) []string {
	var suggestions []string

	quality := result.Quality

	if quality.Overall < 7.0 {
		suggestions = append(suggestions, "Configure Sentinel Hub for comprehensive AI-powered analysis")
	}

	if quality.Source == "cache" && quality.Freshness > time.Hour {
		suggestions = append(suggestions, "Results are stale - consider running fresh analysis")
	}

	if quality.Coverage < 90.0 {
		suggestions = append(suggestions, "Enable deep analysis for complete codebase coverage")
	}

	if quality.Confidence < 0.8 && quality.Source == "hub" {
		suggestions = append(suggestions, "AI analysis confidence is low - review results carefully")
	}

	if degraded, exists := result.Metadata["degraded"]; exists && degraded.(bool) {
		suggestions = append(suggestions, "Analysis ran in degraded mode - configure Hub for optimal results")
	}

	return suggestions
}

// Global warning tracker to prevent duplicate warnings
var configWarningShown bool

// =============================================================================
// üìä RESOURCE LIMIT MONITORING (GRACEFUL FALLBACK COMPLETION)
// =============================================================================

// ResourceLimits defines various resource thresholds for graceful degradation
type ResourceLimits struct {
	MaxMemoryMB       int64         `json:"max_memory_mb"`       // Memory limit in MB
	MaxCPUPct         float64       `json:"max_cpu_pct"`         // CPU limit as percentage
	MaxFileSizeMB     int64         `json:"max_file_size_mb"`    // Per-file size limit in MB
	MaxTotalSizeMB    int64         `json:"max_total_size_mb"`   // Total scan size limit in MB
	TimeoutDuration   time.Duration `json:"timeout_duration"`    // Operation timeout
	NetworkTimeout    time.Duration `json:"network_timeout"`     // Network request timeout
	MaxConcurrentOps  int           `json:"max_concurrent_ops"`  // Maximum concurrent operations
}

// ResourceUsage tracks current resource consumption
type ResourceUsage struct {
	MemoryUsedMB    int64         `json:"memory_used_mb"`
	CPUUsedPct      float64       `json:"cpu_used_pct"`
	TotalFiles      int64         `json:"total_files"`
	TotalSizeMB     int64         `json:"total_size_mb"`
	ActiveOps       int           `json:"active_ops"`
	LastUpdated     time.Time     `json:"last_updated"`
}

// ResourceMonitor provides comprehensive resource monitoring and graceful degradation
type ResourceMonitor struct {
	limits      ResourceLimits
	current     ResourceUsage
	alerts      []ResourceAlert
	mu          sync.RWMutex
	alertCb     func(ResourceAlert)
}

// ResourceAlert represents a resource usage alert or warning
type ResourceAlert struct {
	Type        string    `json:"type"`        // "warning", "critical", "exceeded"
	Resource    string    `json:"resource"`    // "memory", "cpu", "file_size", etc.
	Current     float64   `json:"current"`     // Current usage value
	Limit       float64   `json:"limit"`       // Configured limit
	Percentage  float64   `json:"percentage"`  // Usage as percentage of limit
	Message     string    `json:"message"`     // Human-readable message
	Timestamp   time.Time `json:"timestamp"`
	Recommended string    `json:"recommended"` // Recommended action
}

// DegradationStrategy defines how to gracefully degrade when resources are limited
type DegradationStrategy struct {
	ReduceConcurrency    bool `json:"reduce_concurrency"`
	SkipLargeFiles       bool `json:"skip_large_files"`
	UseCacheOnly         bool `json:"use_cache_only"`
	ReduceAnalysisDepth  bool `json:"reduce_analysis_depth"`
	IncreaseTimeouts     bool `json:"increase_timeouts"`
	DisableNetworkCalls  bool `json:"disable_network_calls"`
}

func NewResourceMonitor() *ResourceMonitor {
	// Default resource limits (can be configured)
	defaultLimits := ResourceLimits{
		MaxMemoryMB:      512,  // 512MB memory limit
		MaxCPUPct:        80.0, // 80% CPU limit
		MaxFileSizeMB:    50,   // 50MB per file
		MaxTotalSizeMB:   1024, // 1GB total scan size
		TimeoutDuration:  30 * time.Second,
		NetworkTimeout:   10 * time.Second,
		MaxConcurrentOps: 5,
	}

	return &ResourceMonitor{
		limits:  defaultLimits,
		current: ResourceUsage{LastUpdated: time.Now()},
		alerts:  make([]ResourceAlert, 0),
	}
}

func (rm *ResourceMonitor) SetLimits(limits ResourceLimits) {
	rm.mu.Lock()
	defer rm.mu.Unlock()
	rm.limits = limits
}

func (rm *ResourceMonitor) SetAlertCallback(callback func(ResourceAlert)) {
	rm.mu.Lock()
	defer rm.mu.Unlock()
	rm.alertCb = callback
}

func (rm *ResourceMonitor) UpdateUsage(usage ResourceUsage) {
	rm.mu.Lock()
	defer rm.mu.Unlock()

	rm.current = usage
	rm.current.LastUpdated = time.Now()

	// Check all resource limits and generate alerts
	rm.checkMemoryLimit()
	rm.checkCPULimit()
	rm.checkFileLimits()
	rm.checkConcurrencyLimit()
}

func (rm *ResourceMonitor) checkMemoryLimit() {
	if rm.current.MemoryUsedMB > rm.limits.MaxMemoryMB {
		alert := ResourceAlert{
			Type:       "exceeded",
			Resource:   "memory",
			Current:    float64(rm.current.MemoryUsedMB),
			Limit:      float64(rm.limits.MaxMemoryMB),
			Percentage: (float64(rm.current.MemoryUsedMB) / float64(rm.limits.MaxMemoryMB)) * 100,
			Message:    fmt.Sprintf("Memory usage exceeded limit: %dMB / %dMB", rm.current.MemoryUsedMB, rm.limits.MaxMemoryMB),
			Timestamp:  time.Now(),
			Recommended: "Reduce analysis depth or file processing concurrency",
		}
		rm.addAlert(alert)
	} else if rm.current.MemoryUsedMB > int64(float64(rm.limits.MaxMemoryMB)*0.8) {
		percentage := (float64(rm.current.MemoryUsedMB) / float64(rm.limits.MaxMemoryMB)) * 100
		alert := ResourceAlert{
			Type:       "warning",
			Resource:   "memory",
			Current:    float64(rm.current.MemoryUsedMB),
			Limit:      float64(rm.limits.MaxMemoryMB),
			Percentage: percentage,
			Message:    fmt.Sprintf("Memory usage high: %dMB / %dMB (%.1f%%)", rm.current.MemoryUsedMB, rm.limits.MaxMemoryMB, percentage),
			Timestamp:  time.Now(),
			Recommended: "Consider reducing concurrent operations",
		}
		rm.addAlert(alert)
	}
}

func (rm *ResourceMonitor) checkCPULimit() {
	if rm.current.CPUUsedPct > rm.limits.MaxCPUPct {
		alert := ResourceAlert{
			Type:       "exceeded",
			Resource:   "cpu",
			Current:    rm.current.CPUUsedPct,
			Limit:      rm.limits.MaxCPUPct,
			Percentage: (rm.current.CPUUsedPct / rm.limits.MaxCPUPct) * 100,
			Message:    fmt.Sprintf("CPU usage exceeded limit: %.1f%% / %.1f%%", rm.current.CPUUsedPct, rm.limits.MaxCPUPct),
			Timestamp:  time.Now(),
			Recommended: "Reduce processing intensity or analysis depth",
		}
		rm.addAlert(alert)
	} else if rm.current.CPUUsedPct > rm.limits.MaxCPUPct*0.8 {
		alert := ResourceAlert{
			Type:       "warning",
			Resource:   "cpu",
			Current:    rm.current.CPUUsedPct,
			Limit:      rm.limits.MaxCPUPct,
			Percentage: (rm.current.CPUUsedPct / rm.limits.MaxCPUPct) * 100,
			Message:    fmt.Sprintf("CPU usage high: %.1f%% / %.1f%%", rm.current.CPUUsedPct, rm.limits.MaxCPUPct),
			Timestamp:  time.Now(),
			Recommended: "Monitor CPU usage and consider reducing load",
		}
		rm.addAlert(alert)
	}
}

func (rm *ResourceMonitor) checkFileLimits() {
	if rm.current.TotalSizeMB > rm.limits.MaxTotalSizeMB {
		alert := ResourceAlert{
			Type:       "exceeded",
			Resource:   "total_size",
			Current:    float64(rm.current.TotalSizeMB),
			Limit:      float64(rm.limits.MaxTotalSizeMB),
			Percentage: (float64(rm.current.TotalSizeMB) / float64(rm.limits.MaxTotalSizeMB)) * 100,
			Message:    fmt.Sprintf("Total scan size exceeded limit: %dMB / %dMB", rm.current.TotalSizeMB, rm.limits.MaxTotalSizeMB),
			Timestamp:  time.Now(),
			Recommended: "Use --max-depth or exclude large directories",
		}
		rm.addAlert(alert)
	}
}

func (rm *ResourceMonitor) checkConcurrencyLimit() {
	if rm.current.ActiveOps > rm.limits.MaxConcurrentOps {
		alert := ResourceAlert{
			Type:       "exceeded",
			Resource:   "concurrency",
			Current:    float64(rm.current.ActiveOps),
			Limit:      float64(rm.limits.MaxConcurrentOps),
			Percentage: (float64(rm.current.ActiveOps) / float64(rm.limits.MaxConcurrentOps)) * 100,
			Message:    fmt.Sprintf("Concurrent operations exceeded limit: %d / %d", rm.current.ActiveOps, rm.limits.MaxConcurrentOps),
			Timestamp:  time.Now(),
			Recommended: "Reduce --concurrency flag or use --sequential",
		}
		rm.addAlert(alert)
	}
}

func (rm *ResourceMonitor) addAlert(alert ResourceAlert) {
	rm.alerts = append(rm.alerts, alert)

	// Keep only last 10 alerts
	if len(rm.alerts) > 10 {
		rm.alerts = rm.alerts[len(rm.alerts)-10:]
	}

	// Call alert callback if set
	if rm.alertCb != nil {
		go rm.alertCb(alert)
	}
}

func (rm *ResourceMonitor) GetAlerts() []ResourceAlert {
	rm.mu.RLock()
	defer rm.mu.RUnlock()

	alerts := make([]ResourceAlert, len(rm.alerts))
	copy(alerts, rm.alerts)
	return alerts
}

func (rm *ResourceMonitor) GetLimits() ResourceLimits {
	rm.mu.RLock()
	defer rm.mu.RUnlock()
	return rm.limits
}

func (rm *ResourceMonitor) GetCurrentUsage() ResourceUsage {
	rm.mu.RLock()
	defer rm.mu.RUnlock()
	return rm.current
}

func (rm *ResourceMonitor) ShouldDegrade() (bool, DegradationStrategy) {
	rm.mu.RLock()
	defer rm.mu.RUnlock()

	strategy := DegradationStrategy{}
	shouldDegrade := false

	// Check for critical resource alerts
	alerts := rm.GetAlerts()
	for _, alert := range alerts {
		if alert.Type == "exceeded" || (alert.Type == "warning" && alert.Percentage > 90) {
			shouldDegrade = true

			switch alert.Resource {
			case "memory":
				strategy.ReduceConcurrency = true
				strategy.ReduceAnalysisDepth = true
			case "cpu":
				strategy.ReduceConcurrency = true
				strategy.SkipLargeFiles = true
			case "total_size":
				strategy.SkipLargeFiles = true
				strategy.ReduceAnalysisDepth = true
			case "concurrency":
				strategy.ReduceConcurrency = true
			}
		}
	}

	return shouldDegrade, strategy
}

// adaptStrategyForResources modifies analysis strategy based on resource constraints
func (fo *FallbackOrchestrator) adaptStrategyForResources(operation string, degradation DegradationStrategy) FallbackStrategy {
	baseStrategy := fo.getStrategy(operation)

	// Apply resource-aware modifications
	if degradation.ReduceConcurrency {
		// Reduce priority sources or add delays between operations
		baseStrategy.PrioritySources = fo.optimizeSourcesForResources(baseStrategy.PrioritySources)
	}

	if degradation.SkipLargeFiles {
		// This would be handled in the file processing logic
		// For now, we modify the strategy to prefer faster sources
		if len(baseStrategy.PrioritySources) > 1 {
			// Prefer cache or local over network calls when resources are constrained
			baseStrategy.PrioritySources = fo.reorderForResourceEfficiency(baseStrategy.PrioritySources)
		}
	}

	if degradation.UseCacheOnly {
		// Only use cached results to minimize resource usage
		baseStrategy.PrioritySources = []string{"cache"}
		baseStrategy.MaxCacheAge = 48 * time.Hour // Extend cache validity
	}

	if degradation.ReduceAnalysisDepth {
		// Reduce quality threshold to accept lower-quality but faster results
		baseStrategy.QualityThreshold = baseStrategy.QualityThreshold * 0.8
		if baseStrategy.QualityThreshold < 5.0 {
			baseStrategy.QualityThreshold = 5.0 // Minimum acceptable quality
		}
	}

	if degradation.DisableNetworkCalls {
		// Remove network-dependent sources
		filteredSources := make([]string, 0)
		for _, source := range baseStrategy.PrioritySources {
			if source != "hub" { // Keep local and cache, remove hub
				filteredSources = append(filteredSources, source)
			}
		}
		if len(filteredSources) == 0 {
			filteredSources = []string{"local"} // Fallback to local only
		}
		baseStrategy.PrioritySources = filteredSources
	}

	return baseStrategy
}

// optimizeSourcesForResources reorders sources to minimize resource usage
func (fo *FallbackOrchestrator) optimizeSourcesForResources(sources []string) []string {
	// Reorder to prefer low-resource sources first
	priority := map[string]int{
		"cache": 1, // Lowest resource usage
		"local": 2, // Medium resource usage
		"hub":   3, // Highest resource usage
	}

	// Sort sources by resource priority
	sorted := make([]string, len(sources))
	copy(sorted, sources)

	for i := 0; i < len(sorted)-1; i++ {
		for j := i + 1; j < len(sorted); j++ {
			if priority[sorted[i]] > priority[sorted[j]] {
				sorted[i], sorted[j] = sorted[j], sorted[i]
			}
		}
	}

	return sorted
}

// reorderForResourceEfficiency reorders sources for better resource efficiency
func (fo *FallbackOrchestrator) reorderForResourceEfficiency(sources []string) []string {
	// When resources are constrained, prefer cache > local > hub
	preferredOrder := []string{"cache", "local", "hub"}
	result := make([]string, 0)

	// Add sources in preferred order if they exist in original list
	for _, preferred := range preferredOrder {
		for _, source := range sources {
			if source == preferred {
				result = append(result, source)
				break
			}
		}
	}

	return result
}

func (rm *ResourceMonitor) GetHealthStatus() string {
	rm.mu.RLock()
	defer rm.mu.RUnlock()

	alerts := rm.GetAlerts()
	criticalCount := 0
	warningCount := 0

	for _, alert := range alerts {
		if alert.Type == "exceeded" {
			criticalCount++
		} else if alert.Type == "warning" {
			warningCount++
		}
	}

	if criticalCount > 0 {
		return fmt.Sprintf("CRITICAL: %d resource limits exceeded", criticalCount)
	} else if warningCount > 0 {
		return fmt.Sprintf("WARNING: %d resource warnings", warningCount)
	} else {
		return "HEALTHY: All resources within limits"
	}
}

// GetMemoryUsage attempts to get current memory usage (simplified implementation)
func GetMemoryUsage() int64 {
	// This is a simplified implementation
	// In a real system, you would use runtime.ReadMemStats() or OS-specific APIs

	// For now, return a placeholder that represents typical usage
	// In production, this would query actual memory statistics
	return 128 // MB - placeholder
}

// GetCPUUsage attempts to get current CPU usage (simplified implementation)
func GetCPUUsage() float64 {
	// This is a simplified implementation
	// In a real system, you would use OS-specific CPU monitoring

	// For now, return a placeholder
	// In production, this would calculate actual CPU percentage
	return 45.0 // percentage - placeholder
}

// =============================================================================
// STANDARDIZED ERROR HANDLING
// =============================================================================

// ErrorSeverity represents the severity level of an error
type ErrorSeverity int

const (
	ErrorSeverityLow ErrorSeverity = iota
	ErrorSeverityMedium
	ErrorSeverityHigh
	ErrorSeverityCritical
)

// handleCommandError provides standardized error handling for CLI commands
func handleCommandError(err error, context string, exitCode int) {
	if err == nil {
		return
	}

	severity := classifyErrorSeverity(err)

	switch severity {
	case ErrorSeverityCritical:
		fmt.Printf("üí• CRITICAL ERROR in %s: %s\n", context, err.Error())
	case ErrorSeverityHigh:
		fmt.Printf("‚ùå ERROR in %s: %s\n", context, err.Error())
	case ErrorSeverityMedium:
		fmt.Printf("‚ö†Ô∏è  WARNING in %s: %s\n", context, err.Error())
	case ErrorSeverityLow:
		fmt.Printf("‚ÑπÔ∏è  INFO in %s: %s\n", context, err.Error())
	}

	if exitCode > 0 {
		os.Exit(exitCode)
	}
}

// classifyErrorSeverity attempts to classify error severity based on error content
func classifyErrorSeverity(err error) ErrorSeverity {
	if err == nil {
		return ErrorSeverityLow
	}

	errStr := err.Error()

	// Critical errors that prevent operation
	if strings.Contains(errStr, "not configured") ||
	   strings.Contains(errStr, "not found") ||
	   strings.Contains(errStr, "permission denied") {
		return ErrorSeverityCritical
	}

	// High severity errors
	if strings.Contains(errStr, "connection failed") ||
	   strings.Contains(errStr, "timeout") ||
	   strings.Contains(errStr, "unauthorized") {
		return ErrorSeverityHigh
	}

	// Medium severity errors
	if strings.Contains(errStr, "parse error") ||
	   strings.Contains(errStr, "invalid") {
		return ErrorSeverityMedium
	}

	return ErrorSeverityLow
}

// =============================================================================
// üìä PROGRESS TRACKING SYSTEM (REAL-TIME FEEDBACK)
// =============================================================================

// ProgressPhase represents different stages of analysis
type ProgressPhase struct {
	Name        string  `json:"name"`
	Description string  `json:"description"`
	Weight      float64 `json:"weight"`      // Percentage weight of total progress
	Started     bool    `json:"started"`
	Completed   bool    `json:"completed"`
	StartTime   time.Time `json:"start_time"`
	EndTime     time.Time `json:"end_time"`
}

// ProgressUpdate represents a progress update event
type ProgressUpdate struct {
	Phase       string    `json:"phase"`
	Message     string    `json:"message"`
	Progress    float64   `json:"progress"`    // 0.0 - 100.0
	Details     string    `json:"details,omitempty"`
	Timestamp   time.Time `json:"timestamp"`
	IsComplete  bool      `json:"is_complete"`
}

// ProgressTracker manages analysis progress tracking
type ProgressTracker struct {
	phases      []ProgressPhase
	currentPhase int
	startTime   time.Time
	totalProgress float64
	mu          sync.RWMutex
	listeners   []ProgressListener
}

// ProgressListener interface for receiving progress updates
type ProgressListener interface {
	OnProgressUpdate(update ProgressUpdate)
}

// ProgressDisplay handles visual progress display
type ProgressDisplay struct {
	verbose     bool
	ciMode      bool
	lastUpdate  ProgressUpdate
	showSpinner bool
	spinnerPos  int
	mu          sync.Mutex
}

func NewProgressTracker() *ProgressTracker {
	return &ProgressTracker{
		phases: []ProgressPhase{
			{Name: "init", Description: "Initializing analysis", Weight: 5.0},
			{Name: "config", Description: "Validating configuration", Weight: 5.0},
			{Name: "scan", Description: "Scanning codebase", Weight: 40.0},
			{Name: "analyze", Description: "Analyzing patterns", Weight: 25.0},
			{Name: "quality", Description: "Calculating quality metrics", Weight: 10.0},
			{Name: "fallback", Description: "Applying fallback strategies", Weight: 10.0},
			{Name: "complete", Description: "Finalizing results", Weight: 5.0},
		},
		startTime: time.Now(),
		listeners: make([]ProgressListener, 0),
	}
}

func NewProgressDisplay(verbose, ciMode bool) *ProgressDisplay {
	return &ProgressDisplay{
		verbose:     verbose,
		ciMode:      ciMode,
		showSpinner: !ciMode,
	}
}

func (pt *ProgressTracker) AddListener(listener ProgressListener) {
	pt.mu.Lock()
	defer pt.mu.Unlock()
	pt.listeners = append(pt.listeners, listener)
}

func (pt *ProgressTracker) StartPhase(phaseName string) {
	pt.mu.Lock()
	defer pt.mu.Unlock()

	for i, phase := range pt.phases {
		if phase.Name == phaseName {
			pt.phases[i].Started = true
			pt.phases[i].StartTime = time.Now()
			pt.currentPhase = i

			update := ProgressUpdate{
				Phase:     phaseName,
				Message:   fmt.Sprintf("Starting: %s", phase.Description),
				Progress:  pt.calculateProgress(),
				Timestamp: time.Now(),
			}

			pt.notifyListeners(update)
			break
		}
	}
}

func (pt *ProgressTracker) CompletePhase(phaseName string) {
	pt.mu.Lock()
	defer pt.mu.Unlock()

	for i, phase := range pt.phases {
		if phase.Name == phaseName {
			pt.phases[i].Completed = true
			pt.phases[i].EndTime = time.Now()

			update := ProgressUpdate{
				Phase:      phaseName,
				Message:    fmt.Sprintf("Completed: %s", phase.Description),
				Progress:   pt.calculateProgress(),
				Timestamp:  time.Now(),
				IsComplete: true,
			}

			pt.notifyListeners(update)
			break
		}
	}
}

func (pt *ProgressTracker) UpdateProgress(phaseName, message, details string) {
	pt.mu.Lock()
	defer pt.mu.Unlock()

	update := ProgressUpdate{
		Phase:     phaseName,
		Message:   message,
		Progress:  pt.calculateProgress(),
		Details:   details,
		Timestamp: time.Now(),
	}

	pt.notifyListeners(update)
}

func (pt *ProgressTracker) calculateProgress() float64 {
	totalWeight := 0.0
	completedWeight := 0.0

	for _, phase := range pt.phases {
		totalWeight += phase.Weight
		if phase.Completed {
			completedWeight += phase.Weight
		} else if phase.Started {
			// Add partial completion for current phase
			elapsed := time.Since(phase.StartTime)
			if elapsed.Seconds() > 0 {
				// Estimate 30% completion for started phases
				completedWeight += phase.Weight * 0.3
			}
		}
	}

	if totalWeight == 0 {
		return 0
	}

	return (completedWeight / totalWeight) * 100.0
}

func (pt *ProgressTracker) GetProgress() (float64, string) {
	pt.mu.RLock()
	defer pt.mu.RUnlock()

	progress := pt.calculateProgress()
	var currentPhase string
	if pt.currentPhase < len(pt.phases) {
		currentPhase = pt.phases[pt.currentPhase].Description
	}

	return progress, currentPhase
}

func (pt *ProgressTracker) notifyListeners(update ProgressUpdate) {
	for _, listener := range pt.listeners {
		go listener.OnProgressUpdate(update)
	}
}

func (pd *ProgressDisplay) OnProgressUpdate(update ProgressUpdate) {
	pd.mu.Lock()
	defer pd.mu.Unlock()

	pd.lastUpdate = update

	if pd.ciMode {
		pd.displayCIProgress(update)
	} else {
		pd.displayInteractiveProgress(update)
	}
}

func (pd *ProgressDisplay) displayInteractiveProgress(update ProgressUpdate) {
	if pd.showSpinner {
		pd.clearSpinner()
	}

	// Show progress bar
	progressBar := pd.createProgressBar(update.Progress)
	fmt.Printf("\r%s %s", progressBar, update.Message)

	if update.Details != "" && pd.verbose {
		fmt.Printf(" (%s)", update.Details)
	}

	if pd.showSpinner && !update.IsComplete {
		pd.showSpinner = true
		go pd.animateSpinner()
	} else if update.IsComplete {
		fmt.Println() // New line after completion
	}
}

func (pd *ProgressDisplay) displayCIProgress(update ProgressUpdate) {
	// CI-friendly output
	fmt.Printf("SENTINEL_PROGRESS=%.1f\n", update.Progress)
	fmt.Printf("SENTINEL_PHASE=%s\n", update.Phase)
	fmt.Printf("SENTINEL_STATUS=%s\n", update.Message)

	if update.Details != "" {
		fmt.Printf("SENTINEL_DETAILS=%s\n", update.Details)
	}
}

func (pd *ProgressDisplay) createProgressBar(progress float64) string {
	width := 40
	filled := int((progress / 100.0) * float64(width))

	bar := "["
	for i := 0; i < width; i++ {
		if i < filled {
			bar += "‚ñà"
		} else {
			bar += "‚ñë"
		}
	}
	bar += fmt.Sprintf("] %.1f%%", progress)

	return bar
}

func (pd *ProgressDisplay) animateSpinner() {
	spinners := []string{"‚†ã", "‚†ô", "‚†π", "‚†∏", "‚†º", "‚†¥", "‚†¶", "‚†ß", "‚†á", "‚†è"}

	for pd.showSpinner {
		pd.mu.Lock()
		fmt.Printf("\r%s %s", spinners[pd.spinnerPos], pd.lastUpdate.Message)
		pd.spinnerPos = (pd.spinnerPos + 1) % len(spinners)
		pd.mu.Unlock()

		time.Sleep(100 * time.Millisecond)
	}
}

func (pd *ProgressDisplay) clearSpinner() {
	if pd.showSpinner {
		fmt.Print("\r" + strings.Repeat(" ", 80) + "\r") // Clear line
		pd.showSpinner = false
	}
}

func (pd *ProgressDisplay) ShowFinalStatus() {
	pd.mu.Lock()
	defer pd.mu.Unlock()

	if pd.showSpinner {
		pd.clearSpinner()
	}

	fmt.Println("\n‚úÖ Analysis Complete!")
}

// =============================================================================
// üìä PROGRESS INDICATOR SYSTEM (REAL-TIME FEEDBACK)
// =============================================================================

// ProgressIndicator provides real-time feedback during analysis operations
type ProgressIndicator struct {
	ciMode      bool
	startTime   time.Time
	currentStep string
	totalSteps  int
	completed   int
	spinnerPos  int
	lastUpdate  time.Time
	mu          sync.Mutex
}

func NewProgressIndicator(ciMode bool) *ProgressIndicator {
	return &ProgressIndicator{
		ciMode:     ciMode,
		startTime:  time.Now(),
		lastUpdate: time.Now(),
	}
}

func (pi *ProgressIndicator) Start(operation string, totalSteps int) {
	pi.mu.Lock()
	defer pi.mu.Unlock()

	pi.currentStep = operation
	pi.totalSteps = totalSteps
	pi.completed = 0
	pi.startTime = time.Now()
	pi.lastUpdate = time.Now()

	if !pi.ciMode {
		fmt.Printf("üöÄ Starting %s...\n", operation)
		pi.showProgress()
	}
}

func (pi *ProgressIndicator) UpdateStep(step string, completed int) {
	pi.mu.Lock()
	defer pi.mu.Unlock()

	pi.currentStep = step
	pi.completed = completed

	now := time.Now()
	// Throttle updates to avoid spam (max 10 updates per second)
	if now.Sub(pi.lastUpdate) < 100*time.Millisecond {
		return
	}
	pi.lastUpdate = now

	if !pi.ciMode {
		pi.showProgress()
	}
}

func (pi *ProgressIndicator) UpdateStatus(status string) {
	pi.mu.Lock()
	defer pi.mu.Unlock()

	pi.currentStep = status

	now := time.Now()
	if now.Sub(pi.lastUpdate) < 200*time.Millisecond {
		return
	}
	pi.lastUpdate = now

	if !pi.ciMode {
		pi.showProgress()
	}
}

func (pi *ProgressIndicator) Complete(success bool) {
	pi.mu.Lock()
	defer pi.mu.Unlock()

	elapsed := time.Since(pi.startTime)

	if pi.ciMode {
		if success {
			fmt.Printf("SENTINEL_ANALYSIS_TIME=%.2fs\n", elapsed.Seconds())
		}
		return
	}

	// Clear the progress line
	fmt.Printf("\r\x1b[K")

	if success {
		fmt.Printf("‚úÖ %s completed in %.2fs\n", pi.currentStep, elapsed.Seconds())
	} else {
		fmt.Printf("‚ùå %s failed after %.2fs\n", pi.currentStep, elapsed.Seconds())
	}
}

func (pi *ProgressIndicator) showProgress() {
	elapsed := time.Since(pi.startTime)

	// Calculate progress percentage
	var percent int
	if pi.totalSteps > 0 {
		percent = (pi.completed * 100) / pi.totalSteps
	} else {
		percent = 0
	}

	// Create spinner animation
	spinners := []string{"‚†ã", "‚†ô", "‚†π", "‚†∏", "‚†º", "‚†¥", "‚†¶", "‚†ß", "‚†á", "‚†è"}
	pi.spinnerPos = (pi.spinnerPos + 1) % len(spinners)
	spinner := spinners[pi.spinnerPos]

	// Format elapsed time
	elapsedStr := pi.formatDuration(elapsed)

	// Create progress bar (20 characters wide)
	progressBar := pi.createProgressBar(percent, 20)

	// Show current status with progress
	fmt.Printf("\r\x1b[K%s %s [%s] %d%% (%s)",
		spinner, pi.currentStep, progressBar, percent, elapsedStr)

	// Force output flush
	fmt.Print("")
}

func (pi *ProgressIndicator) createProgressBar(percent, width int) string {
	if width <= 2 {
		return "[]"
	}

	filled := (percent * (width - 2)) / 100
	bar := "["

	for i := 0; i < filled && i < width-2; i++ {
		bar += "‚ñà"
	}

	for i := filled; i < width-2; i++ {
		bar += "‚ñë"
	}

	bar += "]"
	return bar
}

func (pi *ProgressIndicator) formatDuration(d time.Duration) string {
	if d < time.Second {
		return fmt.Sprintf("%.1fs", d.Seconds())
	} else if d < time.Minute {
		return fmt.Sprintf("%.0fs", d.Seconds())
	} else if d < time.Hour {
		minutes := int(d.Minutes())
		seconds := int(d.Seconds()) % 60
		return fmt.Sprintf("%dm%ds", minutes, seconds)
	} else {
		hours := int(d.Hours())
		minutes := int(d.Minutes()) % 60
		return fmt.Sprintf("%dh%dm", hours, minutes)
	}
}

// AnalysisProgressTracker manages progress across the entire analysis workflow
type AnalysisProgressTracker struct {
	indicator  *ProgressIndicator
	ciMode     bool
	phases     []AnalysisPhase
	currentPhase int
}

type AnalysisPhase struct {
	Name        string
	Weight      int  // Relative weight for progress calculation
	Completed   bool
	SubSteps    []string
	CurrentStep int
}

func NewAnalysisProgressTracker(ciMode bool) *AnalysisProgressTracker {
	indicator := NewProgressIndicator(ciMode)

	// Define analysis phases with relative weights
	phases := []AnalysisPhase{
		{Name: "Configuration Validation", Weight: 5, SubSteps: []string{"Loading config", "Validating settings", "Checking permissions"}},
		{Name: "Source Selection", Weight: 10, SubSteps: []string{"Evaluating Hub", "Checking cache", "Preparing local analysis"}},
		{Name: "Connectivity Check", Weight: 15, SubSteps: []string{"Testing Hub connection", "Validating credentials", "Checking network"}},
		{Name: "Analysis Execution", Weight: 50, SubSteps: []string{"Scanning files", "Pattern detection", "Security checks", "Quality assessment"}},
		{Name: "Result Processing", Weight: 15, SubSteps: []string{"Formatting results", "Quality scoring", "Generating recommendations"}},
		{Name: "Finalization", Weight: 5, SubSteps: []string{"Saving output", "Cleanup", "Summary display"}},
	}

	return &AnalysisProgressTracker{
		indicator: indicator,
		ciMode:    ciMode,
		phases:    phases,
	}
}

func (apt *AnalysisProgressTracker) StartAnalysis() {
	totalWeight := 0
	for _, phase := range apt.phases {
		totalWeight += phase.Weight
	}

	apt.indicator.Start("Security Analysis", totalWeight)
	apt.updateProgress()
}

func (apt *AnalysisProgressTracker) SetPhase(phaseIndex int) {
	if phaseIndex >= 0 && phaseIndex < len(apt.phases) {
		apt.currentPhase = phaseIndex
		phase := &apt.phases[phaseIndex]
		phase.Completed = false
		phase.CurrentStep = 0

		if !apt.ciMode {
			apt.indicator.UpdateStatus(fmt.Sprintf("%s: %s", phase.Name, phase.SubSteps[0]))
		}
		apt.updateProgress()
	}
}

func (apt *AnalysisProgressTracker) UpdateSubStep(subStepIndex int) {
	if apt.currentPhase >= len(apt.phases) {
		return
	}

	phase := &apt.phases[apt.currentPhase]
	if subStepIndex >= 0 && subStepIndex < len(phase.SubSteps) {
		phase.CurrentStep = subStepIndex

		if !apt.ciMode {
			apt.indicator.UpdateStatus(fmt.Sprintf("%s: %s", phase.Name, phase.SubSteps[subStepIndex]))
		}
		apt.updateProgress()
	}
}

func (apt *AnalysisProgressTracker) CompletePhase() {
	if apt.currentPhase < len(apt.phases) {
		apt.phases[apt.currentPhase].Completed = true
		apt.updateProgress()
	}
}

func (apt *AnalysisProgressTracker) UpdateStatus(status string) {
	if !apt.ciMode {
		apt.indicator.UpdateStatus(status)
	}
}

func (apt *AnalysisProgressTracker) CompleteAnalysis(success bool) {
	apt.indicator.Complete(success)
}

func (apt *AnalysisProgressTracker) updateProgress() {
	totalProgress := 0
	totalWeight := 0

	for i, phase := range apt.phases {
		weight := phase.Weight
		totalWeight += weight

		if phase.Completed {
			totalProgress += weight
		} else if i == apt.currentPhase {
			// Partial progress for current phase
			if len(phase.SubSteps) > 0 {
				subProgress := (phase.CurrentStep * weight) / len(phase.SubSteps)
				totalProgress += subProgress
			}
		}
		// Past phases are already completed
	}

	apt.indicator.UpdateStep("Analysis in progress", totalProgress)
}

func (qd *QualityDisplay) getScoreColor(score float64) string {
	if score >= 9.0 {
		return "\033[32m" // Green
	} else if score >= 7.0 {
		return "\033[33m" // Yellow
	} else {
		return "\033[31m" // Red
	}
}

func (qd *QualityDisplay) getAgeColor(age time.Duration) string {
	if age < time.Hour {
		return "\033[32m" // Green - fresh
	} else if age < 4*time.Hour {
		return "\033[33m" // Yellow - acceptable
	} else {
		return "\033[31m" // Red - stale
	}
}

func (qd *QualityDisplay) getCoverageColor(coverage float64) string {
	if coverage >= 90.0 {
		return "\033[32m" // Green
	} else if coverage >= 75.0 {
		return "\033[33m" // Yellow
	} else {
		return "\033[31m" // Red
	}
}

func (qd *QualityDisplay) getConfidenceColor(confidence float64) string {
	if confidence >= 0.9 {
		return "\033[32m" // Green
	} else if confidence >= 0.7 {
		return "\033[33m" // Yellow
	} else {
		return "\033[31m" // Red
	}
}

func (qd *QualityDisplay) getSourceDescription(source string) string {
	descriptions := map[string]string{
		"hub":   "Hub Analysis - Comprehensive",
		"cache": "Cached Results - Fast",
		"local": "Local Analysis - Basic",
	}
	if desc, exists := descriptions[source]; exists {
		return desc
	}
	return source
}

func (qd *QualityDisplay) getPerformanceIndicator(source string) string {
	indicators := map[string]string{
		"hub":   "Fast (Hub-accelerated)",
		"cache": "Instant (Cached)",
		"local": "Variable (Local processing)",
	}
	if indicator, exists := indicators[source]; exists {
		return indicator
	}
	return "Standard"
}

func (qd *QualityDisplay) formatComponentName(component string) string {
	names := map[string]string{
		"analysis":      "Analysis Quality",
		"coverage":      "Code Coverage",
		"staleness":     "Result Freshness",
		"security_depth": "Security Depth",
		"creativity":    "Creative Quality",
		"accuracy":      "Accuracy",
	}
	if name, exists := names[component]; exists {
		return name
	}
	return strings.Title(strings.ReplaceAll(component, "_", " "))
}

func (qd *QualityDisplay) formatDuration(d time.Duration) string {
	if d < time.Minute {
		return "Just now"
	} else if d < time.Hour {
		return fmt.Sprintf("%.0f minutes ago", d.Minutes())
	} else if d < 24*time.Hour {
		return fmt.Sprintf("%.0f hours ago", d.Hours())
	} else {
		return fmt.Sprintf("%.0f days ago", d.Hours()/24)
	}
}

func (qd *QualityDisplay) getOverallStatus(result *QualityAnalysisResult) string {
	if result.Quality.Overall >= 8.0 {
		return "High-quality analysis complete"
	} else if result.Quality.Overall >= 6.0 {
		return "Analysis complete (consider quality improvements)"
	} else {
		return "Basic analysis complete - upgrade for better results"
	}
}

// =============================================================================
// üéØ USER GUIDANCE ENGINE (ISSUE DETECTION & RECOMMENDATIONS)
// =============================================================================

// UserGuidance provides intelligent guidance based on analysis results
type UserGuidance struct {
	IssueDetector *IssueDetector
	SolutionProvider *SolutionProvider
	ImprovementTracker *ImprovementTracker
}

func NewUserGuidance() *UserGuidance {
	return &UserGuidance{
		IssueDetector: NewIssueDetector(),
		SolutionProvider: NewSolutionProvider(),
		ImprovementTracker: NewImprovementTracker(),
	}
}

func (ug *UserGuidance) ProvideGuidance(result *QualityAnalysisResult) {
	issues := ug.IssueDetector.DetectIssues(result)

	if len(issues) == 0 {
		return // No guidance needed
	}

	fmt.Println("")
	fmt.Println("üöÄ Improvement Opportunities:")
	fmt.Println("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")

	for _, issue := range issues {
		solutions := ug.SolutionProvider.GetSolutions(issue)

		fmt.Printf("üìã %s\n", issue.Title)
		if issue.Description != "" {
			fmt.Printf("   %s\n", issue.Description)
		}

		fmt.Println("   üí° Solutions:")
		for _, solution := range solutions {
			fmt.Printf("   ‚Ä¢ %s\n", solution)
		}

		// Track that we showed this guidance
		ug.ImprovementTracker.RecordGuidanceShown(issue.ID)

		fmt.Println("")
	}

	fmt.Println("üí™ Run 'sentinel doctor' anytime to check your setup quality.")
}

// DetectedIssue represents a configuration or quality issue
type DetectedIssue struct {
	ID          string
	Title       string
	Description string
	Severity    string // "low", "medium", "high", "critical"
	Category    string // "configuration", "quality", "performance", "security"
}

// IssueDetector analyzes results to find improvement opportunities
type IssueDetector struct{}

func NewIssueDetector() *IssueDetector {
	return &IssueDetector{}
}

func (id *IssueDetector) DetectIssues(result *QualityAnalysisResult) []DetectedIssue {
	var issues []DetectedIssue

	quality := result.Quality

	// Configuration issues
	if quality.Source == "local" {
		issues = append(issues, DetectedIssue{
			ID: "hub-not-configured",
			Title: "Hub Not Configured",
			Description: "You're using basic local analysis. Configure Sentinel Hub for AI-powered comprehensive analysis.",
			Severity: "medium",
			Category: "configuration",
		})
	}

	// Quality issues
	if quality.Overall < 7.0 {
		issues = append(issues, DetectedIssue{
			ID: "low-quality-results",
			Title: "Suboptimal Analysis Quality",
			Description: "Your current setup provides basic analysis. Upgrade for more accurate and comprehensive results.",
			Severity: "low",
			Category: "quality",
		})
	}

	// Performance issues
	if quality.Source == "cache" && quality.Freshness > 8*time.Hour {
		issues = append(issues, DetectedIssue{
			ID: "stale-results",
			Title: "Using Stale Results",
			Description: "Analysis results are more than 8 hours old. Fresh analysis recommended.",
			Severity: "low",
			Category: "performance",
		})
	}

	// Coverage issues
	if quality.Coverage < 80.0 {
		issues = append(issues, DetectedIssue{
			ID: "incomplete-coverage",
			Title: "Incomplete Code Coverage",
			Description: "Analysis didn't cover the full codebase. Some files may have been skipped.",
			Severity: "medium",
			Category: "quality",
		})
	}

	// AI confidence issues
	if quality.Confidence < 0.75 && quality.Source == "hub" {
		issues = append(issues, DetectedIssue{
			ID: "low-ai-confidence",
			Title: "Low AI Analysis Confidence",
			Description: "AI-powered analysis confidence is below optimal threshold.",
			Severity: "medium",
			Category: "quality",
		})
	}

	// Degraded mode issues
	if degraded, exists := result.Metadata["degraded"]; exists && degraded.(bool) {
		issues = append(issues, DetectedIssue{
			ID: "running-degraded",
			Title: "Running in Degraded Mode",
			Description: "Analysis completed but with reduced quality due to configuration issues.",
			Severity: "high",
			Category: "configuration",
		})
	}

	return issues
}

// SolutionProvider offers specific solutions for detected issues
type SolutionProvider struct {
	solutions map[string][]string
}

func NewSolutionProvider() *SolutionProvider {
	return &SolutionProvider{
		solutions: map[string][]string{
			"hub-not-configured": {
				"Run 'sentinel setup' to configure your Hub connection interactively",
				"Set environment variables: export SENTINEL_HUB_URL=https://your-hub.com",
				"Create .sentinelsrc file with hub configuration",
				"Contact your administrator for Hub access details",
			},
			"low-quality-results": {
				"Configure Sentinel Hub for AI-powered analysis",
				"Enable deep analysis mode with --deep flag",
				"Update to latest Sentinel version for improved algorithms",
				"Review analysis configuration for completeness",
			},
			"stale-results": {
				"Run fresh analysis without --offline flag",
				"Clear analysis cache with 'sentinel cache clear'",
				"Set up automated analysis pipelines for regular scanning",
				"Configure shorter cache TTL for critical projects",
			},
			"incomplete-coverage": {
				"Use --deep flag for comprehensive file analysis",
				"Check file permissions and access rights",
				"Verify supported file types are included",
				"Review ignore patterns that might exclude files",
			},
			"low-ai-confidence": {
				"Ensure Hub has latest AI models and training data",
				"Provide more context through project documentation",
				"Use specific analysis types instead of general scanning",
				"Contact Hub administrator for AI model updates",
			},
			"running-degraded": {
				"Fix primary configuration issues (see above)",
				"Test Hub connectivity with 'sentinel doctor'",
				"Verify API key permissions and validity",
				"Check network connectivity to Hub service",
			},
		},
	}
}

func (sp *SolutionProvider) GetSolutions(issue DetectedIssue) []string {
	if solutions, exists := sp.solutions[issue.ID]; exists {
		return solutions
	}

	// Default solutions for unknown issues
	return []string{
		"Run 'sentinel doctor' for detailed diagnostics",
		"Check Sentinel documentation for configuration guidance",
		"Contact your team administrator for assistance",
		"Update to the latest Sentinel version",
	}
}

// =============================================================================
// LOCAL FALLBACK IMPLEMENTATIONS
// =============================================================================

// runLocalSecurityAudit provides basic local security analysis
func runLocalSecurityAudit() (interface{}, error) {
	args := os.Args[2:]
	ciMode := hasFlag(args, "--ci")

	// Determine codebase path (default to current directory)
	codebasePath := "."
	if len(args) > 0 && !strings.HasPrefix(args[0], "--") {
		codebasePath = args[0]
	}

	// Sanitize and validate codebase path
	codebasePath = sanitizePath(codebasePath)
	if !isValidPath(codebasePath) {
		return nil, fmt.Errorf("invalid codebase path: %s", codebasePath)
	}

	// Resolve absolute path
	absPath, err := filepath.Abs(codebasePath)
	if err != nil {
		absPath = codebasePath
	}

	return runAuditLocal(absPath, ciMode), nil
}

// runLocalSecurityAuditWithProgress provides local security analysis with progress tracking
func runLocalSecurityAuditWithProgress(progressTracker *ProgressTracker) (interface{}, error) {
	args := os.Args[2:]
	ciMode := hasFlag(args, "--ci")

	// Determine codebase path (default to current directory)
	codebasePath := "."
	if len(args) > 0 && !strings.HasPrefix(args[0], "--") {
		codebasePath = args[0]
	}

	// Sanitize and validate codebase path
	codebasePath = sanitizePath(codebasePath)
	if !isValidPath(codebasePath) {
		return nil, fmt.Errorf("invalid codebase path: %s", codebasePath)
	}

	// Resolve absolute path
	absPath, err := filepath.Abs(codebasePath)
	if err != nil {
		absPath = codebasePath
	}

	progressTracker.CompletePhase("init")
	progressTracker.StartPhase("scan")
	progressTracker.UpdateProgress("scan", "Scanning local codebase", fmt.Sprintf("Analyzing %s", absPath))

	// Run the actual local audit
	result := runAuditLocal(absPath, ciMode)

	progressTracker.CompletePhase("scan")
	progressTracker.StartPhase("analyze")
	progressTracker.UpdateProgress("analyze", "Processing local findings", fmt.Sprintf("%d issues found", len(result.Findings)))

	// Simulate some processing time for progress display
	time.Sleep(200 * time.Millisecond)

	progressTracker.CompletePhase("analyze")

	return result, nil
}

// runLocalPatternAnalysis provides basic local pattern analysis
func runLocalPatternAnalysis() (interface{}, error) {
	// Determine codebase path
	args := os.Args[2:]
	codebasePath := "."
	if len(args) > 0 && !strings.HasPrefix(args[0], "--") {
		codebasePath = args[0]
	}

	// Sanitize path
	codebasePath = sanitizePath(codebasePath)
	if !isValidPath(codebasePath) {
		return nil, fmt.Errorf("invalid codebase path: %s", codebasePath)
	}

	// Analyze patterns in the codebase
	patterns, language, framework := analyzeCodebasePatterns(codebasePath)

	result := map[string]interface{}{
		"patterns_found": len(patterns),
		"language": language,
		"framework": framework,
		"confidence": calculatePatternConfidence(patterns, language, framework),
		"patterns": patterns,
	}

	return result, nil
}

// analyzeCodebasePatterns performs basic pattern analysis on a codebase
func analyzeCodebasePatterns(codebasePath string) ([]string, string, string) {
	var patterns []string
	languageCounts := make(map[string]int)
	frameworkCounts := make(map[string]int)

	// Walk through the codebase
	filepath.Walk(codebasePath, func(path string, info os.FileInfo, err error) error {
		if err != nil || info.IsDir() {
			return nil
		}

		// Skip common non-code files and directories
		if shouldSkipFile(path) {
			return nil
		}

		// Detect language by file extension
		ext := strings.ToLower(filepath.Ext(path))
		switch ext {
		case ".go":
			languageCounts["Go"]++
			patterns = append(patterns, detectGoPatterns(path)...)
		case ".js", ".jsx", ".ts", ".tsx":
			languageCounts["JavaScript/TypeScript"]++
			patterns = append(patterns, detectJSPatterns(path)...)
		case ".py":
			languageCounts["Python"]++
			patterns = append(patterns, detectPythonPatterns(path)...)
		case ".java":
			languageCounts["Java"]++
			patterns = append(patterns, detectJavaPatterns(path)...)
		case ".cs":
			languageCounts["C#"]++
			patterns = append(patterns, detectCSharpPatterns(path)...)
		}

		// Detect frameworks by file/directory names
		dir := filepath.Base(filepath.Dir(path))
		file := strings.ToLower(info.Name())

		// Framework detection
		if strings.Contains(file, "package.json") || strings.Contains(dir, "node_modules") {
			frameworkCounts["Node.js"]++
		}
		if strings.Contains(file, "requirements.txt") || strings.Contains(file, "setup.py") {
			frameworkCounts["Python"]++
		}
		if strings.Contains(file, "go.mod") || strings.Contains(file, "go.sum") {
			frameworkCounts["Go Modules"]++
		}
		if strings.Contains(dir, "react") || strings.Contains(file, "react") {
			frameworkCounts["React"]++
		}
		if strings.Contains(dir, "vue") || strings.Contains(file, "vue") {
			frameworkCounts["Vue.js"]++
		}
		if strings.Contains(dir, "angular") || strings.Contains(file, "angular") {
			frameworkCounts["Angular"]++
		}

		return nil
	})

	// Determine primary language and framework
	primaryLanguage := getMostCommon(languageCounts, "Unknown")
	primaryFramework := getMostCommon(frameworkCounts, "None detected")

	return patterns, primaryLanguage, primaryFramework
}

// shouldSkipFile determines if a file should be skipped during pattern analysis
func shouldSkipFile(path string) bool {
	// Skip common non-code files and directories
	skipPatterns := []string{
		".git", ".svn", ".hg", ".DS_Store", "node_modules", "__pycache__",
		".next", ".nuxt", "dist", "build", "target", "bin", "obj",
		".vscode", ".idea", ".vs", "coverage", ".nyc_output",
	}

	for _, pattern := range skipPatterns {
		if strings.Contains(path, pattern) {
			return true
		}
	}

	// Skip by extension
	skipExts := []string{".log", ".lock", ".md", ".txt", ".json", ".yml", ".yaml", ".xml", ".html"}
	ext := strings.ToLower(filepath.Ext(path))
	for _, skipExt := range skipExts {
		if ext == skipExt {
			return true
		}
	}

	return false
}

// Pattern detection functions for different languages
func detectGoPatterns(path string) []string {
	var patterns []string
	content, err := os.ReadFile(path)
	if err != nil {
		return patterns
	}

	contentStr := string(content)

	// Common Go patterns
	if strings.Contains(contentStr, "goroutine") {
		patterns = append(patterns, "Concurrency (goroutines)")
	}
	if strings.Contains(contentStr, "channel") {
		patterns = append(patterns, "Channel-based communication")
	}
	if strings.Contains(contentStr, "interface{}") {
		patterns = append(patterns, "Empty interface usage")
	}
	if strings.Contains(contentStr, "context.Context") {
		patterns = append(patterns, "Context usage")
	}
	if strings.Contains(contentStr, "sync.Mutex") || strings.Contains(contentStr, "sync.RWMutex") {
		patterns = append(patterns, "Mutex synchronization")
	}

	return patterns
}

func detectJSPatterns(path string) []string {
	var patterns []string
	content, err := os.ReadFile(path)
	if err != nil {
		return patterns
	}

	contentStr := string(content)

	// Common JS/TS patterns
	if strings.Contains(contentStr, "async") && strings.Contains(contentStr, "await") {
		patterns = append(patterns, "Async/await patterns")
	}
	if strings.Contains(contentStr, "Promise") {
		patterns = append(patterns, "Promise usage")
	}
	if strings.Contains(contentStr, "useState") || strings.Contains(contentStr, "useEffect") {
		patterns = append(patterns, "React Hooks")
	}
	if strings.Contains(contentStr, "class") && strings.Contains(contentStr, "extends") {
		patterns = append(patterns, "Class inheritance")
	}
	if strings.Contains(contentStr, "import") && strings.Contains(contentStr, "from") {
		patterns = append(patterns, "ES6 modules")
	}

	return patterns
}

func detectPythonPatterns(path string) []string {
	var patterns []string
	content, err := os.ReadFile(path)
	if err != nil {
		return patterns
	}

	contentStr := string(content)

	// Common Python patterns
	if strings.Contains(contentStr, "def ") && strings.Contains(contentStr, "self") {
		patterns = append(patterns, "Object-oriented methods")
	}
	if strings.Contains(contentStr, "async def") || strings.Contains(contentStr, "await") {
		patterns = append(patterns, "Async programming")
	}
	if strings.Contains(contentStr, "with ") && strings.Contains(contentStr, " as ") {
		patterns = append(patterns, "Context managers")
	}
	if strings.Contains(contentStr, "list comprehension") || strings.Contains(contentStr, "[") && strings.Contains(contentStr, "for ") && strings.Contains(contentStr, " in ") {
		patterns = append(patterns, "List comprehensions")
	}
	if strings.Contains(contentStr, "decorator") || strings.Contains(contentStr, "@") {
		patterns = append(patterns, "Decorators")
	}

	return patterns
}

func detectJavaPatterns(path string) []string {
	var patterns []string
	content, err := os.ReadFile(path)
	if err != nil {
		return patterns
	}

	contentStr := string(content)

	// Common Java patterns
	if strings.Contains(contentStr, "public static void main") {
		patterns = append(patterns, "Main method")
	}
	if strings.Contains(contentStr, "implements") {
		patterns = append(patterns, "Interface implementation")
	}
	if strings.Contains(contentStr, "extends") {
		patterns = append(patterns, "Class inheritance")
	}
	if strings.Contains(contentStr, "synchronized") {
		patterns = append(patterns, "Synchronization")
	}
	if strings.Contains(contentStr, "try") && strings.Contains(contentStr, "catch") {
		patterns = append(patterns, "Exception handling")
	}

	return patterns
}

func detectCSharpPatterns(path string) []string {
	var patterns []string
	content, err := os.ReadFile(path)
	if err != nil {
		return patterns
	}

	contentStr := string(content)

	// Common C# patterns
	if strings.Contains(contentStr, "async") && strings.Contains(contentStr, "await") {
		patterns = append(patterns, "Async/await patterns")
	}
	if strings.Contains(contentStr, "using") && strings.Contains(contentStr, ";") {
		patterns = append(patterns, "Using statements")
	}
	if strings.Contains(contentStr, "interface") && strings.Contains(contentStr, "{") {
		patterns = append(patterns, "Interface definitions")
	}
	if strings.Contains(contentStr, "LINQ") || strings.Contains(contentStr, ".Where(") || strings.Contains(contentStr, ".Select(") {
		patterns = append(patterns, "LINQ queries")
	}
	if strings.Contains(contentStr, "lock") && strings.Contains(contentStr, "(") {
		patterns = append(patterns, "Lock statements")
	}

	return patterns
}

// getMostCommon finds the most common item in a map
func getMostCommon(counts map[string]int, defaultValue string) string {
	maxCount := 0
	mostCommon := defaultValue

	for item, count := range counts {
		if count > maxCount {
			maxCount = count
			mostCommon = item
		}
	}

	return mostCommon
}

// calculatePatternConfidence calculates confidence score based on patterns found
func calculatePatternConfidence(patterns []string, language, framework string) float64 {
	baseConfidence := 0.3

	// Language confidence
	if language != "Unknown" {
		baseConfidence += 0.3
	}

	// Framework confidence
	if framework != "None detected" {
		baseConfidence += 0.2
	}

	// Pattern count confidence
	if len(patterns) > 5 {
		baseConfidence += 0.2
	} else if len(patterns) > 2 {
		baseConfidence += 0.1
	}

	// Cap at 1.0
	if baseConfidence > 1.0 {
		baseConfidence = 1.0
	}

	return baseConfidence
}


// ImprovementTracker tracks user interactions with guidance
type ImprovementTracker struct {
	shownGuidance map[string]time.Time
	mu            sync.RWMutex
}

func NewImprovementTracker() *ImprovementTracker {
	return &ImprovementTracker{
		shownGuidance: make(map[string]time.Time),
	}
}

func (it *ImprovementTracker) RecordGuidanceShown(issueID string) {
	it.mu.Lock()
	defer it.mu.Unlock()
	it.shownGuidance[issueID] = time.Now()
}

func (it *ImprovementTracker) GetGuidanceHistory() map[string]time.Time {
	it.mu.RLock()
	defer it.mu.RUnlock()

	history := make(map[string]time.Time)
	for k, v := range it.shownGuidance {
		history[k] = v
	}
	return history
}

func (it *ImprovementTracker) ShouldShowGuidance(issueID string, cooldown time.Duration) bool {
	it.mu.RLock()
	defer it.mu.RUnlock()

	if lastShown, exists := it.shownGuidance[issueID]; exists {
		return time.Since(lastShown) > cooldown
	}
	return true // Never shown before
}

func runAudit() {
	// Parse flags
	args := os.Args[2:]
	ciMode := false
	offlineMode := false
	deepAnalysis := false
	vibeCheck := hasFlag(args, "--vibe-check")
	verbose := hasFlag(args, "--verbose")
	outputFormat := "text"
	outputFile := ""
	hubTimeout := 10 * time.Second
	maxHubRetries := 3
	
	for i, arg := range args {
		switch arg {
		case "--ci":
			ciMode = true
		case "--offline":
			offlineMode = true
		case "--deep":
			deepAnalysis = true
		case "--verbose":
			verbose = true
		case "--vibe-check":
			// Vibe check flag - would trigger additional analysis
		case "--vibe-only":
			// Vibe only flag - would do only vibe analysis
		case "--output":
			if i+1 < len(args) {
				outputFormat = args[i+1]
			}
		case "--output-file":
			if i+1 < len(args) {
				outputFile = args[i+1]
			}
		case "--hub-timeout":
			if i+1 < len(args) {
				if duration, err := time.ParseDuration(args[i+1]); err == nil {
					hubTimeout = duration
				}
			}
		case "--max-hub-retries":
			if i+1 < len(args) {
				if _, err := fmt.Sscanf(args[i+1], "%d", &maxHubRetries); err == nil {
					// maxHubRetries set
				}
			}
		}
	}
	
	// Handle offline mode directly (bypass fallback orchestrator)
	if offlineMode {
		// Initialize progress tracking and resource monitoring
		progressTracker := NewProgressTracker()
		progressDisplay := NewProgressDisplay(verbose, ciMode)
		progressTracker.AddListener(progressDisplay)

		fallbackOrchestrator := NewFallbackOrchestrator()
		resourceMonitor := fallbackOrchestrator.resourceMonitor

		// Initialize resource monitoring
		initialUsage := ResourceUsage{
			MemoryUsedMB: GetMemoryUsage(),
			CPUUsedPct:   GetCPUUsage(),
			TotalFiles:   0,
			TotalSizeMB:  0,
			ActiveOps:    1,
		}
		resourceMonitor.UpdateUsage(initialUsage)

		progressTracker.StartPhase("init")
		progressTracker.UpdateProgress("init", "Starting local analysis", "Offline mode enabled")

		result, err := runLocalSecurityAuditWithProgress(progressTracker)
		if err != nil {
			progressTracker.UpdateProgress("complete", fmt.Sprintf("Analysis failed: %s", err.Error()), "")
			fmt.Printf("‚ùå Local analysis failed: %s\n", err.Error())
			os.Exit(1)
		}

		// Update resource usage after analysis
		finalUsage := ResourceUsage{
			MemoryUsedMB: GetMemoryUsage(),
			CPUUsedPct:   GetCPUUsage(),
			TotalFiles:   1, // Simplified - would count actual files processed
			TotalSizeMB:  10, // Simplified - would calculate actual size
			ActiveOps:    0,
		}
		resourceMonitor.UpdateUsage(finalUsage)

		progressTracker.StartPhase("quality")
		progressTracker.UpdateProgress("quality", "Calculating quality metrics", "Local analysis complete")

		// Create quality result for local analysis
		quality := fallbackOrchestrator.calculateQualityScore(result, "local", "security-audit")

		progressTracker.CompletePhase("quality")
		progressTracker.CompletePhase("complete")

		qualityResult := &QualityAnalysisResult{
			Success:   true,
			Data:      result,
			Quality:   quality,
			Metadata:  map[string]interface{}{"source": "local", "fallback_used": false},
			Timestamp: time.Now(),
		}

		// Show final status
		progressDisplay.ShowFinalStatus()

		// Display quality information
		qualityDisplay := NewQualityDisplay(verbose, ciMode)
		qualityDisplay.ShowQualityReport(qualityResult)

		// Handle output formatting for offline mode
		if outputFile != "" {
			if err := saveOutputToFile(qualityResult, outputFile, outputFormat); err != nil {
				fmt.Printf("‚ùå Failed to save output: %s\n", err.Error())
				os.Exit(1)
			}
			fmt.Printf("üìÑ Results saved to: %s\n", outputFile)
		}

		// Exit with appropriate code based on audit result for offline mode
		auditResult, ok := qualityResult.Data.(*AuditResult)
		if ok && !auditResult.Success {
			if ciMode {
				fmt.Println("‚õî Audit FAILED. Build rejected.")
			} else {
				fmt.Println("‚õî Audit FAILED. Commit rejected.")
			}
			os.Exit(1)
		}

		if !ciMode && auditResult != nil && auditResult.Success {
			fmt.Println("‚úÖ Audit PASSED.")
		}
	} else {
		// Use fallback orchestrator for online mode
		fallbackOrchestrator := NewFallbackOrchestrator()
		qualityDisplay := NewQualityDisplay(verbose, ciMode)

		// Initialize progress tracking
		progressTracker := NewProgressTracker()
		progressDisplay := NewProgressDisplay(verbose, ciMode)
		progressTracker.AddListener(progressDisplay)

		// Execute analysis with quality tracking
		qualityResult, err := fallbackOrchestrator.ExecuteAnalysisWithProgress("security-audit", progressTracker, func() (interface{}, error) {
			return performSecurityAudit(false, deepAnalysis, vibeCheck, hubTimeout, maxHubRetries)
		})

		if err != nil {
			// Handle different types of errors
			switch e := err.(type) {
			case *CriticalConfigurationError:
				progressTracker.UpdateProgress("complete", "Configuration error encountered", e.Error())
				fmt.Printf("‚ùå Critical Configuration Error: %s\n", e.Error())
				fmt.Println("üí° Solutions:")
				for _, solution := range e.Solutions {
					fmt.Printf("‚Ä¢ %s\n", solution)
				}
				os.Exit(1)
			case *NoSourceAvailableError:
				progressTracker.UpdateProgress("complete", "Analysis failed", e.Error())
				fmt.Printf("‚ùå Analysis Failed: %s\n", e.Error())
				fmt.Println("üí° Solutions:")
				for _, solution := range e.Solutions {
					fmt.Printf("‚Ä¢ %s\n", solution)
				}
				os.Exit(1)
			default:
				progressTracker.UpdateProgress("complete", "Unexpected error", err.Error())
				fmt.Printf("‚ùå Unexpected Error: %s\n", err.Error())
				os.Exit(1)
			}
		}

		// Show final status
		progressDisplay.ShowFinalStatus()

		// Display quality information
		qualityDisplay.ShowQualityReport(qualityResult)

		// Handle output formatting
		if outputFile != "" {
			if err := saveOutputToFile(qualityResult, outputFile, outputFormat); err != nil {
				fmt.Printf("‚ùå Failed to save output: %s\n", err.Error())
				os.Exit(1)
			}
			fmt.Printf("üìÑ Results saved to: %s\n", outputFile)
		}

		// Exit with appropriate code based on audit result
		auditResult, ok := qualityResult.Data.(*AuditResult)
		if ok && !auditResult.Success {
			if ciMode {
				fmt.Println("‚õî Audit FAILED. Build rejected.")
			} else {
				fmt.Println("‚õî Audit FAILED. Commit rejected.")
			}
			os.Exit(1)
		}

		if !ciMode && auditResult != nil && auditResult.Success {
			fmt.Println("‚úÖ Audit PASSED.")
		}
	}
}

// performSecurityAudit executes the actual security audit with current parameters
func performSecurityAudit(offlineMode, deepAnalysis, vibeCheck bool, hubTimeout time.Duration, maxHubRetries int) (interface{}, error) {
	args := os.Args[2:]
	ciMode := hasFlag(args, "--ci")
	
	// Determine codebase path (default to current directory)
	codebasePath := "."
	if len(args) > 0 && !strings.HasPrefix(args[0], "--") {
		codebasePath = args[0]
	}
	
	// Sanitize and validate codebase path (Phase E: Security Hardening)
	codebasePath = sanitizePath(codebasePath)
	if !isValidPath(codebasePath) {
		return nil, fmt.Errorf("invalid codebase path: %s", codebasePath)
	}
	
	// Resolve absolute path
	absPath, err := filepath.Abs(codebasePath)
	if err != nil {
		absPath = codebasePath
	}
	
	// Run audit (Hub integration with fallback to local)
	var result AuditResult
	if !offlineMode {
		result = runAuditWithHub(absPath, hubTimeout, maxHubRetries, ciMode)
	} else {
		result = runAuditLocal(absPath, ciMode)
	}
	
	// If deep analysis requested, add additional checks
	if deepAnalysis && !ciMode {
		fmt.Println("üîç Performing deep analysis...")
		// Additional deep analysis logic would go here
	}

	// If vibe check requested, add vibe analysis
	if vibeCheck && !ciMode {
		fmt.Println("üé® Performing vibe analysis...")
		// Additional vibe analysis logic would go here
	}

	return &result, nil
}

// performSecurityAuditWithProgress executes security audit with progress tracking
func performSecurityAuditWithProgress(offlineMode, deepAnalysis, vibeCheck bool, hubTimeout time.Duration, maxHubRetries int, progressTracker *AnalysisProgressTracker) (interface{}, error) {
	args := os.Args[2:]
	ciMode := hasFlag(args, "--ci")

	progressTracker.UpdateStatus("Initializing analysis parameters")

	// Determine codebase path (default to current directory)
	codebasePath := "."
	if len(args) > 0 && !strings.HasPrefix(args[0], "--") {
		codebasePath = args[0]
	}

	// Sanitize and validate codebase path
	codebasePath = sanitizePath(codebasePath)
	if !isValidPath(codebasePath) {
		return nil, fmt.Errorf("invalid codebase path: %s", codebasePath)
	}

	// Resolve absolute path
	absPath, err := filepath.Abs(codebasePath)
	if err != nil {
		absPath = codebasePath
	}

	if !offlineMode {
		progressTracker.UpdateStatus("Starting Hub-based security analysis")
		result := runAuditWithHub(absPath, hubTimeout, maxHubRetries, ciMode)
		progressTracker.UpdateStatus("Hub analysis completed, processing results")
		return &result, nil
		} else {
		progressTracker.UpdateStatus("Starting local security analysis")
		result := runAuditLocal(absPath, ciMode)
		progressTracker.UpdateStatus("Local analysis completed, processing results")
		return &result, nil
	}
}

// saveOutputToFile saves analysis results to a file in the specified format
func saveOutputToFile(result *QualityAnalysisResult, outputFile, outputFormat string) error {
	var output []byte
	var err error

	switch outputFormat {
	case "json":
		output, err = json.MarshalIndent(result, "", "  ")
	case "text":
		output = []byte(fmt.Sprintf("Quality Score: %.1f/10\nSource: %s\nCoverage: %.0f%%\n",
			result.Quality.Overall, result.Quality.Source, result.Quality.Coverage))
	default:
		return fmt.Errorf("unsupported output format: %s", outputFormat)
	}

	if err != nil {
		return err
	}

	return os.WriteFile(outputFile, output, 0644)
}

// runAuditLocal performs local scanning using Go-native file walking
func runAuditLocal(codebasePath string, ciMode bool) AuditResult {
	result := AuditResult{
		Success:   true,
		Findings:  []AuditFinding{},
		Summary:   make(map[string]int),
		Timestamp: time.Now().Format(time.RFC3339),
	}

	// Load config for scan directories
	config := loadConfig()

	// Determine scan directories - use config if available, otherwise default to codebasePath
	scanDirs := []string{codebasePath}
	if config != nil && len(config.ScanDirs) > 0 {
		scanDirs = config.ScanDirs
		if !ciMode {
			fmt.Printf("‚ÑπÔ∏è  Using configured scan directories: %v\n", scanDirs)
		}
	} else {
		if !ciMode {
			fmt.Printf("‚ÑπÔ∏è  Using default scan directory: %s\n", codebasePath)
		}
	}
	
	// Define scan patterns
	patterns := []struct {
		name     string
		pattern  *regexp.Regexp
		severity string
		message  string
	}{
		{
			name:     "secrets",
			pattern:  regexp.MustCompile(`(?i)(ey|api[_-]?key|secret|password|token)\s*[=:]\s*["']?[a-zA-Z0-9]{20,}`),
			severity: "critical",
			message:  "Potential secret or API key detected",
		},
		{
			name:     "debug",
			pattern:  regexp.MustCompile(`console\.(log|debug|info|warn|error)`),
			severity: "warning",
			message:  "console.log statement detected",
		},
		{
			name:     "sql_safety",
			pattern:  regexp.MustCompile(`(?i)NOLOCK`),
			severity: "critical",
			message:  "MSSQL NOLOCK detected (unsafe)",
		},
		{
			name:     "sql_injection",
			pattern:  regexp.MustCompile(`\$_[A-Z]+\[`),
			severity: "critical",
			message:  "Potential SQL injection vulnerability - direct use of user input",
		},
		{
			name:     "eval_usage",
			pattern:  regexp.MustCompile(`\beval\b`),
			severity: "critical",
			message:  "Code injection vulnerability - eval() usage detected",
		},
		{
			name:     "nosql_injection",
			pattern:  regexp.MustCompile(`(?i)\$where`),
			severity: "critical",
			message:  "NoSQL injection vulnerability - $where usage detected",
		},
		{
			name:     "unquoted_variables",
			pattern:  regexp.MustCompile(`\$\{[a-zA-Z_][a-zA-Z0-9_]*\}`),
			severity: "warning",
			message:  "Unquoted variable expansion detected",
		},
	}
	
	// Scan files in all configured directories
	for _, scanDir := range scanDirs {
		err := filepath.Walk(scanDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return nil // Skip files we can't read
		}
		
		// Skip directories and non-code files
		if info.IsDir() {
			// Skip common ignore directories
			if strings.Contains(path, ".git") || strings.Contains(path, "node_modules") ||
				strings.Contains(path, "vendor") || strings.Contains(path, ".next") ||
				strings.Contains(path, "dist") || strings.Contains(path, "build") {
				return filepath.SkipDir
			}
			return nil
		}
		
		// Only scan code files
		ext := filepath.Ext(path)
		codeExts := map[string]bool{
			".js": true, ".ts": true, ".jsx": true, ".tsx": true,
			".go": true, ".py": true, ".java": true, ".cs": true,
			".php": true, ".rb": true, ".sql": true, ".sh": true,
		}
		if !codeExts[ext] {
			return nil
		}
		
		// Read file content
		content, err := os.ReadFile(path)
		if err != nil {
			return nil // Skip files we can't read
		}
		
		// Check each pattern
		lines := strings.Split(string(content), "\n")
		for lineNum, line := range lines {
			for _, p := range patterns {
				if p.pattern.MatchString(line) {
					// Calculate relative path
					relPath, _ := filepath.Rel(codebasePath, path)
					if relPath == "" {
						relPath = path
					}
					
					finding := AuditFinding{
						Type:     p.name,
						Severity: p.severity,
						File:     relPath,
						Line:     lineNum + 1,
						Message:  p.message,
						Pattern:  line,
					}
					result.Findings = append(result.Findings, finding)
					result.Summary[p.name]++
					
					if p.severity == "critical" {
						result.Success = false
					}
				}
			}
		}
		
		return nil
	})
	
	if err != nil {
			// Log error but continue with next directory
		if !ciMode {
				fmt.Printf("‚ö†Ô∏è  Warning: Some files in %s could not be scanned: %v\n", scanDir, err)
			}
		}
	}
	
	return result
}

// CacheEntry stores cached Hub responses (Phase F: Performance)
type CacheEntry struct {
	Data      AuditResult
	Timestamp time.Time
	TTL       time.Duration
}

// MCPCacheEntry stores cached MCP tool responses (Phase F: Performance)
type MCPCacheEntry struct {
	Data      map[string]interface{}
	Timestamp time.Time
	TTL       time.Duration
}

var (
	hubResponseCache = make(map[string]*CacheEntry)
	mcpResponseCache = make(map[string]*MCPCacheEntry)
	cacheMutex       sync.RWMutex
	mcpCacheMutex    sync.RWMutex
)

// getCachedResult retrieves cached result if still valid (Phase F: Graceful Degradation)
func getCachedResult(cacheKey string) (AuditResult, bool) {
	cacheMutex.RLock()
	defer cacheMutex.RUnlock()
	
	entry, exists := hubResponseCache[cacheKey]
	if !exists {
		return AuditResult{}, false
	}
	
	// Check if cache entry is still valid
	if time.Since(entry.Timestamp) > entry.TTL {
		return AuditResult{}, false
	}
	
	return entry.Data, true
}

// setCachedResult stores result in cache (Phase F: Graceful Degradation)
func setCachedResult(cacheKey string, result AuditResult, ttl time.Duration) {
	cacheMutex.Lock()
	defer cacheMutex.Unlock()
	
	hubResponseCache[cacheKey] = &CacheEntry{
		Data:      result,
		Timestamp: time.Now(),
		TTL:       ttl,
	}
}

// getCachedMCPResult retrieves cached MCP result if still valid (Phase F: Caching)
func getCachedMCPResult(cacheKey string) (map[string]interface{}, bool) {
	mcpCacheMutex.RLock()
	defer mcpCacheMutex.RUnlock()
	
	entry, exists := mcpResponseCache[cacheKey]
	if !exists {
		return nil, false
	}
	
	// Check if cache entry is still valid
	if time.Since(entry.Timestamp) > entry.TTL {
		return nil, false
	}
	
	return entry.Data, true
}

// setCachedMCPResult stores MCP result in cache (Phase F: Caching)
func setCachedMCPResult(cacheKey string, result map[string]interface{}, ttl time.Duration) {
	mcpCacheMutex.Lock()
	defer mcpCacheMutex.Unlock()
	
	mcpResponseCache[cacheKey] = &MCPCacheEntry{
		Data:      result,
		Timestamp: time.Now(),
		TTL:       ttl,
	}
}

// runAuditWithHub attempts Hub API integration with fallback to local scanning (Phase F: Enhanced)
func runAuditWithHub(codebasePath string, timeout time.Duration, maxRetries int, ciMode bool) AuditResult {
	config := loadConfig()
	
	// Check if Hub is configured
	if config.HubURL == "" || config.APIKey == "" {
		if !ciMode {
			fmt.Println("‚ö†Ô∏è  Hub not configured, falling back to local scanning...")
		}
		return runAuditLocal(codebasePath, ciMode)
	}
	
	// Check cache first (Phase F: Graceful Degradation)
	cacheKey := fmt.Sprintf("audit:%s", codebasePath)
	if cachedResult, found := getCachedResult(cacheKey); found {
		if !ciMode {
			fmt.Println("‚ÑπÔ∏è  Using cached audit results...")
		}
		return cachedResult
	}
	
	// Try Hub comprehensive analysis endpoint
	hubURL := config.HubURL + "/api/v1/analyze/comprehensive"
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	requestBody := map[string]interface{}{
		"codebasePath": codebasePath,
		"mode":         "auto",
		"depth":        "medium",
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		if !ciMode {
			fmt.Println("‚ö†Ô∏è  Failed to prepare Hub request, falling back to local scanning...")
		}
		result := runAuditLocal(codebasePath, ciMode)
		// Cache local result as fallback (Phase F: Graceful Degradation)
		setCachedResult(cacheKey, result, 5*time.Minute)
		return result
	}
	
	// Send request with timeout
	ctx, cancel := context.WithTimeout(context.Background(), timeout)
	defer cancel()
	
	req, err := http.NewRequestWithContext(ctx, "POST", hubURL, bytes.NewReader(jsonBody))
	if err != nil {
		if !ciMode {
			fmt.Println("‚ö†Ô∏è  Failed to create Hub request, falling back to local scanning...")
		}
		result := runAuditLocal(codebasePath, ciMode)
		setCachedResult(cacheKey, result, 5*time.Minute)
		return result
	}
	
	for k, v := range headers {
		req.Header.Set(k, v)
	}
	
	client := &http.Client{Timeout: timeout}
	resp, err := client.Do(req)
	if err != nil {
		// Hub unavailable - use cached result if available, otherwise fallback to local
		if cachedResult, found := getCachedResult(cacheKey + ":last"); found {
			if !ciMode {
				fmt.Println("‚ö†Ô∏è  Hub unavailable, using last successful cached result...")
			}
			return cachedResult
		}
		
		if !ciMode {
			fmt.Println("‚ö†Ô∏è  Hub unavailable, falling back to local scanning...")
		}
		result := runAuditLocal(codebasePath, ciMode)
		setCachedResult(cacheKey, result, 5*time.Minute)
		return result
	}
	defer resp.Body.Close()
	
	// Parse Hub response
	if resp.StatusCode == http.StatusOK {
		var hubResponse map[string]interface{}
		if err := json.NewDecoder(resp.Body).Decode(&hubResponse); err == nil {
			// Convert Hub response to AuditResult
			result := convertHubResponseToAuditResult(hubResponse, codebasePath)
			
			// Cache successful result (Phase F: Graceful Degradation)
			setCachedResult(cacheKey, result, 10*time.Minute)
			setCachedResult(cacheKey+":last", result, 24*time.Hour) // Keep last successful for 24h
			
			return result
		}
	}
	
	// Hub returned error - use cached result if available, otherwise fallback to local
	if cachedResult, found := getCachedResult(cacheKey + ":last"); found {
		if !ciMode {
			fmt.Println("‚ö†Ô∏è  Hub returned error, using last successful cached result...")
		}
		return cachedResult
	}
	
	if !ciMode {
		fmt.Println("‚ö†Ô∏è  Hub returned error, falling back to local scanning...")
	}
	result := runAuditLocal(codebasePath, ciMode)
	setCachedResult(cacheKey, result, 5*time.Minute)
	return result
}

// convertHubResponseToAuditResult converts Hub API response to AuditResult format
func convertHubResponseToAuditResult(hubResponse map[string]interface{}, codebasePath string) AuditResult {
	result := AuditResult{
		Success:   true,
		Findings:  []AuditFinding{},
		Summary:   make(map[string]int),
		Timestamp: time.Now().Format(time.RFC3339),
	}
	
	// Extract findings from Hub response
	if findings, ok := hubResponse["findings"].([]interface{}); ok {
		for _, f := range findings {
			if findingMap, ok := f.(map[string]interface{}); ok {
				finding := AuditFinding{
					Type:     getString(findingMap, "type", "unknown"),
					Severity: getString(findingMap, "severity", "warning"),
					File:     getString(findingMap, "file", ""),
					Line:     getInt(findingMap, "line", 0),
					Message:  getString(findingMap, "message", ""),
					Pattern:  getString(findingMap, "pattern", ""),
				}
				result.Findings = append(result.Findings, finding)
				result.Summary[finding.Type]++
				
				if finding.Severity == "critical" {
					result.Success = false
				}
			}
		}
	}
	
	return result
}

// Helper functions for type conversion
func getString(m map[string]interface{}, key string, defaultValue string) string {
	if v, ok := m[key].(string); ok {
		return v
	}
	return defaultValue
}

func getInt(m map[string]interface{}, key string, defaultValue int) int {
	if v, ok := m[key].(float64); ok {
		return int(v)
	}
	return defaultValue
}

func getFloat(m map[string]interface{}, key string, defaultValue float64) float64 {
	if v, ok := m[key].(float64); ok {
		return v
	}
	return defaultValue
}

func getStatusIcon(status string) string {
	icons := map[string]string{
		"completed":   "‚úÖ",
		"in_progress": "üîÑ",
		"pending":     "‚è≥",
		"blocked":     "üö´",
	}
	if icon, ok := icons[status]; ok {
		return icon
	}
	return "‚ùì"
}

func getPriorityIcon(priority string) string {
	icons := map[string]string{
		"critical": "üî¥",
		"high":     "üü†",
		"medium":   "üü°",
		"low":      "‚ö™",
	}
	if icon, ok := icons[priority]; ok {
		return icon
	}
	return "‚ö™"
}

// =============================================================================
// STRUCTURED LOGGING (Phase G: Logging and Monitoring)
// =============================================================================

// LogLevel represents the severity of a log message
type LogLevel int

const (
	LogLevelDebug LogLevel = iota
	LogLevelInfo
	LogLevelWarn
	LogLevelError
)

var (
	logLevel      LogLevel = LogLevelInfo
	logFormat     string   = "text" // "text" or "json"
	logOutputFile string   = ""     // Empty means stdout/stderr
	logFile       *os.File = nil
	logMutex      sync.Mutex
)

// initLogging initializes logging based on environment variables
func initLogging() {
	// Set log level from environment
	if level := os.Getenv("SENTINEL_LOG_LEVEL"); level != "" {
		switch strings.ToLower(level) {
		case "debug":
			logLevel = LogLevelDebug
		case "info":
			logLevel = LogLevelInfo
		case "warn", "warning":
			logLevel = LogLevelWarn
		case "error":
			logLevel = LogLevelError
		}
	}

	// Set log format from environment
	if format := os.Getenv("SENTINEL_LOG_FORMAT"); format != "" {
		if format == "json" {
			logFormat = "json"
		}
	}

	// Set log file from environment
	if file := os.Getenv("SENTINEL_LOG_FILE"); file != "" {
		logOutputFile = file
		if f, err := os.OpenFile(file, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644); err == nil {
			logFile = f
		}
	}
}

// logMessage writes a structured log message
func logMessage(level LogLevel, message string, fields map[string]interface{}) {
	if level < logLevel {
		return // Skip if below current log level
	}

	logMutex.Lock()
	defer logMutex.Unlock()

	writer := os.Stderr
	if logFile != nil {
		writer = logFile
	}

	timestamp := time.Now().Format(time.RFC3339)
	levelStr := []string{"DEBUG", "INFO", "WARN", "ERROR"}[level]

	if logFormat == "json" {
		// JSON format
		logEntry := map[string]interface{}{
			"timestamp": timestamp,
			"level":     levelStr,
			"message":   message,
		}
		for k, v := range fields {
			logEntry[k] = v
		}
		jsonData, _ := json.Marshal(logEntry)
		fmt.Fprintf(writer, "%s\n", jsonData)
		} else {
		// Text format
		prefix := fmt.Sprintf("[%s] %s: ", timestamp, levelStr)
		fmt.Fprintf(writer, "%s%s", prefix, message)
		if len(fields) > 0 {
			for k, v := range fields {
				fmt.Fprintf(writer, " %s=%v", k, v)
			}
		}
		fmt.Fprintf(writer, "\n")
	}
}

// LogDebug logs a debug message
func LogDebug(message string, fields map[string]interface{}) {
	logMessage(LogLevelDebug, message, fields)
}

// LogInfo logs an info message
func LogInfo(message string, fields map[string]interface{}) {
	logMessage(LogLevelInfo, message, fields)
}

// LogWarn logs a warning message
func LogWarn(message string, fields map[string]interface{}) {
	logMessage(LogLevelWarn, message, fields)
}

// LogError logs an error message
func LogError(message string, fields map[string]interface{}) {
	logMessage(LogLevelError, message, fields)
}

// sanitizePath sanitizes a file path to prevent directory traversal attacks
func sanitizePath(p string) string {
	// Remove any ".." to prevent directory traversal
	return filepath.Clean(p)
}

// isValidPath validates that a path is safe to use
func isValidPath(p string) bool {
	// Check if path is absolute or relative and does not contain ".." after cleaning
	if filepath.IsAbs(p) {
		return true
	}
	// For relative paths, ensure it's within the current working directory or a subdirectory
	cleanPath := filepath.Clean(p)
	return !strings.HasPrefix(cleanPath, "../") && cleanPath != ".."
}

// sanitizeString sanitizes a string to prevent injection attacks
func sanitizeString(s string) string {
	// Basic sanitization: trim spaces, remove control characters, limit length
	s = strings.TrimSpace(s)
	s = strings.Map(func(r rune) rune {
		if r >= 0x20 && r < 0x7F { // Printable ASCII characters
			return r
		}
		return -1 // Remove other characters
	}, s)
	if len(s) > 1024 { // Limit string length to prevent abuse
		s = s[:1024]
	}
	return s
}

// getIntOrDefault safely extracts an integer value from interface{} with default fallback
func getIntOrDefault(val interface{}, defaultVal int) int {
	if val == nil {
		return defaultVal
	}
	if f, ok := val.(float64); ok {
		return int(f)
	}
	if i, ok := val.(int); ok {
		return i
	}
	return defaultVal
}

// displayAuditResults formats and displays audit results
func displayAuditResults(result AuditResult, format, outputFile string, ciMode bool) {
	switch format {
	case "json":
		jsonOutput, err := json.MarshalIndent(result, "", "  ")
		if err != nil {
			fmt.Printf("‚ùå Error formatting JSON: %v\n", err)
			return
		}
		if outputFile != "" {
			os.WriteFile(outputFile, jsonOutput, 0644)
			if !ciMode {
				fmt.Printf("‚úÖ Report saved to %s\n", outputFile)
			}
		} else {
			fmt.Println(string(jsonOutput))
		}
		return
		
	case "html":
		htmlOutput := formatAuditResultsHTML(result)
		if outputFile != "" {
			os.WriteFile(outputFile, []byte(htmlOutput), 0644)
			if !ciMode {
				fmt.Printf("‚úÖ Report saved to %s\n", outputFile)
			}
		} else {
			fmt.Println(htmlOutput)
		}
		return
		
	case "markdown":
		markdownOutput := formatAuditResultsMarkdown(result)
		if outputFile != "" {
			os.WriteFile(outputFile, []byte(markdownOutput), 0644)
			if !ciMode {
				fmt.Printf("‚úÖ Report saved to %s\n", outputFile)
			}
		} else {
			fmt.Println(markdownOutput)
		}
		return
		
	default:
		// Text format (default)
		formatAuditResultsText(result, ciMode)
	}
}

// formatAuditResultsText formats results as human-readable text
func formatAuditResultsText(result AuditResult, ciMode bool) {
	if len(result.Findings) == 0 {
		return // Already printed "‚úÖ Audit PASSED" in runAudit()
	}
	
	// Group findings by type
	findingsByType := make(map[string][]AuditFinding)
	for _, finding := range result.Findings {
		findingsByType[finding.Type] = append(findingsByType[finding.Type], finding)
	}
	
	// Display findings grouped by type
	for _, findingType := range []string{"secrets", "sql_safety", "debug", "sql_injection", "eval_usage", "nosql_injection", "unquoted_variables"} {
		if findings, ok := findingsByType[findingType]; ok {
			severity := "‚ö†Ô∏è"
			if findings[0].Severity == "critical" {
				severity = "‚ùå"
			}
			
		severityText := "WARNING"
		if findings[0].Severity == "critical" {
			severityText = "CRITICAL"
		}

		fmt.Printf("%s %s: %s found.\n", severity, severityText, strings.Title(strings.ReplaceAll(findingType, "_", " ")))
			
			// Show first few findings
			maxShow := 5
			if ciMode {
				maxShow = 10
			}
			for i, finding := range findings {
				if i >= maxShow {
					fmt.Printf("  ... and %d more\n", len(findings)-maxShow)
					break
				}
				fmt.Printf("  %s:%d - %s\n", finding.File, finding.Line, finding.Message)
			}
		}
	}
}

// formatAuditResultsHTML formats results as HTML
func formatAuditResultsHTML(result AuditResult) string {
	var html strings.Builder
	html.WriteString("<!DOCTYPE html>\n<html><head><title>Sentinel Audit Report</title>")
	html.WriteString("<style>body{font-family:Arial,sans-serif;margin:20px;}h1{color:#333;}")
	html.WriteString(".finding{background:#f5f5f5;padding:10px;margin:5px 0;border-left:3px solid #ccc;}")
	html.WriteString(".critical{border-left-color:#d32f2f;}.warning{border-left-color:#f57c00;}")
	html.WriteString("</style></head><body>")
	html.WriteString("<h1>Sentinel Audit Report</h1>")
	html.WriteString(fmt.Sprintf("<p><strong>Status:</strong> %s</p>", map[bool]string{true: "‚úÖ PASSED", false: "‚ùå FAILED"}[result.Success]))
	html.WriteString(fmt.Sprintf("<p><strong>Timestamp:</strong> %s</p>", result.Timestamp))
	html.WriteString(fmt.Sprintf("<p><strong>Total Findings:</strong> %d</p>", len(result.Findings)))
	
	html.WriteString("<h2>Findings</h2>")
	for _, finding := range result.Findings {
		class := "warning"
		if finding.Severity == "critical" {
			class = "critical"
		}
		html.WriteString(fmt.Sprintf("<div class=\"finding %s\">", class))
		html.WriteString(fmt.Sprintf("<strong>%s</strong> (%s) - %s:%d<br>", finding.Message, finding.Severity, finding.File, finding.Line))
		if finding.Pattern != "" {
			html.WriteString(fmt.Sprintf("<code>%s</code>", finding.Pattern))
		}
		html.WriteString("</div>")
	}
	
	html.WriteString("</body></html>")
	return html.String()
}

// formatAuditResultsMarkdown formats results as Markdown
func formatAuditResultsMarkdown(result AuditResult) string {
	var md strings.Builder
	md.WriteString("# Sentinel Audit Report\n\n")
	md.WriteString(fmt.Sprintf("**Status:** %s\n\n", map[bool]string{true: "‚úÖ PASSED", false: "‚ùå FAILED"}[result.Success]))
	md.WriteString(fmt.Sprintf("**Timestamp:** %s\n\n", result.Timestamp))
	md.WriteString(fmt.Sprintf("**Total Findings:** %d\n\n", len(result.Findings)))
	
	md.WriteString("## Findings\n\n")
	for _, finding := range result.Findings {
		severity := "‚ö†Ô∏è"
		if finding.Severity == "critical" {
			severity = "‚ùå"
		}
		md.WriteString(fmt.Sprintf("### %s %s\n\n", severity, finding.Message))
		md.WriteString(fmt.Sprintf("- **File:** %s\n", finding.File))
		md.WriteString(fmt.Sprintf("- **Line:** %d\n", finding.Line))
		md.WriteString(fmt.Sprintf("- **Severity:** %s\n", finding.Severity))
		if finding.Pattern != "" {
			md.WriteString(fmt.Sprintf("- **Pattern:** `%s`\n", finding.Pattern))
		}
		md.WriteString("\n")
	}
	
	return md.String()
}

func runScribe() {
	// The Auto-Docs Engine
	cmd := exec.Command("sh", "-c", "find . -maxdepth 3 -not -path '*/.*' -not -path './node_modules*'")
	out, _ := cmd.Output()
	writeFile("docs/knowledge/file-structure.txt", string(out))
	fmt.Println("‚úÖ Context Map Updated.")
}

func runRefactor() {
	// NOTE: This feature is not yet implemented.
	// The refactor command is documented but functionality is deferred to a future phase.
	fmt.Println("‚ö†Ô∏è  Sentinel: Refactoring feature is not yet implemented.")
	fmt.Println("   This command is reserved for future legacy code migration functionality.")
	fmt.Println("   See IMPLEMENTATION_ROADMAP.md for planned features.")
}

// =============================================================================
// HTTP CLIENT FOR HUB COMMUNICATION (Phase 11)
// =============================================================================

type Config struct {
	HubURL    string
	APIKey    string
	ScanDirs  []string
	ExcludePaths []string
	SeverityLevels map[string]string
	FileSizeConfig FileSizeConfig
}

type FileSizeConfig struct {
	MaxFileSize     int64
	Thresholds      FileSizeThresholds
	SkipLargeFiles  bool
}

type FileSizeThresholds struct {
	WarningSize  int64
	CriticalSize int64
	SkipSize     int64
}

// =============================================================================
// MCP PROTOCOL TYPES (Phase 14B)
// =============================================================================

// MCPRequest represents a JSON-RPC 2.0 request
type MCPRequest struct {
	JSONRPC string          `json:"jsonrpc"` // "2.0"
	ID      interface{}     `json:"id"`
	Method  string          `json:"method"`
	Params  json.RawMessage `json:"params,omitempty"`
}

// MCPResponse represents a JSON-RPC 2.0 response
type MCPResponse struct {
	JSONRPC string      `json:"jsonrpc"` // "2.0"
	ID      interface{} `json:"id"`
	Result  interface{} `json:"result,omitempty"`
	Error   *MCPError   `json:"error,omitempty"`
}

// MCPError represents a JSON-RPC 2.0 error
type MCPError struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    interface{} `json:"data,omitempty"`
}

// InitializeParams represents MCP initialize request parameters
type InitializeParams struct {
	ProtocolVersion string                 `json:"protocolVersion"`
	Capabilities    map[string]interface{} `json:"capabilities"`
	ClientInfo      map[string]string      `json:"clientInfo,omitempty"`
}

// InitializeResult represents MCP initialize response
type InitializeResult struct {
	ProtocolVersion string                 `json:"protocolVersion"`
	Capabilities    map[string]interface{} `json:"capabilities"`
	ServerInfo      map[string]string      `json:"serverInfo"`
}

// ToolCallParams represents MCP tool call parameters
type ToolCallParams struct {
	Name      string                 `json:"name"`
	Arguments map[string]interface{} `json:"arguments"`
}

// MCPTool represents a registered MCP tool
type MCPTool struct {
	Name        string                 `json:"name"`
	Description string                 `json:"description"`
	InputSchema map[string]interface{} `json:"inputSchema"`
}

// MCP Error Code Constants
const (
	// JSON-RPC 2.0 Standard Errors
	ParseErrorCode     = -32700  // Invalid JSON was received
	InvalidRequestCode = -32600  // The JSON sent is not a valid Request object
	MethodNotFoundCode = -32601  // The method does not exist or is not available
	InvalidParamsCode  = -32602  // Invalid method parameter(s)
	InternalErrorCode  = -32603  // Internal JSON-RPC error

	// Custom MCP Errors - Enhanced for Phase 2
	HubUnavailableCode     = -32000  // Hub service is not available
	HubTimeoutCode         = -32001  // Hub request timed out
	ConfigErrorCode        = -32002  // Configuration error
	ServerOverloadedCode   = -32003  // Server is overloaded
	RequestTimeoutCode     = -32004  // Request processing timed out
	ResourceExhaustedCode  = -32005  // Server resources exhausted
	InvalidToolNameCode    = -32006  // Invalid tool name specified
	ToolExecutionErrorCode = -32007  // Tool execution failed
	MessageTooLargeCode    = -32008  // Message exceeds size limits
	RateLimitExceededCode  = -32009  // Rate limit exceeded
	AuthenticationErrorCode = -32010 // Authentication failed
	AuthorizationErrorCode  = -32011 // Authorization failed
	ServiceUnavailableCode  = -32012 // Service temporarily unavailable
	ServerErrorCode         = -32013 // Generic server error
	ToolValidationErrorCode = -32014 // Tool parameter validation failed
	ToolAnalysisErrorCode   = -32015 // Tool analysis failed
	ToolFileErrorCode       = -32016 // File operation error
	ToolNetworkErrorCode    = -32017 // Network operation error
	TaskNotFoundCode        = -32018 // Task not found
	TaskValidationErrorCode = -32019 // Task validation failed
	TaskDependencyErrorCode = -32020 // Task dependency error
	TaskExecutionErrorCode  = -32021 // Task execution failed
	TaskTimeoutErrorCode    = -32022 // Task execution timed out
	DataValidationErrorCode = -32023 // Data validation failed
	ResourceNotFoundCode    = -32024 // Resource not found
	ResourceConflictCode    = -32025 // Resource conflict
	ResourceLimitErrorCode  = -32026 // Resource limit exceeded
	
	// Task operation timeouts
	TaskGetTimeout    = 30 * time.Second
	TaskVerifyTimeout = 60 * time.Second
	TaskListTimeout   = 30 * time.Second
)

func loadConfig() *Config {
	config := &Config{
		HubURL: os.Getenv("SENTINEL_HUB_URL"),
		APIKey: os.Getenv("SENTINEL_API_KEY"),
	}
	
	// Check for --api-key flag (for CI/CD)
	for i, arg := range os.Args {
		if arg == "--api-key" && i+1 < len(os.Args) {
			config.APIKey = os.Args[i+1]
			break
		}
	}
	
	// Prefer environment variables, but allow file fallback
	// Try to read from .sentinelsrc file only if env vars not set
	if config.APIKey == "" {
	if configData, err := os.ReadFile(".sentinelsrc"); err == nil {
			// Check file permissions (should be 0600 or more restrictive)
			if !configWarningShown {
			if fileInfo, err := os.Stat(".sentinelsrc"); err == nil {
				mode := fileInfo.Mode()
				// Check if file is world-readable (others have read permission)
				if mode&0004 != 0 || mode&0040 != 0 {
					fmt.Fprintf(os.Stderr, "‚ö†Ô∏è  WARNING: .sentinelsrc file permissions are too permissive (current: %s).\n", mode.String())
					fmt.Fprintf(os.Stderr, "   Recommendation: chmod 600 .sentinelsrc\n")
						configWarningShown = true
					}
				}
			}
			
		var jsonConfig map[string]interface{}
		if json.Unmarshal(configData, &jsonConfig) == nil {
				if hubURL, ok := jsonConfig["hubUrl"].(string); ok && hubURL != "" && config.HubURL == "" {
				config.HubURL = hubURL
			}
			if apiKey, ok := jsonConfig["apiKey"].(string); ok && apiKey != "" {
				config.APIKey = apiKey
					// Warn about API key in file
					fmt.Fprintf(os.Stderr, "‚ö†Ô∏è  WARNING: API key found in .sentinelsrc file.\n")
					fmt.Fprintf(os.Stderr, "   Recommendation: Use environment variable SENTINEL_API_KEY instead for better security.\n")
				}
			}
			if scanDirs, ok := jsonConfig["scanDirs"].([]interface{}); ok {
				config.ScanDirs = make([]string, len(scanDirs))
				for i, dir := range scanDirs {
					if dirStr, ok := dir.(string); ok {
						config.ScanDirs[i] = dirStr
					}
				}
			}
			if excludePaths, ok := jsonConfig["excludePaths"].([]interface{}); ok {
				config.ExcludePaths = make([]string, len(excludePaths))
				for i, path := range excludePaths {
					if pathStr, ok := path.(string); ok {
						config.ExcludePaths[i] = pathStr
					}
				}
			}
			if severityLevels, ok := jsonConfig["severityLevels"].(map[string]interface{}); ok {
				config.SeverityLevels = make(map[string]string)
				for key, value := range severityLevels {
					if valueStr, ok := value.(string); ok {
						config.SeverityLevels[key] = valueStr
					}
				}
			}
		}
	}
	
	// Default Hub URL if not set - Use HTTPS for security
	// Note: No default URL to avoid security issues. Users must explicitly configure.
	if config.HubURL == "" {
		// config.HubURL = "https://sentinel-hub.example.com" // No default for security
	}
	
	return config
}

func sendHTTPRequest(url, method string, headers map[string]string, body []byte) ([]byte, int, error) {
	return sendHTTPRequestWithRetry(url, method, headers, body, 3)
}

// CircuitBreaker implements circuit breaker pattern for Hub API calls
type CircuitBreaker struct {
	state         string // "closed", "open", "half-open"
	failureCount  int
	lastFailure   time.Time
	timeout       time.Duration
	mu            sync.Mutex
}

var hubCircuitBreaker = &CircuitBreaker{
	state:   "closed",
	timeout: 30 * time.Second,
}

func (cb *CircuitBreaker) canAttempt() bool {
	cb.mu.Lock()
	defer cb.mu.Unlock()
	
	now := time.Now()
	
	switch cb.state {
	case "closed":
		return true
	case "open":
		// Check if timeout has passed
		if now.Sub(cb.lastFailure) >= cb.timeout {
			cb.state = "half-open"
			return true
		}
		return false
	case "half-open":
		return true
	default:
		return false
	}
}

func (cb *CircuitBreaker) recordSuccess() {
	cb.mu.Lock()
	defer cb.mu.Unlock()
	
	cb.state = "closed"
	cb.failureCount = 0
}

func (cb *CircuitBreaker) recordFailure() {
	cb.mu.Lock()
	defer cb.mu.Unlock()
	
	cb.failureCount++
	cb.lastFailure = time.Now()
	
	if cb.state == "half-open" || cb.failureCount >= 3 {
		cb.state = "open"
	}
}

func sendHTTPRequestWithRetry(url, method string, headers map[string]string, body []byte, maxRetries int) ([]byte, int, error) {
	// Check circuit breaker
	if !hubCircuitBreaker.canAttempt() {
		return nil, 0, fmt.Errorf("circuit breaker is open - Hub API unavailable")
	}
	
	var lastErr error
	var lastStatusCode int
	var retryAfter time.Duration
	
	for attempt := 0; attempt <= maxRetries; attempt++ {
		if attempt > 0 {
			// Handle Retry-After header from previous attempt
			if retryAfter > 0 {
				time.Sleep(retryAfter)
				retryAfter = 0
			} else {
				// Exponential backoff with jitter: 100ms * 2^(attempt-1) + random jitter
				baseBackoff := time.Duration(100 * (1 << uint(attempt-1))) * time.Millisecond
				// Add jitter: ¬±20% of base backoff
				jitter := time.Duration(float64(baseBackoff) * 0.2 * (2.0*float64(time.Now().UnixNano()%100)/100.0 - 1.0))
				backoff := baseBackoff + jitter
			time.Sleep(backoff)
			}
		}
		
		client := &http.Client{
			Timeout: 10 * time.Second,
		}
		
		req, err := http.NewRequest(method, url, bytes.NewBuffer(body))
		if err != nil {
			hubCircuitBreaker.recordFailure()
			return nil, 0, err
		}
		
		for key, value := range headers {
			req.Header.Set(key, value)
		}
		
		resp, err := client.Do(req)
		if err != nil {
			lastErr = err
			// Retry on network errors
			if attempt < maxRetries {
				continue
			}
			hubCircuitBreaker.recordFailure()
			return nil, 0, err
		}
		defer resp.Body.Close()
		
		// Handle rate limiting (429)
		if resp.StatusCode == 429 {
			// Parse Retry-After header
			if retryAfterStr := resp.Header.Get("Retry-After"); retryAfterStr != "" {
				if secs, err := strconv.Atoi(retryAfterStr); err == nil {
					retryAfter = time.Duration(secs) * time.Second
				}
			}
			// Default to 1 second if no Retry-After header
			if retryAfter == 0 {
				retryAfter = time.Second
			}
			
			lastStatusCode = resp.StatusCode
			lastErr = fmt.Errorf("rate limit exceeded (429)")
			
			// Retry after waiting
			if attempt < maxRetries {
				continue
			}
			hubCircuitBreaker.recordFailure()
			return nil, resp.StatusCode, lastErr
		}
		
		// Retry on 5xx server errors, but not on 4xx client errors
		if resp.StatusCode >= 500 && attempt < maxRetries {
			lastStatusCode = resp.StatusCode
			lastErr = fmt.Errorf("server error %d", resp.StatusCode)
			continue
		}
		
		// Don't retry on 4xx errors (client errors)
		if resp.StatusCode >= 400 && resp.StatusCode < 500 {
			hubCircuitBreaker.recordFailure()
			respBody, _ := io.ReadAll(resp.Body)
			return respBody, resp.StatusCode, fmt.Errorf("client error %d: %s", resp.StatusCode, string(respBody))
		}
		
		// Success
		respBody, err := io.ReadAll(resp.Body)
		if err != nil {
			return nil, resp.StatusCode, err
		}
		
		hubCircuitBreaker.recordSuccess()
		return respBody, resp.StatusCode, nil
	}
	
	hubCircuitBreaker.recordFailure()
	return nil, lastStatusCode, lastErr
}

// sendHTTPRequestWithTimeout sends HTTP request with configurable timeout
func sendHTTPRequestWithTimeout(url, method string, headers map[string]string, body []byte, maxRetries int, timeout time.Duration) ([]byte, int, error) {
	// Check circuit breaker
	if !hubCircuitBreaker.canAttempt() {
		return nil, 0, fmt.Errorf("circuit breaker is open - Hub API unavailable")
	}
	
	var lastErr error
	var lastStatusCode int
	var retryAfter time.Duration
	
	for attempt := 0; attempt <= maxRetries; attempt++ {
		if attempt > 0 {
			// Handle Retry-After header from previous attempt
			if retryAfter > 0 {
				time.Sleep(retryAfter)
				retryAfter = 0
			} else {
				// Exponential backoff with jitter: 100ms * 2^(attempt-1) + random jitter
				baseBackoff := time.Duration(100 * (1 << uint(attempt-1))) * time.Millisecond
				// Add jitter: ¬±20% of base backoff
				jitter := time.Duration(float64(baseBackoff) * 0.2 * (2.0*float64(time.Now().UnixNano()%100)/100.0 - 1.0))
				backoff := baseBackoff + jitter
				time.Sleep(backoff)
			}
		}
		
		client := &http.Client{
			Timeout: timeout,  // Use provided timeout
		}
		
		req, err := http.NewRequest(method, url, bytes.NewBuffer(body))
		if err != nil {
			hubCircuitBreaker.recordFailure()
			return nil, 0, err
		}
		
		for key, value := range headers {
			req.Header.Set(key, value)
		}
		
		resp, err := client.Do(req)
		if err != nil {
			lastErr = err
			// Retry on network errors
			if attempt < maxRetries {
				continue
			}
			hubCircuitBreaker.recordFailure()
			return nil, 0, err
		}
		defer resp.Body.Close()
		
		// Handle rate limiting (429)
		if resp.StatusCode == 429 {
			// Parse Retry-After header
			if retryAfterStr := resp.Header.Get("Retry-After"); retryAfterStr != "" {
				if secs, err := strconv.Atoi(retryAfterStr); err == nil {
					retryAfter = time.Duration(secs) * time.Second
				}
			}
			// Default to 1 second if no Retry-After header
			if retryAfter == 0 {
				retryAfter = time.Second
			}
			
			lastStatusCode = resp.StatusCode
			lastErr = fmt.Errorf("rate limit exceeded (429)")
			
			// Retry after waiting
			if attempt < maxRetries {
				continue
			}
		}
		
		// Read response body
		respBody, err := io.ReadAll(resp.Body)
		if err != nil {
			lastErr = err
			if attempt < maxRetries {
				continue
			}
			hubCircuitBreaker.recordFailure()
			return nil, resp.StatusCode, err
		}
		
		// Success - record and return
		if resp.StatusCode >= 200 && resp.StatusCode < 300 {
			hubCircuitBreaker.recordSuccess()
			return respBody, resp.StatusCode, nil
		}
		
		// Non-2xx status code
		lastStatusCode = resp.StatusCode
		lastErr = fmt.Errorf("HTTP %d: %s", resp.StatusCode, string(respBody))
		
		// Retry on 5xx errors
		if resp.StatusCode >= 500 && attempt < maxRetries {
			continue
		}
		
		// Don't retry on 4xx errors (except 429)
		hubCircuitBreaker.recordFailure()
		return respBody, resp.StatusCode, lastErr
	}
	
	hubCircuitBreaker.recordFailure()
	return nil, lastStatusCode, lastErr
}

// sendComprehensiveAnalysisRequest sends comprehensive analysis request with depth-based timeout
func sendComprehensiveAnalysisRequest(url, method string, headers map[string]string, body []byte, depth string) ([]byte, int, error) {
	// Calculate timeout based on depth
	timeout := 10 * time.Second
	switch depth {
	case "surface":
		timeout = 15 * time.Second
	case "medium":
		timeout = 60 * time.Second
	case "deep":
		timeout = 120 * time.Second
	}
	
	// Allow override via environment variable
	if timeoutStr := os.Getenv("SENTINEL_COMPREHENSIVE_TIMEOUT"); timeoutStr != "" {
		if duration, err := time.ParseDuration(timeoutStr); err == nil {
			timeout = duration
		}
	}
	
	return sendHTTPRequestWithTimeout(url, method, headers, body, 3, timeout)
}

func sendDocSyncRequest(reportType string, options map[string]interface{}) (map[string]interface{}, error) {
	config := loadConfig()
	
	if config.HubURL == "" || config.APIKey == "" {
		return nil, fmt.Errorf("Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
	}
	
	url := config.HubURL + "/api/v1/analyze/doc-sync"
	
	// Get project ID from config or use default
	projectID := "default"
	if projID, ok := options["project_id"].(string); ok {
		projectID = projID
	}
	
	requestBody := map[string]interface{}{
		"projectId":  projectID,
		"report_type": reportType,
		"options":     options,
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return nil, err
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	respBody, statusCode, err := sendHTTPRequest(url, "POST", headers, jsonBody)
	if err != nil {
		return nil, fmt.Errorf("Hub request failed: %v", err)
	}
	
	if statusCode != http.StatusOK {
		return nil, fmt.Errorf("Hub returned status %d: %s", statusCode, string(respBody))
	}
	
	var response map[string]interface{}
	if err := json.Unmarshal(respBody, &response); err != nil {
		return nil, err
	}
	
	return response, nil
}

// =============================================================================
// DOC-SYNC COMMAND HANDLER (Phase 11)
// =============================================================================

func runDocSync() {
	// Parse flags
	args := os.Args[2:]
	reportType := "status_tracking"
	fixMode := false
	outputFormat := "text"
	outputFile := ""
	
	for i, arg := range args {
		switch arg {
		case "--fix":
			fixMode = true
		case "--output":
			if i+1 < len(args) {
				outputFormat = args[i+1]
			}
		case "--output-file":
			if i+1 < len(args) {
				outputFile = args[i+1]
			}
		case "--type":
			if i+1 < len(args) {
				reportType = args[i+1]
			}
		}
	}
	
	options := map[string]interface{}{
		"codebase_path": ".",
		"fix":           fixMode,
	}
	
	// Send request to Hub
	fmt.Println("üìã Checking documentation-code sync...")
	response, err := sendDocSyncRequest(reportType, options)
	if err != nil {
		fmt.Printf("‚ö†Ô∏è  Doc-sync check failed: %v\n", err)
		fmt.Println("   (Continuing without doc-sync check)")
		return
	}
	
	// Display results
	if success, ok := response["success"].(bool); ok && success {
		displayDocSyncResults(response, outputFormat, outputFile, fixMode)
	} else {
		msg := "Unknown error"
		if message, ok := response["message"].(string); ok {
			msg = message
		}
		fmt.Printf("‚ùå Doc-sync analysis failed: %s\n", msg)
	}
}

func displayDocSyncResults(response map[string]interface{}, format, outputFile string, fixMode bool) {
	if format == "json" {
		jsonOutput, _ := json.MarshalIndent(response, "", "  ")
		if outputFile != "" {
			os.WriteFile(outputFile, jsonOutput, 0644)
			fmt.Printf("‚úÖ Report saved to %s\n", outputFile)
		} else {
			fmt.Println(string(jsonOutput))
		}
		return
	}
	
	// Human-readable format
	fmt.Println("\nüìã Documentation-Code Sync Report")
	fmt.Println("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	
	// In-sync items
	if inSync, ok := response["in_sync"].([]interface{}); ok {
		fmt.Println("\n‚úÖ IN SYNC:")
		if len(inSync) == 0 {
			fmt.Println("  (none)")
		} else {
			for _, item := range inSync {
				if itemMap, ok := item.(map[string]interface{}); ok {
					phase := ""
					status := ""
					if p, ok := itemMap["phase"].(string); ok {
						phase = p
					}
					if s, ok := itemMap["status"].(string); ok {
						status = s
					}
					fmt.Printf("  - %s (%s)\n", phase, status)
				}
			}
		}
	}
	
	// Discrepancies
	if discrepancies, ok := response["discrepancies"].([]interface{}); ok {
		fmt.Println("\n‚ö†Ô∏è  DISCREPANCIES FOUND:\n")
		if len(discrepancies) == 0 {
			fmt.Println("  (none)")
		} else {
			for _, disc := range discrepancies {
				if discMap, ok := disc.(map[string]interface{}); ok {
					phase := ""
					discType := ""
					docStatus := ""
					codeStatus := ""
					recommendation := ""
					
					if p, ok := discMap["phase"].(string); ok {
						phase = p
					}
					if t, ok := discMap["type"].(string); ok {
						discType = t
					}
					if ds, ok := discMap["doc_status"].(string); ok {
						docStatus = ds
					}
					if cs, ok := discMap["code_status"].(string); ok {
						codeStatus = cs
					}
					if r, ok := discMap["recommendation"].(string); ok {
						recommendation = r
					}
					
					fmt.Printf("  %s: %s\n", phase, discType)
					fmt.Printf("    Documentation: %s\n", docStatus)
					fmt.Printf("    Code: %s\n", codeStatus)
					fmt.Printf("    Recommendation: %s\n", recommendation)
					fmt.Println()
				}
			}
		}
	}
	
	// Summary
	if summary, ok := response["summary"].(map[string]interface{}); ok {
		fmt.Println("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
		totalPhases := 0
		inSyncCount := 0
		discrepancyCount := 0
		
		if tp, ok := summary["total_phases"].(float64); ok {
			totalPhases = int(tp)
		}
		if isc, ok := summary["in_sync_count"].(float64); ok {
			inSyncCount = int(isc)
		}
		if dc, ok := summary["discrepancy_count"].(float64); ok {
			discrepancyCount = int(dc)
		}
		
		fmt.Printf("Summary: %d phases, %d in sync, %d discrepancies\n",
			totalPhases, inSyncCount, discrepancyCount)
	}
	
	if fixMode {
		fmt.Println("\nüí° Use --fix flag to apply suggested updates")
	}
}

// =============================================================================
// KNOWLEDGE COMMAND HANDLER (Phase 12)
// =============================================================================

func runKnowledge() {
	if len(os.Args) < 3 {
		fmt.Println("Usage: ./sentinel knowledge <subcommand>")
		fmt.Println("Subcommands:")
		fmt.Println("  gap-analysis  - Find gaps between documentation and code")
		fmt.Println("  changes       - List change requests")
		fmt.Println("  approve       - Approve change request")
		fmt.Println("  reject        - Reject change request")
		fmt.Println("  impact        - Show impact analysis")
		fmt.Println("  track         - Show implementation status")
		fmt.Println("  start         - Start implementation")
		fmt.Println("  complete      - Mark implementation as complete")
		return
	}
	
	subcommand := os.Args[2]
	
	switch subcommand {
	case "gap-analysis":
		runGapAnalysis()
	case "changes":
		runChangeRequests()
	case "approve":
		runApproveChangeRequest()
	case "reject":
		runRejectChangeRequest()
	case "impact":
		runImpactAnalysis()
	case "track":
		runTrackImplementation()
	case "start":
		runStartImplementation()
	case "complete":
		runCompleteImplementation()
	default:
		fmt.Printf("Unknown subcommand: %s\n", subcommand)
		runKnowledge() // Show help
	}
}

func runGapAnalysis() {
	args := os.Args[3:]
	outputFormat := "text"
	outputFile := ""
	includeTests := true
	reverseCheck := false
	
	for i, arg := range args {
		switch arg {
		case "--output":
			if i+1 < len(args) {
				outputFormat = args[i+1]
			}
		case "--output-file":
			if i+1 < len(args) {
				outputFile = args[i+1]
			}
		case "--no-tests":
			includeTests = false
		case "--reverse-check":
			reverseCheck = true
		}
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	url := config.HubURL + "/api/v1/knowledge/gap-analysis"
	
	requestBody := map[string]interface{}{
		"projectId":    "default",
		"codebasePath": ".",
		"options": map[string]interface{}{
			"includeTests": includeTests,
			"reverseCheck": reverseCheck,
		},
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		fmt.Printf("‚ùå Failed to prepare request: %v\n", err)
		return
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	fmt.Println("üîç Analyzing gaps between documentation and code...")
	respBody, statusCode, err := sendHTTPRequest(url, "POST", headers, jsonBody)
	if err != nil {
		fmt.Printf("‚ùå Gap analysis failed: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	var response map[string]interface{}
	if err := json.Unmarshal(respBody, &response); err != nil {
		fmt.Printf("‚ùå Failed to parse response: %v\n", err)
		return
	}
	
	if success, ok := response["success"].(bool); ok && success {
		displayGapAnalysisResults(response, outputFormat, outputFile)
	} else {
		fmt.Println("‚ùå Gap analysis failed")
	}
}

func displayGapAnalysisResults(response map[string]interface{}, format, outputFile string) {
	report, ok := response["report"].(map[string]interface{})
	if !ok {
		fmt.Println("‚ùå Invalid response format")
		return
	}
	
	if format == "json" {
		jsonOutput, _ := json.MarshalIndent(response, "", "  ")
		if outputFile != "" {
			os.WriteFile(outputFile, jsonOutput, 0644)
			fmt.Printf("‚úÖ Report saved to %s\n", outputFile)
		} else {
			fmt.Println(string(jsonOutput))
		}
		return
	}
	
	// Text format
	gaps, _ := report["gaps"].([]interface{})
	summary, _ := report["summary"].(map[string]interface{})
	
	fmt.Println("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	fmt.Println("Gap Analysis Report")
	fmt.Println("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	
	if summary != nil {
		total, _ := summary["total"].(float64)
		fmt.Printf("\nTotal Gaps Found: %.0f\n", total)
		
		byType, _ := summary["by_type"].(map[string]interface{})
		if byType != nil {
			fmt.Println("\nBy Type:")
			if missingImpl, ok := byType["missing_impl"].(float64); ok {
				fmt.Printf("  Missing Implementation: %.0f\n", missingImpl)
			}
			if missingDoc, ok := byType["missing_doc"].(float64); ok {
				fmt.Printf("  Missing Documentation: %.0f\n", missingDoc)
			}
			if partial, ok := byType["partial_match"].(float64); ok {
				fmt.Printf("  Partial Match: %.0f\n", partial)
			}
			if testsMissing, ok := byType["tests_missing"].(float64); ok {
				fmt.Printf("  Tests Missing: %.0f\n", testsMissing)
			}
		}
	}
	
	if len(gaps) > 0 {
		fmt.Println("\nGaps:")
		for i, gap := range gaps {
			gapMap, _ := gap.(map[string]interface{})
			if gapMap == nil {
				continue
			}
			
			gapType, _ := gapMap["type"].(string)
			ruleTitle, _ := gapMap["rule_title"].(string)
			description, _ := gapMap["description"].(string)
			recommendation, _ := gapMap["recommendation"].(string)
			
			fmt.Printf("\n%d. [%s] %s\n", i+1, gapType, ruleTitle)
			fmt.Printf("   Description: %s\n", description)
			fmt.Printf("   Recommendation: %s\n", recommendation)
		}
	} else {
		fmt.Println("\n‚úÖ No gaps found!")
	}
}

func runChangeRequests() {
	args := os.Args[3:]
	statusFilter := ""
	limit := 50
	offset := 0
	
	for i, arg := range args {
		switch arg {
		case "--status":
			if i+1 < len(args) {
				statusFilter = args[i+1]
			}
		case "--limit":
			if i+1 < len(args) {
				fmt.Sscanf(args[i+1], "%d", &limit)
			}
		case "--offset":
			if i+1 < len(args) {
				fmt.Sscanf(args[i+1], "%d", &offset)
			}
		}
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	url := config.HubURL + "/api/v1/change-requests"
	if statusFilter != "" {
		url += "?status=" + statusFilter
	}
	if limit > 0 {
		if strings.Contains(url, "?") {
			url += "&"
		} else {
			url += "?"
		}
		url += fmt.Sprintf("limit=%d&offset=%d", limit, offset)
	}
	
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}
	
	fmt.Println("üìã Fetching change requests...")
	respBody, statusCode, err := sendHTTPRequest(url, "GET", headers, nil)
	if err != nil {
		fmt.Printf("‚ùå Failed to fetch change requests: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	var response map[string]interface{}
	if err := json.Unmarshal(respBody, &response); err != nil {
		fmt.Printf("‚ùå Failed to parse response: %v\n", err)
		return
	}
	
	displayChangeRequests(response)
}

func displayChangeRequests(response map[string]interface{}) {
	requests, _ := response["change_requests"].([]interface{})
	total, _ := response["total"].(float64)
	
	fmt.Println("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	fmt.Println("Change Requests")
	fmt.Println("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	fmt.Printf("Total: %.0f\n\n", total)
	
	if len(requests) == 0 {
		fmt.Println("No change requests found.")
		return
	}
	
	for i, req := range requests {
		reqMap, _ := req.(map[string]interface{})
		if reqMap == nil {
			continue
		}
		
		id, _ := reqMap["id"].(string)
		crType, _ := reqMap["type"].(string)
		status, _ := reqMap["status"].(string)
		implStatus, _ := reqMap["implementation_status"].(string)
		
		fmt.Printf("%d. %s [%s] - Status: %s", i+1, id, crType, status)
		if implStatus != "" {
			fmt.Printf(", Implementation: %s", implStatus)
		}
		fmt.Println()
	}
}

func runApproveChangeRequest() {
	if len(os.Args) < 4 {
		fmt.Println("Usage: ./sentinel knowledge approve <CR-ID> [--by <email>]")
		return
	}
	
	changeRequestID := os.Args[3]
	approvedBy := "system"
	
	args := os.Args[4:]
	for i, arg := range args {
		if arg == "--by" && i+1 < len(args) {
			approvedBy = args[i+1]
		}
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	url := config.HubURL + "/api/v1/change-requests/" + changeRequestID + "/approve"
	
	requestBody := map[string]interface{}{
		"approved_by": approvedBy,
	}
	
	jsonBody, _ := json.Marshal(requestBody)
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	fmt.Printf("‚úÖ Approving change request %s...\n", changeRequestID)
	respBody, statusCode, err := sendHTTPRequest(url, "POST", headers, jsonBody)
	if err != nil {
		fmt.Printf("‚ùå Failed to approve: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	fmt.Println("‚úÖ Change request approved successfully")
}

func runRejectChangeRequest() {
	if len(os.Args) < 4 {
		fmt.Println("Usage: ./sentinel knowledge reject <CR-ID> [--reason <reason>] [--by <email>]")
		return
	}
	
	changeRequestID := os.Args[3]
	reason := "No reason provided"
	rejectedBy := "system"
	
	args := os.Args[4:]
	for i, arg := range args {
		if arg == "--reason" && i+1 < len(args) {
			reason = args[i+1]
		}
		if arg == "--by" && i+1 < len(args) {
			rejectedBy = args[i+1]
		}
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	url := config.HubURL + "/api/v1/change-requests/" + changeRequestID + "/reject"
	
	requestBody := map[string]interface{}{
		"rejected_by": rejectedBy,
		"reason":      reason,
	}
	
	jsonBody, _ := json.Marshal(requestBody)
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	fmt.Printf("‚ùå Rejecting change request %s...\n", changeRequestID)
	respBody, statusCode, err := sendHTTPRequest(url, "POST", headers, jsonBody)
	if err != nil {
		fmt.Printf("‚ùå Failed to reject: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	fmt.Println("‚úÖ Change request rejected")
}

func runImpactAnalysis() {
	if len(os.Args) < 4 {
		fmt.Println("Usage: ./sentinel knowledge impact <CR-ID> [--codebase-path <path>]")
		return
	}
	
	changeRequestID := os.Args[3]
	codebasePath := "."
	
	args := os.Args[4:]
	for i, arg := range args {
		if arg == "--codebase-path" && i+1 < len(args) {
			codebasePath = args[i+1]
		}
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	url := config.HubURL + "/api/v1/change-requests/" + changeRequestID + "/impact"
	
	requestBody := map[string]interface{}{
		"codebasePath": codebasePath,
	}
	
	jsonBody, _ := json.Marshal(requestBody)
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	fmt.Printf("üîç Analyzing impact for change request %s...\n", changeRequestID)
	respBody, statusCode, err := sendHTTPRequest(url, "POST", headers, jsonBody)
	if err != nil {
		fmt.Printf("‚ùå Failed to analyze impact: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	var response map[string]interface{}
	if err := json.Unmarshal(respBody, &response); err != nil {
		fmt.Printf("‚ùå Failed to parse response: %v\n", err)
		return
	}
	
	displayImpactAnalysis(response)
}

func displayImpactAnalysis(response map[string]interface{}) {
	impact, _ := response["impact"].(map[string]interface{})
	if impact == nil {
		fmt.Println("‚ùå Invalid impact analysis response")
		return
	}
	
	fmt.Println("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	fmt.Println("Impact Analysis")
	fmt.Println("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	
	affectedCode, _ := impact["affected_code"].([]interface{})
	affectedTests, _ := impact["affected_tests"].([]interface{})
	estimatedEffort, _ := impact["estimated_effort"].(string)
	
	fmt.Printf("\nEstimated Effort: %s\n", estimatedEffort)
	
	if len(affectedCode) > 0 {
		fmt.Println("\nAffected Code:")
		for i, code := range affectedCode {
			codeMap, _ := code.(map[string]interface{})
			if codeMap != nil {
				filePath, _ := codeMap["file_path"].(string)
				funcName, _ := codeMap["function_name"].(string)
				fmt.Printf("  %d. %s", i+1, filePath)
				if funcName != "" {
					fmt.Printf(" (%s)", funcName)
				}
				fmt.Println()
			}
		}
	}
	
	if len(affectedTests) > 0 {
		fmt.Println("\nAffected Tests:")
		for i, test := range affectedTests {
			testMap, _ := test.(map[string]interface{})
			if testMap != nil {
				filePath, _ := testMap["file_path"].(string)
				testName, _ := testMap["test_name"].(string)
				fmt.Printf("  %d. %s", i+1, filePath)
				if testName != "" {
					fmt.Printf(" (%s)", testName)
				}
				fmt.Println()
			}
		}
	}
}

func runTrackImplementation() {
	if len(os.Args) < 4 {
		fmt.Println("Usage: ./sentinel knowledge track <CR-ID>")
		return
	}
	
	changeRequestID := os.Args[3]
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	url := config.HubURL + "/api/v1/change-requests/" + changeRequestID
	
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}
	
	fmt.Printf("üìä Tracking implementation for change request %s...\n", changeRequestID)
	respBody, statusCode, err := sendHTTPRequest(url, "GET", headers, nil)
	if err != nil {
		fmt.Printf("‚ùå Failed to track: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	var cr map[string]interface{}
	if err := json.Unmarshal(respBody, &cr); err != nil {
		fmt.Printf("‚ùå Failed to parse response: %v\n", err)
		return
	}
	
	displayImplementationStatus(cr)
}

func displayImplementationStatus(cr map[string]interface{}) {
	fmt.Println("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	fmt.Println("Implementation Status")
	fmt.Println("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	
	id, _ := cr["id"].(string)
	status, _ := cr["status"].(string)
	implStatus, _ := cr["implementation_status"].(string)
	implNotes, _ := cr["implementation_notes"].(string)
	
	fmt.Printf("Change Request: %s\n", id)
	fmt.Printf("Status: %s\n", status)
	fmt.Printf("Implementation Status: %s\n", implStatus)
	if implNotes != "" {
		fmt.Printf("Notes: %s\n", implNotes)
	}
}

func runStartImplementation() {
	if len(os.Args) < 4 {
		fmt.Println("Usage: ./sentinel knowledge start <CR-ID> [--notes <notes>]")
		return
	}
	
	changeRequestID := os.Args[3]
	notes := ""
	
	args := os.Args[4:]
	for i, arg := range args {
		if arg == "--notes" && i+1 < len(args) {
			notes = args[i+1]
		}
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	url := config.HubURL + "/api/v1/change-requests/" + changeRequestID + "/start"
	
	requestBody := map[string]interface{}{
		"notes": notes,
	}
	
	jsonBody, _ := json.Marshal(requestBody)
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	fmt.Printf("üöÄ Starting implementation for change request %s...\n", changeRequestID)
	respBody, statusCode, err := sendHTTPRequest(url, "POST", headers, jsonBody)
	if err != nil {
		fmt.Printf("‚ùå Failed to start: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	fmt.Println("‚úÖ Implementation started")
}

func runCompleteImplementation() {
	if len(os.Args) < 4 {
		fmt.Println("Usage: ./sentinel knowledge complete <CR-ID> [--notes <notes>]")
		return
	}
	
	changeRequestID := os.Args[3]
	notes := ""
	
	args := os.Args[4:]
	for i, arg := range args {
		if arg == "--notes" && i+1 < len(args) {
			notes = args[i+1]
		}
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	url := config.HubURL + "/api/v1/change-requests/" + changeRequestID + "/complete"
	
	requestBody := map[string]interface{}{
		"notes": notes,
	}
	
	jsonBody, _ := json.Marshal(requestBody)
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	fmt.Printf("‚úÖ Completing implementation for change request %s...\n", changeRequestID)
	respBody, statusCode, err := sendHTTPRequest(url, "POST", headers, jsonBody)
	if err != nil {
		fmt.Printf("‚ùå Failed to complete: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	fmt.Println("‚úÖ Implementation completed")
}

// =============================================================================
// TASKS COMMAND HANDLER (Phase 14E)
// =============================================================================

func runTasks() {
	if len(os.Args) < 3 {
		fmt.Println("Usage: ./sentinel tasks <subcommand>")
		fmt.Println("Subcommands:")
		fmt.Println("  scan         - Scan codebase for tasks")
		fmt.Println("  list         - List all tasks")
		fmt.Println("  verify       - Verify task completion")
		fmt.Println("  dependencies - Show dependency graph")
		fmt.Println("  complete     - Manually mark task complete")
		return
	}
	
	subcommand := os.Args[2]
	
	switch subcommand {
	case "scan":
		runTasksScan()
	case "list":
		runTasksList()
	case "verify":
		runTasksVerify()
	case "dependencies":
		runTasksDependencies()
	case "complete":
		runTasksComplete()
	default:
		fmt.Printf("Unknown subcommand: %s\n", subcommand)
		runTasks() // Show help
	}
}

func runTasksScan() {
	args := os.Args[3:]
	codebasePath := "."
	
	for i, arg := range args {
		if arg == "--dir" && i+1 < len(args) {
			codebasePath = args[i+1]
		}
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	absPath, _ := filepath.Abs(codebasePath)
	
	url := config.HubURL + "/api/v1/tasks/scan"
	requestBody := map[string]interface{}{
		"codebasePath": absPath,
	}
	
	jsonBody, _ := json.Marshal(requestBody)
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	fmt.Printf("üîç Scanning codebase for tasks in %s...\n", absPath)
	respBody, statusCode, err := sendHTTPRequest(url, "POST", headers, jsonBody)
	if err != nil {
		fmt.Printf("‚ùå Failed to scan: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		fmt.Printf("‚ùå Failed to parse response: %v\n", err)
		return
	}
	
	detected, _ := result["detected"].(float64)
	unique, _ := result["unique"].(float64)
	stored, _ := result["stored"].(float64)
	
	fmt.Printf("‚úÖ Scan complete: %d detected, %d unique, %d stored\n", int(detected), int(unique), int(stored))
}

func runTasksList() {
	args := os.Args[3:]
	statusFilter := ""
	priorityFilter := ""
	limit := 50
	
	for i, arg := range args {
		if arg == "--status" && i+1 < len(args) {
			statusFilter = args[i+1]
		}
		if arg == "--priority" && i+1 < len(args) {
			priorityFilter = args[i+1]
		}
		if arg == "--limit" && i+1 < len(args) {
			if l, err := strconv.Atoi(args[i+1]); err == nil {
				limit = l
			}
		}
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	url := config.HubURL + "/api/v1/tasks"
	queryParams := urlpkg.Values{}
	if statusFilter != "" {
		queryParams.Add("status", statusFilter)
	}
	if priorityFilter != "" {
		queryParams.Add("priority", priorityFilter)
	}
	queryParams.Add("limit", strconv.Itoa(limit))
	
	if len(queryParams) > 0 {
		url += "?" + queryParams.Encode()
	}
	
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}
	
	respBody, statusCode, err := sendHTTPRequest(url, "GET", headers, nil)
	if err != nil {
		fmt.Printf("‚ùå Failed to list tasks: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	var response map[string]interface{}
	if err := json.Unmarshal(respBody, &response); err != nil {
		fmt.Printf("‚ùå Failed to parse response: %v\n", err)
		return
	}
	
	tasks, _ := response["tasks"].([]interface{})
	total, _ := response["total"].(float64)
	
	fmt.Printf("\nüìã Tasks (%d total)\n", int(total))
	fmt.Println("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	
	if len(tasks) == 0 {
		fmt.Println("  (no tasks found)")
		return
	}
	
	for _, taskInterface := range tasks {
		if task, ok := taskInterface.(map[string]interface{}); ok {
			id, _ := task["id"].(string)
			title, _ := task["title"].(string)
			status, _ := task["status"].(string)
			priority, _ := task["priority"].(string)
			filePath, _ := task["file_path"].(string)
			
			statusIcon := "‚è≥"
			if status == "completed" {
				statusIcon = "‚úÖ"
			} else if status == "in_progress" {
				statusIcon = "üîÑ"
			} else if status == "blocked" {
				statusIcon = "üö´"
			}
			
			priorityIcon := "‚ö™"
			if priority == "critical" {
				priorityIcon = "üî¥"
			} else if priority == "high" {
				priorityIcon = "üü†"
			} else if priority == "medium" {
				priorityIcon = "üü°"
			}
			
			fmt.Printf("%s %s [%s] %s\n", statusIcon, priorityIcon, status, title)
			if filePath != "" {
				fmt.Printf("   üìÅ %s\n", filePath)
			}
			fmt.Printf("   üÜî %s\n\n", id)
		}
	}
}

func runTasksVerify() {
	args := os.Args[3:]
	verifyAll := false
	taskID := ""
	force := false
	
	for _, arg := range args {
		if arg == "--all" {
			verifyAll = true
		}
		if arg == "--force" {
			force = true
		}
		if !strings.HasPrefix(arg, "--") && taskID == "" {
			taskID = arg
		}
	}
	
	if !verifyAll && taskID == "" {
		fmt.Println("Usage: ./sentinel tasks verify <TASK-ID> [--force]")
		fmt.Println("   or: ./sentinel tasks verify --all [--force]")
		return
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	if verifyAll {
		fmt.Println("üîç Verifying all pending tasks...")
		url := config.HubURL + "/api/v1/tasks/verify-all"
		requestBody := map[string]interface{}{
			"force": force,
		}
		
		jsonBody, _ := json.Marshal(requestBody)
		headers := map[string]string{
			"Content-Type":  "application/json",
			"Authorization": "Bearer " + config.APIKey,
		}
		
		respBody, statusCode, err := sendHTTPRequest(url, "POST", headers, jsonBody)
		if err != nil {
			fmt.Printf("‚ùå Failed to verify all tasks: %v\n", err)
			return
		}
		
		if statusCode != 200 {
			fmt.Printf("‚ùå Verification failed (status %d): %s\n", statusCode, string(respBody))
			return
		}
		
		var result map[string]interface{}
		if err := json.Unmarshal(respBody, &result); err != nil {
			fmt.Printf("‚ùå Failed to parse response: %v\n", err)
			return
		}
		
		total, _ := result["total"].(float64)
		verified, _ := result["verified"].(float64)
		failed, _ := result["failed"].(float64)
		skipped, _ := result["skipped"].(float64)
		
		fmt.Printf("‚úÖ Verification complete:\n")
		fmt.Printf("   Total: %d\n", int(total))
		fmt.Printf("   Verified: %d\n", int(verified))
		fmt.Printf("   Failed: %d\n", int(failed))
		fmt.Printf("   Skipped: %d\n", int(skipped))
	} else {
		url := config.HubURL + "/api/v1/tasks/" + taskID + "/verify"
		requestBody := map[string]interface{}{
			"force": force,
		}
		
		jsonBody, _ := json.Marshal(requestBody)
		headers := map[string]string{
			"Content-Type":  "application/json",
			"Authorization": "Bearer " + config.APIKey,
		}
		
		fmt.Printf("üîç Verifying task %s...\n", taskID)
		respBody, statusCode, err := sendHTTPRequest(url, "POST", headers, jsonBody)
		if err != nil {
			fmt.Printf("‚ùå Failed to verify: %v\n", err)
			return
		}
		
		if statusCode != http.StatusOK {
			fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
			return
		}
		
		var result map[string]interface{}
		if err := json.Unmarshal(respBody, &result); err != nil {
			fmt.Printf("‚ùå Failed to parse response: %v\n", err)
			return
		}
		
		confidence, _ := result["overall_confidence"].(float64)
		status, _ := result["status"].(string)
		
		fmt.Printf("‚úÖ Verification complete: %.0f%% confidence, status: %s\n", confidence*100, status)
	}
}

func runTasksDependencies() {
	args := os.Args[3:]
	taskID := ""
	
	if len(args) > 0 && !strings.HasPrefix(args[0], "--") {
		taskID = args[0]
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	if taskID == "" {
		fmt.Println("Usage: ./sentinel tasks dependencies [TASK-ID]")
		fmt.Println("‚ö†Ô∏è  Dependency graph visualization not yet implemented")
		return
	}
	
	url := config.HubURL + "/api/v1/tasks/" + taskID + "/dependencies"
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}
	
	fmt.Printf("üîç Fetching dependencies for task %s...\n", taskID)
	respBody, statusCode, err := sendHTTPRequest(url, "GET", headers, nil)
	if err != nil {
		fmt.Printf("‚ùå Failed to get dependencies: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		fmt.Printf("‚ùå Failed to parse response: %v\n", err)
		return
	}
	
	dependencies, _ := result["dependencies"].([]interface{})
	blockedBy, _ := result["blocked_by"].([]interface{})
	blocks, _ := result["blocks"].([]interface{})
	
	fmt.Printf("\nüìä Dependencies for task %s\n", taskID)
	fmt.Println("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê")
	
	if len(blockedBy) > 0 {
		fmt.Println("\nüö´ Blocked by:")
		for _, depID := range blockedBy {
			fmt.Printf("  - %v\n", depID)
		}
	}
	
	if len(blocks) > 0 {
		fmt.Println("\nüîí Blocks:")
		for _, depID := range blocks {
			fmt.Printf("  - %v\n", depID)
		}
	}
	
	if len(dependencies) > 0 {
		fmt.Println("\nüì¶ Dependencies:")
		for _, depInterface := range dependencies {
			if dep, ok := depInterface.(map[string]interface{}); ok {
				depID, _ := dep["depends_on_task_id"].(string)
				depType, _ := dep["dependency_type"].(string)
				confidence, _ := dep["confidence"].(float64)
				fmt.Printf("  - %s (%s, %.0f%% confidence)\n", depID, depType, confidence*100)
			}
		}
	}
	
	if len(blockedBy) == 0 && len(blocks) == 0 && len(dependencies) == 0 {
		fmt.Println("  (no dependencies)")
	}
}

func runTasksComplete() {
	if len(os.Args) < 4 {
		fmt.Println("Usage: ./sentinel tasks complete <TASK-ID> [--reason <reason>]")
		return
	}
	
	taskID := os.Args[3]
	reason := ""
	
	args := os.Args[4:]
	for i, arg := range args {
		if arg == "--reason" && i+1 < len(args) {
			reason = args[i+1]
		}
	}
	
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		fmt.Println("‚ùå Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY")
		return
	}
	
	// Get current task to get version
	url := config.HubURL + "/api/v1/tasks/" + taskID
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}
	
	respBody, statusCode, err := sendHTTPRequest(url, "GET", headers, nil)
	if err != nil {
		fmt.Printf("‚ùå Failed to get task: %v\n", err)
		return
	}
	
	if statusCode != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", statusCode, string(respBody))
		return
	}
	
	var task map[string]interface{}
	if err := json.Unmarshal(respBody, &task); err != nil {
		fmt.Printf("‚ùå Failed to parse task: %v\n", err)
		return
	}
	
	version, _ := task["version"].(float64)
	
	// Update task status to completed
	updateURL := config.HubURL + "/api/v1/tasks/" + taskID
	requestBody := map[string]interface{}{
		"status":  "completed",
		"version": int(version),
	}
	if reason != "" {
		requestBody["reason"] = reason
	}
	
	jsonBody, _ := json.Marshal(requestBody)
	headers["Content-Type"] = "application/json"
	
	fmt.Printf("‚úÖ Marking task %s as complete...\n", taskID)
	updateResp, updateStatus, err := sendHTTPRequest(updateURL, "PUT", headers, jsonBody)
	if err != nil {
		fmt.Printf("‚ùå Failed to complete task: %v\n", err)
		return
	}
	
	if updateStatus != http.StatusOK {
		fmt.Printf("‚ùå Hub returned status %d: %s\n", updateStatus, string(updateResp))
		return
	}
	
	fmt.Println("‚úÖ Task marked as complete")
}

// =============================================================================
// MCP SERVER IMPLEMENTATION (Phase 14B)
// =============================================================================

// registeredTools contains all available MCP tools
var registeredTools = []MCPTool{
	{
		Name:        "sentinel_analyze_feature_comprehensive",
		Description: "Perform comprehensive analysis of a feature across all layers (UI, API, Database, Logic, Integration, Tests) with business context validation",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"feature": map[string]interface{}{
					"type":        "string",
					"description": "Feature name or description (e.g., 'Order Cancellation')",
				},
				"mode": map[string]interface{}{
					"type":        "string",
					"enum":        []string{"auto", "manual"},
					"description": "Auto-discover feature components or use manual file specification",
					"default":     "auto",
				},
				"files": map[string]interface{}{
					"type":        "object",
					"description": "Manual file specification (required if mode='manual')",
					"properties": map[string]interface{}{
						"ui":         map[string]interface{}{"type": "array", "items": map[string]interface{}{"type": "string"}},
						"api":        map[string]interface{}{"type": "array", "items": map[string]interface{}{"type": "string"}},
						"database":   map[string]interface{}{"type": "array", "items": map[string]interface{}{"type": "string"}},
						"logic":      map[string]interface{}{"type": "array", "items": map[string]interface{}{"type": "string"}},
						"integration": map[string]interface{}{"type": "array", "items": map[string]interface{}{"type": "string"}},
						"tests":      map[string]interface{}{"type": "array", "items": map[string]interface{}{"type": "string"}},
					},
				},
				"codebasePath": map[string]interface{}{
					"type":        "string",
					"description": "Path to codebase root (required for auto mode, optional for manual)",
				},
				"depth": map[string]interface{}{
					"type":        "string",
					"enum":        []string{"surface", "medium", "deep"},
					"description": "Analysis depth (surface=fast, medium=balanced, deep=comprehensive)",
					"default":     "medium",
				},
				"includeBusinessContext": map[string]interface{}{
					"type":        "boolean",
					"description": "Include business rules, journeys, and entities validation",
					"default":     false,
				},
			},
			"required": []string{"feature"},
		},
	},
	{
		Name:        "sentinel_check_intent",
		Description: "Analyze unclear prompts and generate clarifying questions. Handles vague requests gracefully by understanding intent and asking for clarification.",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"prompt": map[string]interface{}{
					"type":        "string",
					"description": "User prompt to analyze for clarity",
				},
				"codebasePath": map[string]interface{}{
					"type":        "string",
					"description": "Path to codebase root (optional, for context gathering)",
				},
				"includeContext": map[string]interface{}{
					"type":        "boolean",
					"description": "Include context gathering (recent files, git status, etc.)",
					"default":     true,
				},
			},
			"required": []string{"prompt"},
		},
	},
	{
		Name:        "sentinel_analyze_intent",
		Description: "Analyze user intent and return context, rules, security, and test requirements",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"request": map[string]interface{}{
					"type":        "string",
					"description": "User's request to analyze",
				},
				"recentFiles": map[string]interface{}{
					"type":        "array",
					"items":       map[string]interface{}{"type": "string"},
					"description": "Recently edited files (optional)",
				},
				"gitStatus": map[string]interface{}{
					"type":        "object",
					"description": "Current git status (optional)",
				},
				"codebasePath": map[string]interface{}{
					"type":        "string",
					"description": "Path to codebase root (optional)",
				},
			},
			"required": []string{"request"},
		},
	},
	{
		Name:        "sentinel_get_context",
		Description: "Get recent activity context including git status, recent commits, and error logs",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"codebasePath": map[string]interface{}{
					"type":        "string",
					"description": "Path to codebase root (optional, defaults to current directory)",
				},
			},
		},
	},
	{
		Name:        "sentinel_get_patterns",
		Description: "Get learned patterns and project conventions from intent analysis",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"patternType": map[string]interface{}{
					"type":        "string",
					"description": "Filter patterns by type (optional)",
				},
				"limit": map[string]interface{}{
					"type":        "integer",
					"description": "Maximum number of patterns to return (default: 50)",
					"default":     50,
				},
			},
		},
	},
	{
		Name:        "sentinel_get_business_context",
		Description: "Get business rules, entities, and journeys for the project",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"itemType": map[string]interface{}{
					"type":        "string",
					"description": "Filter by knowledge item type: 'rule', 'entity', 'journey' (optional)",
				},
			},
		},
	},
	{
		Name:        "sentinel_get_security_context",
		Description: "Get security rules, compliance status, and security score for the project",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{},
		},
	},
	{
		Name:        "sentinel_get_test_requirements",
		Description: "Get test requirements, coverage status, and missing tests for the project",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"knowledgeItemId": map[string]interface{}{
					"type":        "string",
					"description": "Knowledge item ID to get test requirements for (optional)",
				},
			},
		},
	},
	{
		Name:        "sentinel_check_file_size",
		Description: "Check file size and get warnings and split suggestions",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"filePath": map[string]interface{}{
					"type":        "string",
					"description": "Path to the file to check",
				},
			},
			"required": []string{"filePath"},
		},
	},
	{
		Name:        "sentinel_validate_code",
		Description: "Validate generated code using AST analysis",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Code content to validate",
				},
				"filePath": map[string]interface{}{
					"type":        "string",
					"description": "Path to the file (optional)",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language (javascript, python, go, etc.)",
				},
			},
			"required": []string{"code"},
		},
	},
	{
		Name:        "sentinel_validate_security",
		Description: "Validate code for security compliance",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Code content to validate",
				},
				"filePath": map[string]interface{}{
					"type":        "string",
					"description": "Path to the file (optional)",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
				},
			},
			"required": []string{"code"},
		},
	},
	{
		Name:        "sentinel_validate_business",
		Description: "Validate code against business rules",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"feature": map[string]interface{}{
					"type":        "string",
					"description": "Feature description",
				},
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Code content to validate",
				},
			},
			"required": []string{"feature", "code"},
		},
	},
	{
		Name:        "sentinel_validate_tests",
		Description: "Validate test quality and coverage",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"testFilePath": map[string]interface{}{
					"type":        "string",
					"description": "Path to the test file",
				},
			},
			"required": []string{"testFilePath"},
		},
	},
	{
		Name:        "sentinel_apply_fix",
		Description: "Apply fixes to code issues",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"filePath": map[string]interface{}{
					"type":        "string",
					"description": "Path to the file to fix",
				},
				"fixType": map[string]interface{}{
					"type":        "string",
					"description": "Type of fix to apply (e.g., 'security', 'style', 'performance')",
				},
			},
			"required": []string{"filePath", "fixType"},
		},
	},
	{
		Name:        "sentinel_generate_tests",
		Description: "Generate test cases for a feature",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"feature": map[string]interface{}{
					"type":        "string",
					"description": "Feature description",
				},
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Code content to generate tests for",
				},
			},
			"required": []string{"feature", "code"},
		},
	},
	{
		Name:        "sentinel_run_tests",
		Description: "Execute tests in sandbox",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"testFilePath": map[string]interface{}{
					"type":        "string",
					"description": "Path to the test file",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
				},
			},
			"required": []string{"testFilePath"},
		},
	},
	{
		Name:        "sentinel_get_task_status",
		Description: "Get task completion status (requires Phase 14E)",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"taskId": map[string]interface{}{
					"type":        "string",
					"description": "Task ID",
				},
				"codebasePath": map[string]interface{}{
					"type":        "string",
					"description": "Optional codebase path for dependency analysis",
				},
			},
			"required": []string{"taskId"},
		},
	},
	{
		Name:        "sentinel_verify_task",
		Description: "Verify task completion (requires Phase 14E)",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"taskId": map[string]interface{}{
					"type":        "string",
					"description": "Task ID",
				},
			},
			"required": []string{"taskId"},
		},
	},
	{
		Name:        "sentinel_list_tasks",
		Description: "List all tasks (requires Phase 14E)",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"status": map[string]interface{}{
					"type":        "string",
					"description": "Filter by status (pending, in_progress, completed, blocked)",
				},
				"priority": map[string]interface{}{
					"type":        "string",
					"description": "Filter by priority (low, medium, high, critical)",
				},
				"source": map[string]interface{}{
					"type":        "string",
					"description": "Filter by source (cursor, manual, change_request, comprehensive_analysis)",
				},
				"assigned_to": map[string]interface{}{
					"type":        "string",
					"description": "Filter by assignee",
				},
				"tags": map[string]interface{}{
					"type":        "array",
					"items":       map[string]interface{}{"type": "string"},
					"description": "Filter by tags (array)",
				},
				"include_archived": map[string]interface{}{
					"type":        "boolean",
					"description": "Include archived tasks",
				},
				"limit": map[string]interface{}{
					"type":        "integer",
					"description": "Maximum number of tasks to return (1-100)",
					"minimum":     1,
					"maximum":     100,
				},
				"offset": map[string]interface{}{
					"type":        "integer",
					"description": "Offset for pagination",
					"minimum":     0,
				},
			},
		},
	},
	{
		Name:        "sentinel_analyze_complexity",
		Description: "Analyze code complexity using AST metrics (cyclomatic complexity, nesting depth, cognitive complexity)",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Source code to analyze",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"javascript", "typescript", "python", "go", "java", "csharp"},
				},
				"filePath": map[string]interface{}{
					"type":        "string",
					"description": "File path for context",
				},
				"thresholds": map[string]interface{}{
					"type": "object",
					"description": "Complexity thresholds",
					"properties": map[string]interface{}{
						"cyclomatic": map[string]interface{}{"type": "number", "default": 10},
						"cognitive":  map[string]interface{}{"type": "number", "default": 15},
						"nesting":    map[string]interface{}{"type": "number", "default": 4},
					},
				},
			},
			"required": []string{"code", "language"},
		},
	},
	{
		Name:        "sentinel_detect_dead_code",
		Description: "Detect unreachable or unused code using AST analysis",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"codebase": map[string]interface{}{
					"type":        "array",
					"items":       map[string]interface{}{"type": "string"},
					"description": "List of file paths to analyze",
				},
				"entryPoints": map[string]interface{}{
					"type":        "array",
					"items":       map[string]interface{}{"type": "string"},
					"description": "Entry point files (e.g., main.js, index.py)",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"javascript", "typescript", "python", "go", "java", "csharp"},
				},
			},
			"required": []string{"codebase", "language"},
		},
	},
	{
		Name:        "sentinel_analyze_dependencies",
		Description: "Analyze import/export dependencies and module relationships using AST",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"files": map[string]interface{}{
					"type":        "array",
					"items":       map[string]interface{}{"type": "string"},
					"description": "List of file paths to analyze",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"javascript", "typescript", "python", "go", "java", "csharp"},
				},
				"includeExternal": map[string]interface{}{
					"type":        "boolean",
					"description": "Include external dependencies",
					"default":     false,
				},
			},
			"required": []string{"files", "language"},
		},
	},
	{
		Name:        "sentinel_check_type_safety",
		Description: "Analyze type safety and potential type errors using AST",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Source code to analyze",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"typescript", "python", "go", "java", "csharp"},
				},
				"strict": map[string]interface{}{
					"type":        "boolean",
					"description": "Strict type checking mode",
					"default":     true,
				},
			},
			"required": []string{"code", "language"},
		},
	},
	{
		Name:        "sentinel_analyze_performance",
		Description: "Analyze performance bottlenecks and optimization opportunities using AST",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Source code to analyze",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"javascript", "typescript", "python", "go", "java", "csharp"},
				},
				"context": map[string]interface{}{
					"type":        "object",
					"description": "Performance context",
					"properties": map[string]interface{}{
						"environment": map[string]interface{}{
							"type": "string",
							"enum": []string{"browser", "server", "mobile"},
						},
						"targetRuntime": map[string]interface{}{
							"type": "string",
							"enum": []string{"node", "browser", "jvm", "dotnet"},
						},
					},
				},
			},
			"required": []string{"code", "language"},
		},
	},
	{
		Name:        "sentinel_format_code",
		Description: "Format and beautify code according to language standards and project conventions",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Source code to format",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"javascript", "typescript", "python", "go", "java", "csharp", "html", "css", "json", "yaml"},
				},
				"options": map[string]interface{}{
					"type": "object",
					"description": "Formatting options",
					"properties": map[string]interface{}{
						"indentSize": map[string]interface{}{
							"type": "integer",
							"default": 2,
							"minimum": 1,
							"maximum": 8,
						},
						"useTabs": map[string]interface{}{
							"type": "boolean",
							"default": false,
						},
						"lineWidth": map[string]interface{}{
							"type": "integer",
							"default": 80,
							"minimum": 60,
							"maximum": 120,
						},
					},
				},
			},
			"required": []string{"code", "language"},
		},
	},
	{
		Name:        "sentinel_lint_code",
		Description: "Lint code for style violations, potential bugs, and best practices",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Source code to lint",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"javascript", "typescript", "python", "go", "java", "csharp"},
				},
				"rules": map[string]interface{}{
					"type":        "array",
					"items":       map[string]interface{}{"type": "string"},
					"description": "Specific linting rules to apply (empty for all)",
				},
				"strict": map[string]interface{}{
					"type":        "boolean",
					"description": "Enable strict linting mode",
					"default":     false,
				},
			},
			"required": []string{"code", "language"},
		},
	},
	{
		Name:        "sentinel_refactor_code",
		Description: "Suggest and apply code refactoring improvements (rename variables, extract methods, etc.)",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Source code to refactor",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"javascript", "typescript", "python", "go", "java", "csharp"},
				},
				"refactoringType": map[string]interface{}{
					"type":        "string",
					"description": "Type of refactoring to apply",
					"enum":        []string{"extract_method", "rename_variable", "inline_variable", "extract_constant", "simplify_condition", "remove_dead_code", "optimize_imports"},
				},
				"selection": map[string]interface{}{
					"type": "object",
					"description": "Code selection to refactor",
					"properties": map[string]interface{}{
						"startLine":   map[string]interface{}{"type": "integer"},
						"endLine":     map[string]interface{}{"type": "integer"},
						"startColumn": map[string]interface{}{"type": "integer"},
						"endColumn":   map[string]interface{}{"type": "integer"},
					},
				},
			},
			"required": []string{"code", "language", "refactoringType"},
		},
	},
	{
		Name:        "sentinel_generate_docs",
		Description: "Generate documentation for code functions, classes, and modules",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"code": map[string]interface{}{
					"type":        "string",
					"description": "Source code to document",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"javascript", "typescript", "python", "go", "java", "csharp"},
				},
				"format": map[string]interface{}{
					"type":        "string",
					"description": "Documentation format",
					"enum":        []string{"javadoc", "jsdoc", "sphinx", "google", "numpy"},
					"default":     "google",
				},
				"includeExamples": map[string]interface{}{
					"type":        "boolean",
					"description": "Include usage examples in documentation",
					"default":     true,
				},
			},
			"required": []string{"code", "language"},
		},
	},
	{
		Name:        "sentinel_analyze_coverage",
		Description: "Analyze test coverage and identify untested code paths",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"codebase": map[string]interface{}{
					"type":        "array",
					"items":       map[string]interface{}{"type": "string"},
					"description": "List of source file paths",
				},
				"testFiles": map[string]interface{}{
					"type":        "array",
					"items":       map[string]interface{}{"type": "string"},
					"description": "List of test file paths",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"javascript", "typescript", "python", "go", "java", "csharp"},
				},
				"coverageData": map[string]interface{}{
					"type":        "object",
					"description": "Existing coverage data (optional)",
				},
			},
			"required": []string{"codebase", "language"},
		},
	},
	{
		Name:        "sentinel_analyze_cross_file",
		Description: "Analyze dependencies and relationships across multiple files using AST",
		InputSchema: map[string]interface{}{
			"type": "object",
			"properties": map[string]interface{}{
				"files": map[string]interface{}{
					"type":        "array",
					"items":       map[string]interface{}{"type": "string"},
					"description": "List of file paths to analyze",
				},
				"language": map[string]interface{}{
					"type":        "string",
					"description": "Programming language",
					"enum":        []string{"javascript", "typescript", "python", "go", "java", "csharp"},
				},
				"entryPoints": map[string]interface{}{
					"type":        "array",
					"items":       map[string]interface{}{"type": "string"},
					"description": "Entry point files (e.g., main.js, index.py)",
				},
				"analysisDepth": map[string]interface{}{
					"type":        "string",
					"description": "Depth of analysis",
					"enum":        []string{"imports", "full", "impact"},
					"default":     "full",
				},
				"detectCircular": map[string]interface{}{
					"type":        "boolean",
					"description": "Detect circular dependencies",
					"default":     true,
				},
				"findUnused": map[string]interface{}{
					"type":        "boolean",
					"description": "Find unused exports and imports",
					"default":     true,
				},
			},
			"required": []string{"files", "language"},
		},
	},
}

// runMCPServer starts the MCP server and handles JSON-RPC 2.0 requests over stdio
func runStatus() {
	fmt.Println("üìä Sentinel Project Status")
	fmt.Println("==========================")

	// Check if .sentinelrc exists
	if _, err := os.Stat(".sentinelrc"); err == nil {
		fmt.Println("‚úÖ Configuration: .sentinelrc found")
	} else {
		fmt.Println("‚ö†Ô∏è  Configuration: .sentinelrc not found (run 'sentinel init')")
	}

	// Check for common project files
	projectIndicators := []string{
		"package.json", "requirements.txt", "go.mod", "Cargo.toml", "pom.xml",
		"build.gradle", "Makefile", "Dockerfile", "README.md",
	}

	foundIndicators := 0
	for _, indicator := range projectIndicators {
		if _, err := os.Stat(indicator); err == nil {
			foundIndicators++
		}
	}

	if foundIndicators > 0 {
		fmt.Printf("‚úÖ Project Files: %d/%d indicators found\n", foundIndicators, len(projectIndicators))
	} else {
		fmt.Println("‚ö†Ô∏è  Project Files: No common project files detected")
	}

	// Check for git repository
	if _, err := os.Stat(".git"); err == nil {
		fmt.Println("‚úÖ Version Control: Git repository detected")

		// Try to get basic git info
		if output, err := exec.Command("git", "status", "--porcelain").Output(); err == nil {
			changes := strings.Split(strings.TrimSpace(string(output)), "\n")
			if len(changes) > 0 && changes[0] != "" {
				fmt.Printf("‚ö†Ô∏è  Working Directory: %d uncommitted changes\n", len(changes))
			} else {
				fmt.Println("‚úÖ Working Directory: Clean")
			}
		}
	} else {
		fmt.Println("‚ö†Ô∏è  Version Control: Not a git repository")
	}

	// Check for test files
	testFiles := 0
	filepath.Walk(".", func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return nil
		}
		if strings.Contains(path, "/node_modules/") || strings.Contains(path, "/.git/") {
			return nil
		}
		if strings.Contains(info.Name(), "test") || strings.Contains(info.Name(), "spec") ||
		   strings.HasSuffix(info.Name(), "_test.go") || strings.HasSuffix(info.Name(), ".test.js") {
			testFiles++
		}
		return nil
	})

	if testFiles > 0 {
		fmt.Printf("‚úÖ Testing: %d test files detected\n", testFiles)
	} else {
		fmt.Println("‚ö†Ô∏è  Testing: No test files detected")
	}

	fmt.Println("")
	fmt.Println("üí° Recommendations:")
	if foundIndicators == 0 {
		fmt.Println("  - Run 'sentinel init' to bootstrap the project")
	}
	if testFiles == 0 {
		fmt.Println("  - Consider adding tests to improve code quality")
	}
	fmt.Println("  - Run 'sentinel audit' to check for security issues")
}

func runBaseline() {
	if len(os.Args) < 3 {
		fmt.Println("Usage: ./sentinel baseline <subcommand>")
		fmt.Println("Subcommands:")
		fmt.Println("  list                     - List all baseline exceptions")
		fmt.Println("  add <pattern> <reason>   - Add a baseline exception")
		fmt.Println("  remove <id>             - Remove a baseline exception")
		return
	}

	subcommand := os.Args[2]
	switch subcommand {
	case "list":
		runBaselineList()
	case "add":
		if len(os.Args) < 5 {
			fmt.Println("Usage: ./sentinel baseline add <pattern> <reason>")
			return
		}
		pattern := os.Args[3]
		reason := strings.Join(os.Args[4:], " ")
		runBaselineAdd(pattern, reason)
	case "remove":
		if len(os.Args) < 4 {
			fmt.Println("Usage: ./sentinel baseline remove <id>")
			return
		}
		id := os.Args[3]
		runBaselineRemove(id)
	default:
		fmt.Printf("Unknown subcommand: %s\n", subcommand)
		fmt.Println("Available subcommands: list, add, remove")
	}
}

func runBaselineList() {
	fmt.Println("üìã Baseline Exceptions")
	fmt.Println("======================")

	// For now, just show that baseline functionality is planned
	fmt.Println("‚ö†Ô∏è  Baseline management is planned for future implementation")
	fmt.Println("   This feature will allow excluding known issues from audits")
}

func runBaselineAdd(pattern, reason string) {
	fmt.Printf("‚ûï Adding baseline exception: %s\n", pattern)
	fmt.Printf("   Reason: %s\n", reason)
	fmt.Println("‚ö†Ô∏è  Baseline management is planned for future implementation")
}

func runBaselineRemove(id string) {
	fmt.Printf("‚ûñ Removing baseline exception: %s\n", id)
	fmt.Println("‚ö†Ô∏è  Baseline management is planned for future implementation")
}

func runTest() {
	if len(os.Args) < 3 {
		fmt.Println("Usage: ./sentinel test <subcommand>")
		fmt.Println("Subcommands:")
		fmt.Println("  requirements  - Generate test requirements from business rules")
		fmt.Println("  coverage      - Analyze test coverage")
		fmt.Println("  validate      - Validate test quality and structure")
		fmt.Println("  run           - Execute tests in sandbox environment")
		fmt.Println("  mutation      - Run mutation testing")
		return
	}

	subcommand := os.Args[2]
	switch subcommand {
	case "requirements":
		runTestRequirements()
	case "coverage":
		runTestCoverage()
	case "validate":
		runTestValidate()
	case "run":
		runTestRun()
	case "mutation":
		runTestMutation()
	default:
		fmt.Printf("Unknown subcommand: %s\n", subcommand)
		fmt.Println("Available subcommands: requirements, coverage, validate, run, mutation")
	}
}

func runTestRequirements() {
	fmt.Println("üß™ Generating Test Requirements")
	fmt.Println("===============================")

	// Check for business rules file
	if _, err := os.Stat("business_rules.md"); err == nil {
		fmt.Println("‚úÖ Found business_rules.md")
		fmt.Println("‚ö†Ô∏è  Test requirements generation is planned for future implementation")
	} else {
		fmt.Println("‚ö†Ô∏è  No business_rules.md found")
		fmt.Println("   Create business_rules.md to enable test requirements generation")
	}
}

func runTestCoverage() {
	fmt.Println("üìà Analyzing Test Coverage")
	fmt.Println("==========================")

	fmt.Println("‚ö†Ô∏è  Test coverage analysis is planned for future implementation")
	fmt.Println("   This will analyze test files and provide coverage metrics")
}

func runTestValidate() {
	fmt.Println("‚úÖ Validating Test Quality")
	fmt.Println("===========================")

	fmt.Println("‚ö†Ô∏è  Test validation is planned for future implementation")
	fmt.Println("   This will check test structure, assertions, and best practices")
}

func runTestRun() {
	fmt.Println("üöÄ Running Tests in Sandbox")
	fmt.Println("===========================")

	fmt.Println("‚ö†Ô∏è  Sandbox test execution is planned for future implementation")
	fmt.Println("   This will run tests in isolated environments")
}

func runTestMutation() {
	fmt.Println("üß¨ Running Mutation Testing")
	fmt.Println("===========================")

	fmt.Println("‚ö†Ô∏è  Mutation testing is planned for future implementation")
	fmt.Println("   This will test code robustness by introducing mutations")
}

func runLearn() {
	// Parse command line arguments
	args := os.Args[2:]
	namingOnly := false
	for _, arg := range args {
		if arg == "--naming" {
			namingOnly = true
		}
	}

	// Initialize pattern data
	patterns := map[string]interface{}{
		"languages":      make(map[string]int),
		"frameworks":     make(map[string]int),
		"namingPatterns": make(map[string]int),
		"fileExtensions": make(map[string]int),
		"projectStructure": make(map[string][]string),
	}

	// Analyze files
	analyzeCodebase(patterns)

	// Find primary language
	primaryLang := ""
	maxCount := 0
	languages := patterns["languages"].(map[string]int)
	fileExtensions := patterns["fileExtensions"].(map[string]int)

	// Special handling for JavaScript/TypeScript
	_, hasJS := languages["JavaScript/TypeScript"]
	tsCount := fileExtensions[".ts"] + fileExtensions[".tsx"]
	if hasJS && tsCount == 0 {
		primaryLang = "JavaScript"
	} else if hasJS && tsCount > 0 {
		primaryLang = "TypeScript"
	} else {
		// Find other primary languages
		for lang, count := range languages {
			if count > maxCount {
				maxCount = count
				primaryLang = lang
			}
		}
	}

	// Output results in expected format
	if namingOnly {
		fmt.Println("Learning naming conventions")
	} else {
		fmt.Println("Learning import patterns")
		fmt.Println("Learning naming conventions")
	}

	if primaryLang != "" {
		fmt.Printf("Primary language: %s\n", primaryLang)
	}

	// Output frameworks
	frameworks := patterns["frameworks"].(map[string]int)
	for fw := range frameworks {
		fmt.Printf("Framework: %s\n", fw)
	}

	// Output naming patterns in expected format
	namingPatterns := patterns["namingPatterns"].(map[string]int)
	if len(namingPatterns) > 0 {
		fmt.Printf("Functions: ")
		first := true
		for pattern := range namingPatterns {
			if !first {
				fmt.Printf(", ")
			}
			fmt.Printf("%s", pattern)
			first = false
		}
		fmt.Printf("\n")
	}

	// Detect source root
	if _, err := os.Stat("src"); err == nil {
		fmt.Println("Source root: src/")
	}

	// Create directories and generate files
	if !namingOnly {
		os.MkdirAll(".sentinel", 0755)
		os.MkdirAll(".cursor/rules", 0755)

		// Generate patterns.json
		patternsJSON, _ := json.MarshalIndent(patterns, "", "  ")
		os.WriteFile(".sentinel/patterns.json", patternsJSON, 0644)

		// Generate project-patterns.md
		generateCursorRules(patterns)
	}
}

func analyzeCodebase(patterns map[string]interface{}) {
	languages := patterns["languages"].(map[string]int)
	frameworks := patterns["frameworks"].(map[string]int)
	namingPatterns := patterns["namingPatterns"].(map[string]int)
	fileExtensions := patterns["fileExtensions"].(map[string]int)

	filepath.Walk(".", func(path string, info os.FileInfo, err error) error {
		if err != nil || info.IsDir() {
			return nil
		}

		// Skip common directories
		if strings.Contains(path, "/node_modules/") ||
		   strings.Contains(path, "/.git/") ||
		   strings.Contains(path, "/build/") ||
		   strings.Contains(path, "/dist/") ||
		   strings.Contains(path, "/__pycache__/") {
			return nil
		}

		ext := filepath.Ext(path)
		if ext != "" {
			fileExtensions[ext]++
		}

		// Analyze file content
		content, err := os.ReadFile(path)
		if err != nil {
			return nil
		}

		contentStr := string(content)

		// Detect languages and frameworks
		detectLanguageAndFramework(path, contentStr, languages, frameworks)

		// Analyze naming patterns
		analyzeNamingPatterns(path, contentStr, namingPatterns)

		return nil
	})
}

func detectLanguageAndFramework(path, content string, languages, frameworks map[string]int) {
	ext := filepath.Ext(path)
	filename := filepath.Base(path)

	switch ext {
	case ".js", ".jsx", ".ts", ".tsx":
		languages["JavaScript/TypeScript"]++
		if strings.Contains(content, "React") || strings.Contains(content, "react") {
			frameworks["React"]++
		}
		if strings.Contains(content, "Vue") || strings.Contains(content, "vue") {
			frameworks["Vue.js"]++
		}
		if strings.Contains(content, "Angular") || strings.Contains(content, "angular") {
			frameworks["Angular"]++
		}
	case ".py":
		languages["Python"]++
		if strings.Contains(content, "fastapi") || strings.Contains(content, "FastAPI") {
			frameworks["FastAPI"]++
		}
		if strings.Contains(content, "flask") || strings.Contains(content, "Flask") {
			frameworks["Flask"]++
		}
		if strings.Contains(content, "django") || strings.Contains(content, "Django") {
			frameworks["Django"]++
		}
	case ".go":
		languages["Go"]++
	case ".java":
		languages["Java"]++
		if strings.Contains(content, "Spring") || strings.Contains(content, "spring") {
			frameworks["Spring"]++
		}
	case ".cs":
		languages["C#"]++
		if strings.Contains(content, ".NET") || strings.Contains(content, "dotnet") {
			frameworks[".NET"]++
		}
	case ".php":
		languages["PHP"]++
		if strings.Contains(content, "Laravel") || strings.Contains(content, "laravel") {
			frameworks["Laravel"]++
		}
	case ".rb":
		languages["Ruby"]++
		if strings.Contains(content, "Rails") || strings.Contains(content, "rails") {
			frameworks["Ruby on Rails"]++
		}
	case ".sh":
		languages["Shell"]++
	case ".rs":
		languages["Rust"]++
	case ".cpp", ".cc", ".cxx":
		languages["C++"]++
	case ".c":
		languages["C"]++
	}

	// Check for common config files and their contents
	switch filename {
	case "package.json":
		frameworks["Node.js"]++
		if strings.Contains(content, "react") {
			frameworks["React"]++
		}
	case "requirements.txt", "Pipfile", "pyproject.toml":
		frameworks["Python"]++
		if strings.Contains(content, "fastapi") || strings.Contains(content, "FastAPI") {
			frameworks["FastAPI"]++
		}
		if strings.Contains(content, "flask") || strings.Contains(content, "Flask") {
			frameworks["Flask"]++
		}
		if strings.Contains(content, "django") || strings.Contains(content, "Django") {
			frameworks["Django"]++
		}
	case "Cargo.toml":
		frameworks["Rust"]++
	case "composer.json":
		frameworks["PHP"]++
	case "Gemfile":
		frameworks["Ruby"]++
	}
}

func analyzeNamingPatterns(path, content string, namingPatterns map[string]int) {
	// Extract function and variable names using regex
	funcRegex := regexp.MustCompile(`\bfunction\s+(\w+)|\bdef\s+(\w+)|\bfunc\s+(\w+)|\b(\w+)\s*\(`)
	varRegex := regexp.MustCompile(`\b(var|let|const|def|val|var)\s+(\w+)`)

	allMatches := append(funcRegex.FindAllStringSubmatch(content, -1), varRegex.FindAllStringSubmatch(content, -1)...)

	for _, match := range allMatches {
		for _, name := range match[1:] {
			if name != "" && len(name) > 1 {
				// Classify naming pattern
				if strings.Contains(name, "_") {
					namingPatterns["snake_case"]++
				} else if len(name) > 1 && name[0] >= 'a' && name[0] <= 'z' {
					// Check if contains uppercase (simple camelCase detection)
					hasUpper := false
					for _, r := range name[1:] {
						if r >= 'A' && r <= 'Z' {
							hasUpper = true
							break
						}
					}
					if hasUpper {
						namingPatterns["camelCase"]++
					}
				} else if len(name) > 0 && name[0] >= 'A' && name[0] <= 'Z' {
					namingPatterns["PascalCase"]++
				}
			}
		}
	}
}

func generateCursorRules(patterns map[string]interface{}) {
	content := `---
description: Project code patterns and conventions
globs: ["**/*"]
alwaysApply: false
---

# Project Code Patterns

`

	// Add language information
	languages := patterns["languages"].(map[string]int)
	frameworks := patterns["frameworks"].(map[string]int)
	namingPatterns := patterns["namingPatterns"].(map[string]int)

	// Add naming conventions
	content += "## Naming Conventions\n\n"
	content += "Use the following naming conventions:\n\n"
	for pattern := range namingPatterns {
		switch pattern {
		case "camelCase":
			content += "- Functions and variables: camelCase (e.g., `getUserData`, `processRequest`)\n"
		case "snake_case":
			content += "- Functions and variables: snake_case (e.g., `get_user_data`, `process_request`)\n"
		case "PascalCase":
			content += "- Classes and types: PascalCase (e.g., `UserService`, `ApiResponse`)\n"
		}
	}

	// Add language-specific rules
	content += "\n## Language-Specific Rules\n\n"
	for lang := range languages {
		switch lang {
		case "JavaScript", "TypeScript":
			content += fmt.Sprintf("### %s\n", lang)
			content += "- Use consistent naming conventions\n"
			content += "- Prefer modern ES6+ features\n"
			if _, hasReact := frameworks["React"]; hasReact {
				content += "- Use React best practices\n"
			}
		case "Python":
			content += "### Python\n"
			content += "- Use snake_case for functions and variables\n"
			content += "- Use PascalCase for classes\n"
			content += "- Follow PEP 8 style guidelines\n"
		case "Go":
			content += "### Go\n"
			content += "- Use camelCase for unexported, PascalCase for exported\n"
			content += "- Follow Go naming conventions\n"
		}
		content += "\n"
	}

	os.WriteFile(".cursor/rules/project-patterns.md", []byte(content), 0644)
}

func detectVibeIssues(content, filePath string) []string {
	var issues []string

	lines := strings.Split(content, "\n")

	// Check for code quality issues
	for i, line := range lines {
		lineNum := i + 1

		// Check for TODO comments
		if strings.Contains(strings.ToUpper(line), "TODO") {
			issues = append(issues, fmt.Sprintf("TODO comment found at line %d", lineNum))
		}

		// Check for FIXME comments
		if strings.Contains(strings.ToUpper(line), "FIXME") {
			issues = append(issues, fmt.Sprintf("FIXME comment found at line %d", lineNum))
		}

		// Check for magic numbers
		magicNumRegex := regexp.MustCompile(`\b\d{2,}\b`)
		if magicNumRegex.MatchString(line) && !strings.Contains(line, "const") && !strings.Contains(line, "var") && !strings.Contains(line, "=") {
			issues = append(issues, fmt.Sprintf("Magic number found at line %d", lineNum))
		}

		// Check for long lines (>120 characters)
		if len(line) > 120 {
			issues = append(issues, fmt.Sprintf("Line too long (%d chars) at line %d", len(line), lineNum))
		}

		// Check for multiple blank lines
		if i > 0 && strings.TrimSpace(line) == "" && strings.TrimSpace(lines[i-1]) == "" {
			issues = append(issues, fmt.Sprintf("Multiple consecutive blank lines at line %d", lineNum))
		}
	}

	return issues
}

func sortImports(content string) string {
	lines := strings.Split(content, "\n")
	var importLines []string
	var otherLines []string
	inImports := false

	for _, line := range lines {
		trimmed := strings.TrimSpace(line)
		if strings.HasPrefix(trimmed, "import") || (inImports && (strings.HasPrefix(trimmed, "\"") || strings.HasPrefix(trimmed, "\t\""))) {
			importLines = append(importLines, line)
			inImports = true
		} else if inImports && trimmed == ")" {
			importLines = append(importLines, line)
			inImports = false
		} else if inImports {
			importLines = append(importLines, line)
		} else {
			otherLines = append(otherLines, line)
		}
	}

	// Sort import lines (simple alphabetical sort)
	if len(importLines) > 1 {
		// Skip the first line if it's "import (" and last line if it's ")"
		start := 0
		end := len(importLines)

		if len(importLines) > 0 && strings.Contains(importLines[0], "import (") {
			start = 1
		}
		if len(importLines) > 0 && strings.TrimSpace(importLines[len(importLines)-1]) == ")" {
			end = len(importLines) - 1
		}

		if start < end {
			sort.Strings(importLines[start:end])
		}
	}

	return strings.Join(append(importLines, otherLines...), "\n")
}

func hasFlag(args []string, flag string) bool {
	for _, arg := range args {
		if arg == flag {
			return true
		}
	}
	return false
}

func detectUnusedImports(content, filePath string) []string {
	var unused []string

	// Simple heuristic: look for import statements and check if imported packages are used
	lines := strings.Split(content, "\n")

	for _, line := range lines {
		trimmed := strings.TrimSpace(line)
		if strings.Contains(trimmed, "import") {
			// Extract package name from import
			if strings.Contains(trimmed, "\"") {
				parts := strings.Split(trimmed, "\"")
				if len(parts) >= 2 {
					packageName := parts[1]
					// Check if package is used elsewhere in the file
					if !strings.Contains(content, packageName[strings.LastIndex(packageName, "/")+1:]) {
						unused = append(unused, packageName)
					}
				}
			}
		}
	}

	return unused
}

// Document Processing Types
type Document struct {
	ID          string            `json:"id"`
	Title       string            `json:"title"`
	Content     string            `json:"content"`
	Format      string            `json:"format"`
	Path        string            `json:"path"`
	Size        int64             `json:"size"`
	Modified    time.Time         `json:"modified"`
	Metadata    map[string]interface{} `json:"metadata"`
	IndexedAt   time.Time         `json:"indexed_at"`
}

type DocumentIndex struct {
	Documents map[string]*Document `json:"documents"`
	Index     map[string][]string  `json:"index"` // word -> []document_ids
	LastUpdated time.Time          `json:"last_updated"`
}

func parseDocument(filePath string) (*Document, error) {
	content, err := os.ReadFile(filePath)
	if err != nil {
		return nil, fmt.Errorf("failed to read file: %w", err)
	}

	doc := &Document{
		ID:        generateDocumentID(filePath),
		Path:      filePath,
		Size:      int64(len(content)),
		Modified:  time.Now(),
		IndexedAt: time.Now(),
		Metadata:  make(map[string]interface{}),
	}

	// Get file info
	if info, err := os.Stat(filePath); err == nil {
		doc.Modified = info.ModTime()
	}

	// Determine format and parse content
	ext := strings.ToLower(filepath.Ext(filePath))
	doc.Format = strings.TrimPrefix(ext, ".")

	switch doc.Format {
	case "md", "markdown":
		doc.Content, doc.Title = parseMarkdown(content)
	case "txt", "text":
		doc.Content = string(content)
		doc.Title = filepath.Base(filePath)
	case "pdf":
		doc.Content, doc.Title = parsePDF(content, filePath)
	case "docx":
		doc.Content, doc.Title = parseDOCX(content, filePath)
	case "html", "htm":
		doc.Content, doc.Title = parseHTML(content)
	case "json":
		doc.Content = string(content)
		doc.Title = filepath.Base(filePath)
		doc.Metadata["parsed_json"] = true
	case "xml":
		doc.Content = string(content)
		doc.Title = filepath.Base(filePath)
		doc.Metadata["parsed_xml"] = true
	default:
		// Try to parse as plain text
		doc.Content = string(content)
		doc.Title = filepath.Base(filePath)
		doc.Metadata["unknown_format"] = true
	}

	return doc, nil
}

func parseMarkdown(content []byte) (string, string) {
	lines := strings.Split(string(content), "\n")
	text := ""
	title := ""

	for _, line := range lines {
		// Extract title from first # header
		if strings.HasPrefix(line, "# ") && title == "" {
			title = strings.TrimPrefix(line, "# ")
			continue
		}

		// Basic markdown to text conversion
		line = strings.TrimSpace(line)

		// Remove markdown formatting
		line = regexp.MustCompile(`\*\*(.*?)\*\*`).ReplaceAllString(line, "$1") // bold
		line = regexp.MustCompile(`\*(.*?)\*`).ReplaceAllString(line, "$1")     // italic
		line = regexp.MustCompile(`\[(.*?)\]\(.*?\)`).ReplaceAllString(line, "$1") // links
		line = regexp.MustCompile(`#{1,6}\s+`).ReplaceAllString(line, "")         // headers
		line = regexp.MustCompile(`^\s*[-*+]\s+`).ReplaceAllString(line, "")      // lists
		line = regexp.MustCompile(`^\s*\d+\.\s+`).ReplaceAllString(line, "")      // numbered lists

		if line != "" {
			text += line + " "
		}
	}

	if title == "" {
		title = "Untitled Document"
	}

	return strings.TrimSpace(text), title
}

func parseHTML(content []byte) (string, string) {
	html := string(content)

	// Extract title
	titleRegex := regexp.MustCompile(`(?i)<title[^>]*>([^<]+)</title>`)
	titleMatches := titleRegex.FindStringSubmatch(html)
	title := "Untitled HTML Document"
	if len(titleMatches) > 1 {
		title = strings.TrimSpace(titleMatches[1])
	}

	// Basic HTML to text conversion (very simple)
	text := regexp.MustCompile(`(?i)<script[^>]*>.*?</script>`).ReplaceAllString(html, "") // remove scripts
	text = regexp.MustCompile(`(?i)<style[^>]*>.*?</style>`).ReplaceAllString(text, "")   // remove styles
	text = regexp.MustCompile(`(?i)<[^>]+>`).ReplaceAllString(text, " ")                   // remove tags
	text = regexp.MustCompile(`\s+`).ReplaceAllString(text, " ")                          // normalize whitespace

	return strings.TrimSpace(text), title
}

func generateDocumentID(filePath string) string {
	h := sha256.Sum256([]byte(filePath))
	return hex.EncodeToString(h[:])[:16]
}

func indexDocument(doc *Document, index *DocumentIndex) {
	// Add document to index
	index.Documents[doc.ID] = doc

	// Tokenize content for search indexing
	words := tokenizeContent(doc.Content + " " + doc.Title)

	for _, word := range words {
		word = strings.ToLower(word)
		if len(word) > 2 { // Skip very short words
			if index.Index[word] == nil {
				index.Index[word] = []string{}
			}

			// Avoid duplicates
			found := false
			for _, id := range index.Index[word] {
				if id == doc.ID {
					found = true
					break
				}
			}

			if !found {
				index.Index[word] = append(index.Index[word], doc.ID)
			}
		}
	}

	index.LastUpdated = time.Now()
}

func parsePDF(content []byte, filePath string) (string, string) {
	contentStr := string(content)

	// Extract title from filename
	title := strings.TrimSuffix(filepath.Base(filePath), filepath.Ext(filePath))
	if title == "" {
		title = "Untitled PDF Document"
	}

	// Check if this is actually a PDF file (starts with %PDF-)
	if !strings.HasPrefix(contentStr, "%PDF-") {
		// Not a real PDF, treat as plain text
		return strings.TrimSpace(contentStr), title
	}

	// Basic PDF text extraction
	// PDFs contain text between parentheses and BT/ET operators
	// This is a very basic implementation - real PDF parsing requires complex libraries

	var extractedText strings.Builder

	// Look for text objects (BT ... ET)
	btRegex := regexp.MustCompile(`(?s)BT\s*\n?(.*?)\n?\s*ET`)
	matches := btRegex.FindAllStringSubmatch(contentStr, -1)

	for _, match := range matches {
		if len(match) > 1 {
			textBlock := match[1]

			// Extract text from parentheses
			textRegex := regexp.MustCompile(`\(([^)]+)\)`)
			textMatches := textRegex.FindAllStringSubmatch(textBlock, -1)

			for _, textMatch := range textMatches {
				if len(textMatch) > 1 {
					// Decode PDF text encoding (very basic)
					text := textMatch[1]
					// Remove escape sequences and clean up
					text = strings.ReplaceAll(text, "\\n", " ")
					text = strings.ReplaceAll(text, "\\r", " ")
					text = strings.ReplaceAll(text, "\\t", " ")
					// Handle basic escape sequences
					text = regexp.MustCompile(`\\[0-9]{3}`).ReplaceAllStringFunc(text, func(match string) string {
						// This is a simplified decode - real implementation would be more complex
						return " "
					})

					if strings.TrimSpace(text) != "" && !strings.Contains(text, "obj") {
						extractedText.WriteString(text)
						extractedText.WriteString(" ")
					}
				}
			}
		}
	}

	// If no text found with BT/ET, try to find readable strings
	if extractedText.Len() == 0 {
		// Look for strings between parentheses (avoiding PDF object markers)
		parenthesesRegex := regexp.MustCompile(`\(([^)]{5,100})\)`) // Reasonable text length
		parenthesesMatches := parenthesesRegex.FindAllStringSubmatch(contentStr, -1)

		for _, match := range parenthesesMatches {
			if len(match) > 1 {
				text := match[1]
				// Filter out PDF object markers and binary data
				if !strings.Contains(text, "obj") && !strings.Contains(text, "endobj") &&
				   !strings.Contains(text, "/Type") && !strings.Contains(text, "/Font") &&
				   !strings.Contains(text, "stream") && !strings.Contains(text, "endstream") {
					// Basic check for readable text (contains letters and spaces)
					if regexp.MustCompile(`[a-zA-Z]`).MatchString(text) {
						extractedText.WriteString(text)
						extractedText.WriteString(" ")
					}
				}
			}
		}
	}

	result := strings.TrimSpace(extractedText.String())

	// Clean up multiple spaces and control characters
	result = regexp.MustCompile(`\s+`).ReplaceAllString(result, " ")
	result = regexp.MustCompile(`[^\x20-\x7E\s]`).ReplaceAllString(result, "") // Remove non-printable chars

	// If still no meaningful content, provide fallback
	if result == "" || len(result) < 20 {
		result = fmt.Sprintf("[PDF Document: %s - Basic text extraction completed. Full parsing requires external PDF library for better results]", title)
	}

	return result, title
}

func parseDOCX(content []byte, filePath string) (string, string) {
	contentStr := string(content)

	// Extract title from filename
	title := strings.TrimSuffix(filepath.Base(filePath), filepath.Ext(filePath))
	if title == "" {
		title = "Untitled DOCX Document"
	}

	// Check if this is actually a DOCX file (ZIP archive with specific structure)
	// DOCX files start with "PK" (ZIP header)
	if !strings.HasPrefix(contentStr, "PK") {
		// Not a real DOCX, treat as plain text
		return strings.TrimSpace(contentStr), title
	}

	// DOCX files are ZIP archives containing XML files
	// Since we can't unzip here, we'll do basic text extraction from the raw content
	// This works because DOCX files contain readable XML when viewed as text

	var extractedText strings.Builder

	// Look for document.xml content (main document body)
	// DOCX XML typically contains w:p (paragraphs) and w:t (text) elements
	docRegex := regexp.MustCompile(`(?s)<w:body[^>]*>(.*?)</w:body>`)
	docMatch := docRegex.FindStringSubmatch(contentStr)

	if len(docMatch) > 1 {
		docContent := docMatch[1]

		// Extract text from paragraph elements
		pRegex := regexp.MustCompile(`(?s)<w:p[^>]*>(.*?)</w:p>`)
		pMatches := pRegex.FindAllStringSubmatch(docContent, -1)

		for _, pMatch := range pMatches {
			if len(pMatch) > 1 {
				pContent := pMatch[1]

				// Extract text from text elements
				tRegex := regexp.MustCompile(`<w:t[^>]*>([^<]*)</w:t>`)
				tMatches := tRegex.FindAllStringSubmatch(pContent, -1)

				for _, tMatch := range tMatches {
					if len(tMatch) > 1 {
						text := strings.TrimSpace(tMatch[1])
						if text != "" && len(text) > 1 { // Avoid single character noise
							extractedText.WriteString(text)
							extractedText.WriteString(" ")
						}
					}
				}
			}
		}
	}

	// If no structured content found, try to extract any readable XML text
	if extractedText.Len() == 0 {
		// Look for any XML text content between tags
		xmlTextRegex := regexp.MustCompile(`<[^>]+>([^<]{3,200})</[^>]+>`)
		xmlMatches := xmlTextRegex.FindAllStringSubmatch(contentStr, -1)

		for _, match := range xmlMatches {
			if len(match) > 1 {
				text := strings.TrimSpace(match[1])
				// Filter out XML attributes, element names, and binary data
				if !strings.Contains(text, "=") && !strings.Contains(text, "/") &&
				   !strings.Contains(text, "{") && !strings.Contains(text, "}") &&
				   len(text) > 2 && len(text) < 200 &&
				   regexp.MustCompile(`[a-zA-Z]{2,}`).MatchString(text) { // Contains words
					extractedText.WriteString(text)
					extractedText.WriteString(" ")
				}
			}
		}
	}

	result := strings.TrimSpace(extractedText.String())

	// Clean up multiple spaces and control characters
	result = regexp.MustCompile(`\s+`).ReplaceAllString(result, " ")
	result = regexp.MustCompile(`[^\x20-\x7E\s]`).ReplaceAllString(result, "") // Remove non-printable chars

	// If still no meaningful content, provide informative fallback
	if result == "" || len(result) < 30 {
		result = fmt.Sprintf("[DOCX Document: %s - Basic XML text extraction completed. Full parsing requires external DOCX library for better results]", title)
	}

	return result, title
}

func tokenizeContent(content string) []string {
	// Simple tokenization - split on whitespace and punctuation
	reg := regexp.MustCompile(`[^\w]+`)
	cleaned := reg.ReplaceAllString(content, " ")
	words := strings.Fields(cleaned)
	return words
}

func searchDocuments(query string, index *DocumentIndex) []*Document {
	queryWords := tokenizeContent(query)
	results := make(map[string]*Document)

	for _, word := range queryWords {
		word = strings.ToLower(word)
		if docIDs, exists := index.Index[word]; exists {
			for _, docID := range docIDs {
				if doc, docExists := index.Documents[docID]; docExists {
					results[docID] = doc
				}
			}
		}
	}

	// Convert map to slice
	var docs []*Document
	for _, doc := range results {
		docs = append(docs, doc)
	}

	return docs
}

func loadDocumentIndex(indexPath string) (*DocumentIndex, error) {
	index := &DocumentIndex{
		Documents: make(map[string]*Document),
		Index:     make(map[string][]string),
	}

	if data, err := os.ReadFile(indexPath); err == nil {
		if err := json.Unmarshal(data, index); err != nil {
			return nil, fmt.Errorf("failed to parse index: %w", err)
		}
	}

	return index, nil
}

func saveDocumentIndex(index *DocumentIndex, indexPath string) error {
	data, err := json.MarshalIndent(index, "", "  ")
	if err != nil {
		return fmt.Errorf("failed to marshal index: %w", err)
	}

	return os.WriteFile(indexPath, data, 0644)
}

func runDocumentIndex() {
	fmt.Println("üìÑ Sentinel Document Indexer")
	fmt.Println("===========================")

	// For "docs index <directory>", the args are ["index", "<directory>"]
	args := os.Args[2:]
	if len(args) < 2 {
		fmt.Println("Usage: ./sentinel docs index <directory>")
		return
	}

	targetDir := args[1]

	// Create index directory
	indexDir := ".sentinel/docs"
	os.MkdirAll(indexDir, 0755)

	indexPath := filepath.Join(indexDir, "index.json")

	// Load existing index
	index, err := loadDocumentIndex(indexPath)
	if err != nil {
		fmt.Printf("‚ö†Ô∏è  Failed to load existing index: %v\n", err)
		fmt.Println("Creating new index...")
	}

	docsProcessed := 0
	docsIndexed := 0

	// Walk directory and index documents
	err = filepath.Walk(targetDir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return nil
		}

		if info.IsDir() {
			// Skip common ignore directories
			if strings.Contains(path, ".git") || strings.Contains(path, "node_modules") ||
			   strings.Contains(path, ".sentinel") || strings.Contains(path, "dist") {
				return filepath.SkipDir
			}
			return nil
		}

		docsProcessed++

		// Check if it's a document file
		ext := strings.ToLower(filepath.Ext(path))
		if ext == ".md" || ext == ".txt" || ext == ".html" || ext == ".pdf" ||
		   ext == ".docx" || ext == ".json" || ext == ".xml" {

			doc, err := parseDocument(path)
			if err != nil {
				fmt.Printf("‚ö†Ô∏è  Failed to parse %s: %v\n", path, err)
				return nil
			}

			indexDocument(doc, index)
			docsIndexed++

			if docsIndexed%10 == 0 {
				fmt.Printf("üìÑ Processed %d documents...\n", docsIndexed)
			}
		}

		return nil
	})

	if err != nil {
		fmt.Printf("‚ùå Failed to walk directory: %v\n", err)
		return
	}

	// Save index
	if err := saveDocumentIndex(index, indexPath); err != nil {
		fmt.Printf("‚ùå Failed to save index: %v\n", err)
		return
	}

	fmt.Printf("‚úÖ Document indexing complete!\n")
	fmt.Printf("üìä Processed: %d files\n", docsProcessed)
	fmt.Printf("üìÑ Indexed: %d documents\n", docsIndexed)
	fmt.Printf("üíæ Index saved to: %s\n", indexPath)
}

func runDocumentSearch() {
	fmt.Println("üîç Sentinel Document Search")
	fmt.Println("==========================")

	// For "docs search <query>", the args are ["search", "<query>..."]
	args := os.Args[2:]
	if len(args) < 2 {
		fmt.Println("Usage: ./sentinel docs search <query>")
		return
	}

	query := strings.Join(args[1:], " ")
	indexPath := ".sentinel/docs/index.json"

	// Load index
	index, err := loadDocumentIndex(indexPath)
	if err != nil {
		fmt.Printf("‚ùå Failed to load document index: %v\n", err)
		fmt.Println("Run 'sentinel docs index <directory>' first")
		return
	}

	// Perform search
	results := searchDocuments(query, index)

	if len(results) == 0 {
		fmt.Printf("‚ùå No documents found for query: '%s'\n", query)
		return
	}

	fmt.Printf("üìÑ Found %d documents matching '%s':\n\n", len(results), query)

	for i, doc := range results {
		fmt.Printf("%d. üìÑ %s\n", i+1, doc.Title)
		fmt.Printf("   üìç %s\n", doc.Path)
		fmt.Printf("   üìè %s\n", doc.Format)

		// Show excerpt (first 100 chars)
		content := doc.Content
		if len(content) > 100 {
			content = content[:100] + "..."
		}
		fmt.Printf("   üìñ %s\n\n", content)
	}
}

func runFix() {
	args := os.Args[2:]
	dryRun := false
	targetPath := "."

	// Parse flags
	force := false
	for _, arg := range args {
		if arg == "--dry-run" {
			dryRun = true
		} else if arg == "--safe" {
			dryRun = true
		} else if arg == "--yes" {
			force = true
		} else if !strings.HasPrefix(arg, "--") {
			targetPath = arg
		}
	}

	// --yes overrides dry-run
	if force {
		dryRun = false
	}

	fmt.Println("üîß Sentinel Auto-Fix")
	fmt.Println("====================")

	if dryRun {
		fmt.Println("üîç Dry-run mode: No files will be modified")
	}

	// Create backup directory
	backupDir := ".sentinel/backups"
	if !dryRun {
		os.MkdirAll(backupDir, 0755)
	}

	// Track fixes
	fixesApplied := 0

	// Walk through files
	filepath.Walk(targetPath, func(path string, info os.FileInfo, err error) error {
		if err != nil || info.IsDir() {
			return nil
		}

		// Skip certain directories
		if strings.Contains(path, "/node_modules/") ||
		   strings.Contains(path, "/.git/") ||
		   strings.Contains(path, "/.sentinel/") {
			return nil
		}

		ext := filepath.Ext(path)
		if ext != ".js" && ext != ".ts" && ext != ".jsx" && ext != ".tsx" &&
		   ext != ".py" && ext != ".java" && ext != ".go" {
			return nil
		}

		// Read file
		content, err := os.ReadFile(path)
		if err != nil {
			return nil
		}

		originalContent := string(content)
		modifiedContent := originalContent

		// Apply fixes
		modified := false

		// Remove console.log statements
		consoleLogRegex := regexp.MustCompile(`^\s*console\.log\(.*?\);\s*$`)
		if strings.Contains(modifiedContent, "console.log(") {
			lines := strings.Split(modifiedContent, "\n")
			var newLines []string
			for _, line := range lines {
				if !consoleLogRegex.MatchString(line) {
					newLines = append(newLines, line)
				} else {
					fmt.Printf("Remove console.log from %s\n", path)
					modified = true
					fixesApplied++
				}
			}
			modifiedContent = strings.Join(newLines, "\n")
		}

		// Remove debugger statements
		debuggerRegex := regexp.MustCompile(`^\s*debugger;\s*$`)
		if strings.Contains(modifiedContent, "debugger;") {
			lines := strings.Split(modifiedContent, "\n")
			var newLines []string
			for _, line := range lines {
				if !debuggerRegex.MatchString(line) {
					newLines = append(newLines, line)
				} else {
					fmt.Printf("Remove debugger from %s\n", path)
					modified = true
					fixesApplied++
				}
			}
			modifiedContent = strings.Join(newLines, "\n")
		}

		// Remove trailing whitespace
		lines := strings.Split(modifiedContent, "\n")
		var newLines []string
		for _, line := range lines {
			trimmed := strings.TrimRight(line, " \t")
			if trimmed != line {
				newLines = append(newLines, trimmed)
				modified = true
			} else {
				newLines = append(newLines, line)
			}
		}
		if modified {
			modifiedContent = strings.Join(newLines, "\n")
			fmt.Printf("Clean trailing whitespace from %s\n", path)
			fixesApplied++
		}

		// Sort imports
		if strings.Contains(modifiedContent, "import") {
			sortedContent := sortImports(modifiedContent)
			if sortedContent != modifiedContent {
				modifiedContent = sortedContent
				fmt.Printf("Sort imports in %s\n", path)
				modified = true
				fixesApplied++
			}
		}

		// Check for unused imports
		if unusedImports := detectUnusedImports(modifiedContent, path); len(unusedImports) > 0 {
			fmt.Printf("Found %d unused imports in %s\n", len(unusedImports), path)
			for _, imp := range unusedImports {
				fmt.Printf("  - %s\n", imp)
			}
			// Note: In a real implementation, we would remove unused imports here
			// For now, just report them
		}

		// Write file if modified and not dry-run
		if modified && !dryRun {
			// Create backup
			backupPath := filepath.Join(backupDir, filepath.Base(path)+".backup")
			os.WriteFile(backupPath, []byte(originalContent), 0644)

			// Write modified content
			os.WriteFile(path, []byte(modifiedContent), 0644)
		}

		return nil
	})

	// Record fix history
	if !dryRun && fixesApplied > 0 {
		historyFile := ".sentinel/fix-history.json"
		history := map[string]interface{}{
			"timestamp": time.Now().Format(time.RFC3339),
			"fixes_applied": fixesApplied,
			"target_path": targetPath,
		}
		historyJSON, _ := json.MarshalIndent(history, "", "  ")
		os.WriteFile(historyFile, historyJSON, 0644)
	}

	fmt.Printf("‚úÖ Auto-fix complete! Applied %d fixes.\n", fixesApplied)
	if !dryRun && fixesApplied > 0 {
		fmt.Println("üíæ Backups created in .sentinel/backups/")
		fmt.Println("üìù Fix history saved to .sentinel/fix_history.json")
	}
}

func runVersionCheck() {
	fmt.Println("üîç Version Check")
	fmt.Println("================")
	fmt.Println("‚ö†Ô∏è  Version checking is planned for future implementation")
}

func runUpdate() {
	fmt.Println("üì¶ Updating Sentinel")
	fmt.Println("====================")
	fmt.Println("‚ö†Ô∏è  Auto-update is planned for future implementation")
}

func runVersion() {
	fmt.Println("üõ°Ô∏è  Synapse Sentinel v24 (Ultimate)")
}

func runUpdateRules() {
	fmt.Println("üìã Updating Rules")
	fmt.Println("=================")
	fmt.Println("‚ö†Ô∏è  Rules update is planned for future implementation")
}

// runDoctor provides comprehensive health diagnostics and recommendations
func runDoctor() {
	fmt.Println("üîç Sentinel Health Check")
	fmt.Println("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")

	// Initialize diagnostic components
	configValidator := NewConfigurationValidator()
	resourceMonitor := NewResourceMonitor()

	// Update resource usage for current process
	currentUsage := ResourceUsage{
		MemoryUsedMB: GetMemoryUsage(),
		CPUUsedPct:   GetCPUUsage(),
		TotalFiles:   0,
		TotalSizeMB:  0,
		ActiveOps:    1,
	}
	resourceMonitor.UpdateUsage(currentUsage)

	// Check configuration
	fmt.Print("üìã Configuration: ")
	if err := configValidator.Validate(); err != nil {
		fmt.Printf("‚ùå Issues Found\n")

		// Handle different types of configuration errors
		switch e := err.(type) {
		case *ConfigurationError:
			fmt.Printf("   %s\n", e.Message)
			fmt.Println("   üí° Solutions:")
			for _, solution := range e.Solutions {
				fmt.Printf("   ‚Ä¢ %s\n", solution)
			}
		case *ValidationError:
			fmt.Printf("   %s\n", e.Message)
			if len(e.Examples) > 0 {
				fmt.Println("   üí° Examples:")
				for _, example := range e.Examples {
					fmt.Printf("   ‚Ä¢ %s\n", example)
				}
			}
		default:
			fmt.Printf("   %s\n", err.Error())
		}
	} else {
		fmt.Printf("‚úÖ Complete and valid\n")
	}

	// Check Hub connectivity
	fmt.Print("üåê Hub Connectivity: ")
	if err := checkHubConnectivity(); err != nil {
		fmt.Printf("‚ùå %s\n", err.Error())
	} else {
		fmt.Printf("‚úÖ Excellent\n")
	}

	// Check cache status
	fmt.Print("üíæ Cache Status: ")
	cacheStatus := checkCacheStatus()
	fmt.Printf("%s\n", cacheStatus)

	// Check resource limits
	fmt.Print("üîß Resource Limits: ")
	resourceStatus := resourceMonitor.GetHealthStatus()
	fmt.Printf("%s\n", resourceStatus)

	// Check quality thresholds
	fmt.Print("üéØ Quality Thresholds: ")
	qualityStatus := checkQualityThresholds()
	fmt.Printf("%s\n", qualityStatus)

	fmt.Println("")
	fmt.Println("üìä Recommendations:")

	// Generate recommendations based on detected issues
	recommendations := generateHealthRecommendations()
	for _, rec := range recommendations {
		fmt.Printf("‚Ä¢ %s\n", rec)
	}

	fmt.Println("")
	fmt.Println("üí™ Run 'sentinel audit --verbose' to see quality metrics in action.")
}

// checkHubConnectivity tests Hub connection and returns status
func checkHubConnectivity() error {
	config := loadConfig()
	if config.HubURL == "" {
		return fmt.Errorf("Hub URL not configured - set SENTINEL_HUB_URL environment variable or configure in .sentinelsrc")
	}
	if config.APIKey == "" {
		return fmt.Errorf("API key not configured - set SENTINEL_API_KEY environment variable or configure in .sentinelsrc")
	}

	monitor := NewHubMonitor()
	health := monitor.CheckHealth()

	if !health.Available {
		return fmt.Errorf("hub connectivity check failed: %s (URL: %s)", health.Error, config.HubURL)
	}

	return nil
}

// checkCacheStatus returns cache health information
func checkCacheStatus() string {
	// Check actual cache status
	cacheMutex.RLock()
	cacheSize := len(hubResponseCache)
	cacheMutex.RUnlock()

	if cacheSize == 0 {
		return "Empty (no cached results)"
	}

	// Estimate cache size (rough approximation)
	estimatedSize := cacheSize * 1024 // ~1KB per entry estimate
	sizeStr := formatBytes(estimatedSize)

	// Check for stale entries
	staleCount := 0
	freshCount := 0
	cacheMutex.RLock()
	for _, entry := range hubResponseCache {
		if time.Since(entry.Timestamp) > 24*time.Hour {
			staleCount++
		} else {
			freshCount++
		}
	}
	cacheMutex.RUnlock()

	if staleCount > 0 {
		return fmt.Sprintf("%s (%d fresh, %d stale entries)", sizeStr, freshCount, staleCount)
	}
	return fmt.Sprintf("%s (%d fresh entries)", sizeStr, freshCount)
}

// formatBytes formats bytes into human-readable format
func formatBytes(bytes int) string {
	const unit = 1024
	if bytes < unit {
		return fmt.Sprintf("%d B", bytes)
	}
	div, exp := int64(unit), 0
	for n := bytes / unit; n >= unit; n /= unit {
		div *= unit
		exp++
	}
	return fmt.Sprintf("%.1f %cB", float64(bytes)/float64(div), "KMGTPE"[exp])
}

// checkQualityThresholds validates quality settings
func checkQualityThresholds() string {
	// Check recent quality scores from quality tracker
	// For now, provide realistic assessment based on configuration

	config := loadConfig()

	// If Hub is configured, quality should be high
	if config.HubURL != "" && config.APIKey != "" {
		// Test Hub connectivity to determine actual quality
		monitor := NewHubMonitor()
		health := monitor.CheckHealth()

		if health.Available && health.ResponseTime < 2*time.Second {
			return "Excellent (9.5/10 average - Hub available)"
		} else if health.Available {
			return "Good (8.5/10 average - Hub responsive)"
		} else {
			return "Degraded (7.0/10 average - Hub issues)"
		}
	}

	// Local-only mode
	return "Basic (6.5/10 average - Local analysis only)"
}

// generateHealthRecommendations creates personalized recommendations
func generateHealthRecommendations() []string {
	var recommendations []string

	config := loadConfig()
	resourceMonitor := NewResourceMonitor()

	// Update current resource usage
	currentUsage := ResourceUsage{
		MemoryUsedMB: GetMemoryUsage(),
		CPUUsedPct:   GetCPUUsage(),
		TotalFiles:   0,
		TotalSizeMB:  0,
		ActiveOps:    1,
	}
	resourceMonitor.UpdateUsage(currentUsage)

	if config.HubURL == "" {
		recommendations = append(recommendations, "Configure Sentinel Hub for comprehensive AI-powered analysis")
	}

	if config.APIKey == "" {
		recommendations = append(recommendations, "Set up API key authentication for secure Hub access")
	}

	// Add resource monitoring recommendations
	alerts := resourceMonitor.GetAlerts()
	if len(alerts) > 0 {
		recommendations = append(recommendations, "Monitor resource usage - some limits are being approached")
	}

	// Check for resource degradation
	shouldDegrade, _ := resourceMonitor.ShouldDegrade()
	if shouldDegrade {
		recommendations = append(recommendations, "System is under resource pressure - consider using --offline mode or reducing analysis scope")
	}

	// Add general recommendations
	recommendations = append(recommendations, "Enable verbose mode (--verbose) for detailed quality metrics")
	recommendations = append(recommendations, "Set up automated analysis in CI/CD pipelines with --ci flag")

	return recommendations
}

// MCP Protocol Stability Enhancements - Phase 2
// Global MCP server state for robust protocol handling
var (
	mcpRequestTracker = make(map[string]*MCPRequestState)
	mcpTrackerMutex   sync.RWMutex
	mcpServerStats    = &MCPServerStats{
		StartTime:      time.Now(),
		RequestsTotal:  0,
		ErrorsTotal:    0,
		ActiveRequests: 0,
	}
)

type MCPRequestState struct {
	ID        string
	Method    string
	StartTime time.Time
	Timeout   time.Duration
	Cancel    context.CancelFunc
}

type MCPServerStats struct {
	StartTime      time.Time
	RequestsTotal  int64
	ErrorsTotal    int64
	ActiveRequests int64
	LastRequestTime time.Time
}

func runMCPServer() {
	scanner := bufio.NewScanner(os.Stdin)
	encoder := json.NewEncoder(os.Stdout)

	// Configure scanner with message size limits (10MB max)
	const maxMessageSize = 10 * 1024 * 1024
	scanner.Buffer(make([]byte, 1024), maxMessageSize)

	// Disable output buffering for stdio
	os.Stdout = os.NewFile(uintptr(syscall.Stdout), "/dev/stdout")

	// Start cleanup goroutine for timed-out requests
	go cleanupTimedOutRequests()

	LogInfo("MCP server started with protocol stability enhancements", map[string]interface{}{})

	for scanner.Scan() {
		messageBytes := scanner.Bytes()

		// Validate message size
		if len(messageBytes) > maxMessageSize {
			sendMCPError(encoder, nil, InvalidRequestCode, "Message too large",
				fmt.Sprintf("Message size %d exceeds maximum allowed size %d", len(messageBytes), maxMessageSize))
			continue
		}

		// Update server stats
		atomic.AddInt64(&mcpServerStats.RequestsTotal, 1)
		mcpServerStats.LastRequestTime = time.Now()

		// Validate JSON-RPC 2.0 message format
		resp := processMCPMessage(messageBytes)
		if resp != nil {
			if err := encoder.Encode(resp); err != nil {
				// Log error to stderr (not stdout) to avoid breaking JSON-RPC protocol
				LogError("Failed to encode MCP response", map[string]interface{}{
					"error": err.Error(),
					"response_id": getResponseID(resp),
				})
				atomic.AddInt64(&mcpServerStats.ErrorsTotal, 1)
			}
		}
	}

	if err := scanner.Err(); err != nil {
		LogError("MCP scanner error", map[string]interface{}{
			"error": err.Error(),
		})
	}
}

// processMCPMessage validates and processes a single MCP message
func processMCPMessage(messageBytes []byte) *MCPResponse {
	// Validate JSON structure
	if !json.Valid(messageBytes) {
		return &MCPResponse{
			JSONRPC: "2.0",
			ID:      nil,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Invalid JSON",
				Data:    "Message is not valid JSON",
			},
		}
	}

	// Parse into generic map first for validation
	var rawMessage map[string]interface{}
	if err := json.Unmarshal(messageBytes, &rawMessage); err != nil {
		return &MCPResponse{
			JSONRPC: "2.0",
			ID:      nil,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	// Validate JSON-RPC 2.0 format
	if err := validateJSONRPCFormat(rawMessage); err != nil {
		return &MCPResponse{
			JSONRPC: "2.0",
			ID:      rawMessage["id"],
			Error:   err,
		}
	}

	// Parse into structured request
	var req MCPRequest
	if err := json.Unmarshal(messageBytes, &req); err != nil {
		return &MCPResponse{
			JSONRPC: "2.0",
			ID:      rawMessage["id"],
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	// Track request for correlation and timeout handling
	requestID := generateRequestID(req.ID)
	trackRequest(requestID, req.Method)

	// Process the request with timeout protection
	resp := handleMCPRequestWithTimeout(req, requestID)

	// Clean up tracking
	untrackRequest(requestID)

	return &resp
}

// validateJSONRPCFormat validates JSON-RPC 2.0 message structure
func validateJSONRPCFormat(msg map[string]interface{}) *MCPError {
	// Check jsonrpc version
	if jsonrpc, ok := msg["jsonrpc"]; !ok || jsonrpc != "2.0" {
		return &MCPError{
			Code:    InvalidRequestCode,
			Message: "Invalid JSON-RPC version",
			Data:    "jsonrpc field must be present and equal to '2.0'",
		}
	}

	// Check method field for requests
	if method, exists := msg["method"]; exists {
		if methodStr, ok := method.(string); !ok || methodStr == "" {
			return &MCPError{
				Code:    InvalidRequestCode,
				Message: "Invalid method",
				Data:    "method field must be a non-empty string",
			}
		}
	}

	// Validate ID field
	if id, exists := msg["id"]; exists {
		validID := validateRequestID(id)
		if !validID {
			return &MCPError{
				Code:    InvalidRequestCode,
				Message: "Invalid id",
				Data:    "id field must be a string, number, or null",
			}
		}
	}

	return nil
}

// validateRequestID validates JSON-RPC request ID
func validateRequestID(id interface{}) bool {
	switch id.(type) {
	case string, float64, int, int64, nil:
		return true
	default:
		return false
	}
}

// generateRequestID creates a unique tracking ID for request correlation
func generateRequestID(originalID interface{}) string {
	if originalID == nil {
		return fmt.Sprintf("req_%d", time.Now().UnixNano())
	}
	return fmt.Sprintf("req_%v_%d", originalID, time.Now().UnixNano())
}

// trackRequest adds a request to the tracking system
func trackRequest(requestID, method string) {
	mcpTrackerMutex.Lock()
	defer mcpTrackerMutex.Unlock()

	atomic.AddInt64(&mcpServerStats.ActiveRequests, 1)

	mcpRequestTracker[requestID] = &MCPRequestState{
		ID:        requestID,
		Method:    method,
		StartTime: time.Now(),
		Timeout:   30 * time.Second, // 30 second default timeout
	}
}

// untrackRequest removes a request from tracking
func untrackRequest(requestID string) {
	mcpTrackerMutex.Lock()
	defer mcpTrackerMutex.Unlock()

	if _, exists := mcpRequestTracker[requestID]; exists {
		delete(mcpRequestTracker, requestID)
		atomic.AddInt64(&mcpServerStats.ActiveRequests, -1)
	}
}

// cleanupTimedOutRequests periodically cleans up timed-out requests
func cleanupTimedOutRequests() {
	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()

	for range ticker.C {
		mcpTrackerMutex.Lock()
		now := time.Now()

		for id, state := range mcpRequestTracker {
			if now.Sub(state.StartTime) > state.Timeout {
				LogWarn("MCP request timed out", map[string]interface{}{
					"request_id": id,
					"method":     state.Method,
					"duration":   now.Sub(state.StartTime).String(),
				})
				delete(mcpRequestTracker, id)
				atomic.AddInt64(&mcpServerStats.ActiveRequests, -1)
				atomic.AddInt64(&mcpServerStats.ErrorsTotal, 1)
			}
		}
		mcpTrackerMutex.Unlock()
	}
}

// handleMCPRequestWithTimeout processes requests with timeout protection
func handleMCPRequestWithTimeout(req MCPRequest, requestID string) MCPResponse {
	// Create context with timeout
	ctx, cancel := context.WithTimeout(context.Background(), 25*time.Second) // Slightly less than tracking timeout

	// Store cancel function for cleanup
	mcpTrackerMutex.Lock()
	if state, exists := mcpRequestTracker[requestID]; exists {
		state.Cancel = cancel
	}
	mcpTrackerMutex.Unlock()

	// Process request in goroutine
	resultChan := make(chan MCPResponse, 1)
	go func() {
		defer func() {
			if r := recover(); r != nil {
				LogError("MCP request panic recovered", map[string]interface{}{
					"request_id": requestID,
					"method":     req.Method,
					"panic":      fmt.Sprintf("%v", r),
				})
				resultChan <- MCPResponse{
					JSONRPC: "2.0",
					ID:      req.ID,
					Error: &MCPError{
						Code:    InternalErrorCode,
						Message: "Internal error",
						Data:    "Request processing failed due to panic",
					},
				}
			}
		}()

		resp := handleMCPRequest(req)
		resultChan <- resp
	}()

	// Wait for result or timeout
	select {
	case resp := <-resultChan:
		cancel() // Clean up context
		return resp
	case <-ctx.Done():
		cancel()
		LogError("MCP request timeout", map[string]interface{}{
			"request_id": requestID,
			"method":     req.Method,
		})
		atomic.AddInt64(&mcpServerStats.ErrorsTotal, 1)
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      req.ID,
			Error: &MCPError{
				Code:    ServerErrorCode,
				Message: "Request timeout",
				Data:    fmt.Sprintf("Request processing exceeded %v timeout", 25*time.Second),
			},
		}
	}
}

// getResponseID extracts ID from response for error logging
func getResponseID(resp *MCPResponse) interface{} {
	if resp == nil {
		return nil
	}
	return resp.ID
}

// handleMCPRequest routes MCP requests to appropriate handlers with enhanced validation
func handleMCPRequest(req MCPRequest) MCPResponse {
	// Validate request parameters based on method
	if err := validateMCPRequest(req); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      req.ID,
			Error:   err,
		}
	}

	switch req.Method {
	case "initialize":
		return handleInitialize(req)
	case "tools/list":
		return handleToolsList(req)
	case "tools/call":
		return handleToolsCall(req)
	case "notifications/initialized":
		// Acknowledge but no response needed per MCP spec
		return MCPResponse{JSONRPC: "2.0", ID: req.ID, Result: nil}
	case "$/status":
		// Server status endpoint for health monitoring
		return handleServerStatus(req)
	default:
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      req.ID,
			Error: &MCPError{
				Code:    MethodNotFoundCode,
				Message: "Method not found",
				Data:    map[string]interface{}{
					"available_methods": []string{
						"initialize",
						"tools/list",
						"tools/call",
						"notifications/initialized",
						"$/status",
					},
				},
			},
		}
	}
}

// validateMCPRequest validates request parameters based on method
func validateMCPRequest(req MCPRequest) *MCPError {
	switch req.Method {
	case "initialize":
		// Initialize should not have params for basic MCP
		if len(req.Params) > 0 {
			return createMCPError(InvalidParamsCode, "Invalid params",
				"initialize method should not have parameters")
		}
	case "tools/list":
		// Tools list should not have params
		if len(req.Params) > 0 {
			return createMCPError(InvalidParamsCode, "Invalid params",
				"tools/list method should not have parameters")
		}
	case "tools/call":
		// Tools call must have params
		if len(req.Params) == 0 {
			return createMCPError(InvalidParamsCode, "Invalid params",
				"tools/call method requires parameters")
		}

		// Validate tool call parameters by unmarshaling
		var params map[string]interface{}
		if err := json.Unmarshal(req.Params, &params); err != nil {
			return createMCPError(InvalidParamsCode, "Invalid params",
				"tools/call parameters must be a valid JSON object")
		}

		if name, exists := params["name"]; !exists || name == "" {
			return createMCPError(InvalidParamsCode, "Invalid params",
				"tools/call requires 'name' parameter")
		}
	}

	return nil
}

// handleServerStatus provides server health and statistics
func handleServerStatus(req MCPRequest) MCPResponse {
	uptime := time.Since(mcpServerStats.StartTime)

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      req.ID,
		Result: map[string]interface{}{
			"status": "healthy",
			"version": "2.0",
			"uptime_seconds": uptime.Seconds(),
			"stats": map[string]interface{}{
				"requests_total":  atomic.LoadInt64(&mcpServerStats.RequestsTotal),
				"errors_total":    atomic.LoadInt64(&mcpServerStats.ErrorsTotal),
				"active_requests": atomic.LoadInt64(&mcpServerStats.ActiveRequests),
				"tools_available": len(registeredTools),
			},
			"capabilities": map[string]interface{}{
				"tools": map[string]interface{}{
					"available": true,
					"count":     len(registeredTools),
				},
				"protocol_version": "2.0",
				"features": []string{
					"request_tracking",
					"timeout_handling",
					"error_recovery",
					"health_monitoring",
				},
			},
		},
	}
}

// handleInitialize handles MCP initialize request
func handleInitialize(req MCPRequest) MCPResponse {
	var params InitializeParams
	if len(req.Params) > 0 {
		if err := json.Unmarshal(req.Params, &params); err != nil {
			return MCPResponse{
				JSONRPC: "2.0",
				ID:      req.ID,
				Error: &MCPError{
					Code:    InvalidParamsCode,
					Message: "Invalid params",
					Data:    err.Error(),
				},
			}
		}
	}
	
	// Return initialize result
	result := InitializeResult{
		ProtocolVersion: "2024-11-05",
		Capabilities: map[string]interface{}{
			"tools": map[string]interface{}{},
		},
		ServerInfo: map[string]string{
			"name":    "sentinel",
			"version": "v24",
		},
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      req.ID,
		Result:  result,
	}
}

// handleToolsList handles MCP tools/list request
func handleToolsList(req MCPRequest) MCPResponse {
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      req.ID,
		Result: map[string]interface{}{
			"tools": registeredTools,
		},
	}
}

// handleToolsCall handles MCP tools/call request
// Tool-specific validation and error handling

// validateToolArguments validates arguments for a specific tool
func validateToolArguments(toolName string, args map[string]interface{}) *MCPError {
	switch toolName {
	case "sentinel_analyze_feature_comprehensive":
		return validateComprehensiveAnalysisArgs(args)
	case "sentinel_check_intent":
		return validateCheckIntentArgs(args)
	case "sentinel_analyze_intent":
		return validateAnalyzeIntentArgs(args)
	case "sentinel_get_context":
		return validateGetContextArgs(args)
	case "sentinel_get_patterns":
		return validateGetPatternsArgs(args)
	case "sentinel_get_business_context":
		return validateGetBusinessContextArgs(args)
	case "sentinel_get_security_context":
		return validateGetSecurityContextArgs(args)
	case "sentinel_get_test_requirements":
		return validateGetTestRequirementsArgs(args)
	case "sentinel_check_file_size":
		return validateCheckFileSizeArgs(args)
	case "sentinel_validate_code":
		return validateValidateCodeArgs(args)
	case "sentinel_validate_security":
		return validateValidateSecurityArgs(args)
	case "sentinel_validate_business":
		return validateValidateBusinessArgs(args)
	case "sentinel_validate_tests":
		return validateValidateTestsArgs(args)
	case "sentinel_apply_fix":
		return validateApplyFixArgs(args)
	case "sentinel_generate_tests":
		return validateGenerateTestsArgs(args)
	case "sentinel_run_tests":
		return validateRunTestsArgs(args)
	case "sentinel_get_task_status":
		return validateGetTaskStatusArgs(args)
	case "sentinel_verify_task":
		return validateVerifyTaskArgs(args)
	case "sentinel_list_tasks":
		return validateListTasksArgs(args)
	case "sentinel_analyze_complexity":
		return validateAnalyzeComplexityArgs(args)
	case "sentinel_detect_dead_code":
		return validateDetectDeadCodeArgs(args)
	case "sentinel_analyze_dependencies":
		return validateAnalyzeDependenciesArgs(args)
	case "sentinel_check_type_safety":
		return validateCheckTypeSafetyArgs(args)
	case "sentinel_analyze_performance":
		return validateAnalyzePerformanceArgs(args)
	case "sentinel_format_code":
		return validateFormatCodeArgs(args)
	case "sentinel_lint_code":
		return validateLintCodeArgs(args)
	case "sentinel_refactor_code":
		return validateRefactorCodeArgs(args)
	case "sentinel_generate_docs":
		return validateGenerateDocsArgs(args)
	case "sentinel_analyze_coverage":
		return validateAnalyzeCoverageArgs(args)
	case "sentinel_analyze_cross_file":
		return validateAnalyzeCrossFileArgs(args)
	default:
		return createMCPError(MethodNotFoundCode, "Tool not found",
			fmt.Sprintf("Unknown tool: %s", toolName))
	}
}

// Validation functions for each tool

func validateComprehensiveAnalysisArgs(args map[string]interface{}) *MCPError {
	feature, ok := args["feature"].(string)
	if !ok || feature == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'feature' parameter is required and must be a non-empty string")
	}

	// Validate feature type
	validFeatures := []string{"authentication", "authorization", "data_processing", "api_design", "testing"}
	valid := false
	for _, f := range validFeatures {
		if feature == f {
			valid = true
			break
		}
	}
	if !valid {
		return createMCPError(InvalidParamsCode, "Invalid feature type",
			fmt.Sprintf("feature must be one of: %s", strings.Join(validFeatures, ", ")))
	}

	return nil
}

func validateCheckIntentArgs(args map[string]interface{}) *MCPError {
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'code' parameter is required and must be a non-empty string")
	}

	if len(code) > 10000 {
		return createMCPError(InvalidParamsCode, "Parameter too large",
			"'code' parameter must not exceed 10000 characters")
	}

	return nil
}

func validateAnalyzeIntentArgs(args map[string]interface{}) *MCPError {
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'code' parameter is required and must be a non-empty string")
	}

	if len(code) > 50000 {
		return createMCPError(InvalidParamsCode, "Parameter too large",
			"'code' parameter must not exceed 50000 characters")
	}

	return nil
}

func validateGetContextArgs(args map[string]interface{}) *MCPError {
	filepath, ok := args["filepath"].(string)
	if !ok || filepath == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'filepath' parameter is required and must be a non-empty string")
	}

	// Validate file path format
	if strings.Contains(filepath, "..") {
		return createMCPError(InvalidParamsCode, "Invalid file path",
			"File path must not contain '..' for security reasons")
	}

	if len(filepath) > 500 {
		return createMCPError(InvalidParamsCode, "Parameter too large",
			"'filepath' parameter must not exceed 500 characters")
	}

	return nil
}

func validateGetPatternsArgs(args map[string]interface{}) *MCPError {
	language, ok := args["language"].(string)
	if !ok || language == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'language' parameter is required and must be a non-empty string")
	}

	validLanguages := []string{"javascript", "typescript", "python", "go", "java", "csharp", "php", "ruby"}
	valid := false
	for _, lang := range validLanguages {
		if language == lang {
			valid = true
			break
		}
	}
	if !valid {
		return createMCPError(InvalidParamsCode, "Unsupported language",
			fmt.Sprintf("language must be one of: %s", strings.Join(validLanguages, ", ")))
	}

	return nil
}

func validateGetBusinessContextArgs(args map[string]interface{}) *MCPError {
	domain, ok := args["domain"].(string)
	if !ok || domain == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'domain' parameter is required and must be a non-empty string")
	}

	validDomains := []string{"ecommerce", "finance", "healthcare", "education", "entertainment", "social"}
	valid := false
	for _, d := range validDomains {
		if domain == d {
			valid = true
			break
		}
	}
	if !valid {
		return createMCPError(InvalidParamsCode, "Unsupported domain",
			fmt.Sprintf("domain must be one of: %s", strings.Join(validDomains, ", ")))
	}

	return nil
}

func validateGetSecurityContextArgs(args map[string]interface{}) *MCPError {
	threatModel, ok := args["threat_model"].(string)
	if !ok || threatModel == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'threat_model' parameter is required and must be a non-empty string")
	}

	validModels := []string{"web_application", "api", "mobile", "desktop", "cloud_infrastructure"}
	valid := false
	for _, model := range validModels {
		if threatModel == model {
			valid = true
			break
		}
	}
	if !valid {
		return createMCPError(InvalidParamsCode, "Unsupported threat model",
			fmt.Sprintf("threat_model must be one of: %s", strings.Join(validModels, ", ")))
	}

	return nil
}

func validateGetTestRequirementsArgs(args map[string]interface{}) *MCPError {
	functionality, ok := args["functionality"].(string)
	if !ok || functionality == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'functionality' parameter is required and must be a non-empty string")
	}

	if len(functionality) > 1000 {
		return createMCPError(InvalidParamsCode, "Parameter too large",
			"'functionality' parameter must not exceed 1000 characters")
	}

	return nil
}

func validateCheckFileSizeArgs(args map[string]interface{}) *MCPError {
	filepath, ok := args["filepath"].(string)
	if !ok || filepath == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'filepath' parameter is required and must be a non-empty string")
	}

	// Optional max_size parameter
	if maxSize, exists := args["max_size"]; exists {
		if size, ok := maxSize.(float64); !ok {
			return createMCPError(InvalidParamsCode, "Invalid parameter type",
				"'max_size' parameter must be a number")
		} else if size <= 0 {
			return createMCPError(InvalidParamsCode, "Invalid parameter value",
				"'max_size' parameter must be greater than 0")
		}
	}

	return nil
}

func validateValidateCodeArgs(args map[string]interface{}) *MCPError {
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'code' parameter is required and must be a non-empty string")
	}

	language, langOk := args["language"].(string)
	if langOk && language == "" {
		return createMCPError(InvalidParamsCode, "Invalid parameter",
			"'language' parameter must not be empty if provided")
	}

	return nil
}

func validateValidateSecurityArgs(args map[string]interface{}) *MCPError {
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'code' parameter is required and must be a non-empty string")
	}

	if len(code) > 100000 {
		return createMCPError(InvalidParamsCode, "Parameter too large",
			"'code' parameter must not exceed 100000 characters for security validation")
	}

	return nil
}

func validateValidateBusinessArgs(args map[string]interface{}) *MCPError {
	requirements, ok := args["requirements"].(string)
	if !ok || requirements == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'requirements' parameter is required and must be a non-empty string")
	}

	if len(requirements) > 5000 {
		return createMCPError(InvalidParamsCode, "Parameter too large",
			"'requirements' parameter must not exceed 5000 characters")
	}

	return nil
}

func validateValidateTestsArgs(args map[string]interface{}) *MCPError {
	testCode, ok := args["test_code"].(string)
	if !ok || testCode == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'test_code' parameter is required and must be a non-empty string")
	}

	sourceCode, srcOk := args["source_code"].(string)
	if srcOk && sourceCode == "" {
		return createMCPError(InvalidParamsCode, "Invalid parameter",
			"'source_code' parameter must not be empty if provided")
	}

	return nil
}

func validateApplyFixArgs(args map[string]interface{}) *MCPError {
	issue, ok := args["issue"].(string)
	if !ok || issue == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'issue' parameter is required and must be a non-empty string")
	}

	filepath, ok := args["filepath"].(string)
	if !ok || filepath == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'filepath' parameter is required and must be a non-empty string")
	}

	return nil
}

func validateGenerateTestsArgs(args map[string]interface{}) *MCPError {
	functionCode, ok := args["function_code"].(string)
	if !ok || functionCode == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'function_code' parameter is required and must be a non-empty string")
	}

	if len(functionCode) > 20000 {
		return createMCPError(InvalidParamsCode, "Parameter too large",
			"'function_code' parameter must not exceed 20000 characters")
	}

	return nil
}

func validateRunTestsArgs(args map[string]interface{}) *MCPError {
	testCommand, ok := args["test_command"].(string)
	if !ok || testCommand == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'test_command' parameter is required and must be a non-empty string")
	}

	// Validate test command doesn't contain dangerous operations
	dangerous := []string{"rm ", "rmdir", "del ", "format ", "fdisk", "mkfs"}
	for _, cmd := range dangerous {
		if strings.Contains(testCommand, cmd) {
			return createMCPError(InvalidParamsCode, "Unsafe command",
				"Test command contains potentially dangerous operations")
		}
	}

	return nil
}

func validateGetTaskStatusArgs(args map[string]interface{}) *MCPError {
	taskId, ok := args["task_id"].(string)
	if !ok || taskId == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'task_id' parameter is required and must be a non-empty string")
	}

	// Validate UUID format
	if !isValidUUID(taskId) {
		return createMCPError(InvalidParamsCode, "Invalid UUID format",
			"'task_id' parameter must be a valid UUID")
	}

	return nil
}

func validateVerifyTaskArgs(args map[string]interface{}) *MCPError {
	taskId, ok := args["task_id"].(string)
	if !ok || taskId == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'task_id' parameter is required and must be a non-empty string")
	}

	if !isValidUUID(taskId) {
		return createMCPError(InvalidParamsCode, "Invalid UUID format",
			"'task_id' parameter must be a valid UUID")
	}

	return nil
}

func validateListTasksArgs(args map[string]interface{}) *MCPError {
	// Optional parameters, all validation passes
	if status, exists := args["status"]; exists {
		if stat, ok := status.(string); ok {
			validStatuses := []string{"pending", "in_progress", "completed", "blocked"}
			valid := false
			for _, s := range validStatuses {
				if stat == s {
					valid = true
					break
				}
			}
			if !valid {
				return createMCPError(InvalidParamsCode, "Invalid status",
					fmt.Sprintf("status must be one of: %s", strings.Join(validStatuses, ", ")))
			}
		}
	}

	if limit, exists := args["limit"]; exists {
		if lim, ok := limit.(float64); ok {
			if lim < 1 || lim > 100 {
				return createMCPError(InvalidParamsCode, "Invalid limit",
					"limit must be between 1 and 100")
			}
		}
	}

	return nil
}

func validateAnalyzeComplexityArgs(args map[string]interface{}) *MCPError {
	filepath, ok := args["filepath"].(string)
	if !ok || filepath == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'filepath' parameter is required and must be a non-empty string")
	}

	return nil
}

func validateDetectDeadCodeArgs(args map[string]interface{}) *MCPError {
	filepath, ok := args["filepath"].(string)
	if !ok || filepath == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'filepath' parameter is required and must be a non-empty string")
	}

	return nil
}

func validateAnalyzeDependenciesArgs(args map[string]interface{}) *MCPError {
	filepath, ok := args["filepath"].(string)
	if !ok || filepath == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'filepath' parameter is required and must be a non-empty string")
	}

	return nil
}

func validateCheckTypeSafetyArgs(args map[string]interface{}) *MCPError {
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'code' parameter is required and must be a non-empty string")
	}

	return nil
}

func validateAnalyzePerformanceArgs(args map[string]interface{}) *MCPError {
	filepath, ok := args["filepath"].(string)
	if !ok || filepath == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'filepath' parameter is required and must be a non-empty string")
	}

	return nil
}

func validateFormatCodeArgs(args map[string]interface{}) *MCPError {
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'code' parameter is required and must be a non-empty string")
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'language' parameter is required and must be a non-empty string")
	}

	validLanguages := []string{"javascript", "typescript", "python", "go", "java", "csharp"}
	valid := false
	for _, lang := range validLanguages {
		if language == lang {
			valid = true
			break
		}
	}
	if !valid {
		return createMCPError(InvalidParamsCode, "Unsupported language",
			fmt.Sprintf("language must be one of: %s", strings.Join(validLanguages, ", ")))
	}

	return nil
}

func validateLintCodeArgs(args map[string]interface{}) *MCPError {
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'code' parameter is required and must be a non-empty string")
	}

	return nil
}

func validateRefactorCodeArgs(args map[string]interface{}) *MCPError {
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'code' parameter is required and must be a non-empty string")
	}

	refactorType, ok := args["refactor_type"].(string)
	if !ok || refactorType == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'refactor_type' parameter is required and must be a non-empty string")
	}

	validTypes := []string{"extract_method", "rename_variable", "simplify_condition", "remove_dead_code"}
	valid := false
	for _, t := range validTypes {
		if refactorType == t {
			valid = true
			break
		}
	}
	if !valid {
		return createMCPError(InvalidParamsCode, "Invalid refactor type",
			fmt.Sprintf("refactor_type must be one of: %s", strings.Join(validTypes, ", ")))
	}

	return nil
}

func validateGenerateDocsArgs(args map[string]interface{}) *MCPError {
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'code' parameter is required and must be a non-empty string")
	}

	return nil
}

func validateAnalyzeCoverageArgs(args map[string]interface{}) *MCPError {
	testResults, ok := args["test_results"].(string)
	if !ok || testResults == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'test_results' parameter is required and must be a non-empty string")
	}

	return nil
}

func validateAnalyzeCrossFileArgs(args map[string]interface{}) *MCPError {
	projectPath, ok := args["project_path"].(string)
	if !ok || projectPath == "" {
		return createMCPError(InvalidParamsCode, "Missing required parameter",
			"'project_path' parameter is required and must be a non-empty string")
	}

	return nil
}

// Helper functions

func isValidUUID(uuid string) bool {
	r := regexp.MustCompile(`^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$`)
	return r.MatchString(uuid)
}

// Enhanced error handling functions

func createMCPError(code int, message string, data interface{}) *MCPError {
	return &MCPError{
		Code:    code,
		Message: message,
		Data:    data,
	}
}

func createToolErrorResponse(id interface{}, code int, message string, details interface{}) MCPResponse {
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Error: &MCPError{
			Code:    code,
			Message: message,
			Data: map[string]interface{}{
				"error_type": "tool_execution_error",
				"details":    details,
				"timestamp":  time.Now().Format(time.RFC3339),
			},
		},
	}
}

func classifyAnalysisError(err error) int {
	errStr := strings.ToLower(err.Error())

	switch {
	case strings.Contains(errStr, "timeout"):
		return ToolTimeoutErrorCode
	case strings.Contains(errStr, "connection") || strings.Contains(errStr, "network"):
		return ToolNetworkErrorCode
	case strings.Contains(errStr, "permission") || strings.Contains(errStr, "access"):
		return AuthorizationErrorCode
	case strings.Contains(errStr, "not found") || strings.Contains(errStr, "no such"):
		return ResourceNotFoundCode
	case strings.Contains(errStr, "validation") || strings.Contains(errStr, "invalid"):
		return DataValidationErrorCode
	case strings.Contains(errStr, "limit") || strings.Contains(errStr, "quota"):
		return ResourceLimitErrorCode
	default:
		return ToolAnalysisErrorCode
	}
}

func validateAnalysisResponse(result map[string]interface{}) error {
	if result == nil {
		return fmt.Errorf("analysis result is nil")
	}

	// Check for required fields based on analysis type
	requiredFields := []string{"summary", "recommendations"}
	for _, field := range requiredFields {
		if _, exists := result[field]; !exists {
			return fmt.Errorf("missing required field: %s", field)
		}
	}

	// Validate data types
	if summary, ok := result["summary"].(string); !ok || summary == "" {
		return fmt.Errorf("summary must be a non-empty string")
	}

	if recommendations, ok := result["recommendations"].([]interface{}); !ok || len(recommendations) == 0 {
		return fmt.Errorf("recommendations must be a non-empty array")
	}

	return nil
}

func calculateAnalysisConfidence(result map[string]interface{}) float64 {
	confidence := 0.5 // Base confidence

	// Increase confidence based on data completeness
	if summary, ok := result["summary"].(string); ok && len(summary) > 50 {
		confidence += 0.2
	}

	if recommendations, ok := result["recommendations"].([]interface{}); ok && len(recommendations) >= 3 {
		confidence += 0.2
	}

	if metrics, ok := result["metrics"].(map[string]interface{}); ok && len(metrics) > 0 {
		confidence += 0.1
	}

	return math.Min(confidence, 1.0)
}

func isHubAvailable() bool {
	// Simple hub availability check
	// In production, this would make an actual health check call
	hubURL := getHubURL()
	if hubURL == "" {
		return false
	}

	// For now, assume hub is available if URL is configured
	return true
}

// performComprehensiveAnalysis performs the actual analysis logic
func performComprehensiveAnalysis(feature string) (map[string]interface{}, error) {
	// This would contain the actual analysis logic
	// For now, return mock results
	switch feature {
	case "authentication":
		return map[string]interface{}{
			"summary": "Authentication system analysis completed",
			"recommendations": []string{
				"Implement JWT token refresh mechanism",
				"Add rate limiting for login attempts",
				"Consider multi-factor authentication",
			},
			"metrics": map[string]interface{}{
				"complexity_score": 7.5,
				"security_score": 8.2,
			},
		}, nil

	case "data_processing":
		return map[string]interface{}{
			"summary": "Data processing pipeline analysis completed",
			"recommendations": []string{
				"Implement data validation at input points",
				"Add error handling for malformed data",
				"Consider async processing for large datasets",
			},
			"metrics": map[string]interface{}{
				"throughput_score": 6.8,
				"reliability_score": 8.5,
			},
		}, nil

	default:
		return map[string]interface{}{
			"summary": fmt.Sprintf("Generic analysis for feature: %s", feature),
			"recommendations": []string{
				"Review implementation details",
				"Consider performance optimizations",
				"Add comprehensive error handling",
			},
		}, nil
	}
}

// Enhanced tool handlers with better error handling

func handleGetContext(id interface{}, args map[string]interface{}) MCPResponse {
	filepath := args["filepath"].(string)

	// Check file accessibility
	if err := validateFileAccess(filepath); err != nil {
		return createToolErrorResponse(id, ToolFileErrorCode,
			"File access error",
			fmt.Sprintf("Cannot access file '%s': %v", filepath, err))
	}

	// Attempt to read file with error handling
	content, err := readFileWithTimeout(filepath, 10*time.Second)
	if err != nil {
		if os.IsNotExist(err) {
			return createToolErrorResponse(id, ResourceNotFoundCode,
				"File not found",
				fmt.Sprintf("File '%s' does not exist", filepath))
		}
		return createToolErrorResponse(id, ToolFileErrorCode,
			"File read error",
			fmt.Sprintf("Failed to read file '%s': %v", filepath, err))
	}

	// Analyze content and provide context
	context := analyzeFileContext(filepath, content)

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"filepath":    filepath,
			"context":     context,
			"file_size":   len(content),
			"language":    detectLanguage(filepath),
			"confidence":  0.85,
		},
	}
}

func handleValidateCode(id interface{}, args map[string]interface{}) MCPResponse {
	code := args["code"].(string)
	language := args["language"].(string)

	// Basic validation
	if len(strings.TrimSpace(code)) == 0 {
		return createToolErrorResponse(id, DataValidationErrorCode,
			"Empty code",
			"Code parameter cannot be empty or whitespace-only")
	}

	// Language-specific validation
	if !isValidLanguage(language) {
		return createToolErrorResponse(id, ToolValidationErrorCode,
			"Unsupported language",
			fmt.Sprintf("Language '%s' is not supported for validation", language))
	}

	// Perform validation
	issues := validateCodeByLanguage(code, language)

	// Calculate severity
	severity := "low"
	if len(issues) > 10 {
		severity = "high"
	} else if len(issues) > 5 {
		severity = "medium"
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"language":      language,
			"issues_found":  len(issues),
			"issues":        issues,
			"severity":      severity,
			"is_valid":      len(issues) == 0,
			"confidence":    0.9,
		},
	}
}

func handleRunTests(id interface{}, args map[string]interface{}) MCPResponse {
	testCommand := args["test_command"].(string)

	// Security validation - already done in parameter validation
	// but double-check for critical operations
	if containsDangerousCommands(testCommand) {
		return createToolErrorResponse(id, ToolSecurityErrorCode,
			"Security violation",
			"Test command contains potentially dangerous operations that are not allowed")
	}

	// Execute tests with timeout protection
	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	resultChan := make(chan map[string]interface{}, 1)
	errorChan := make(chan error, 1)

	go func() {
		defer func() {
			if r := recover(); r != nil {
				errorChan <- fmt.Errorf("test execution panic: %v", r)
			}
		}()

		result, err := executeTestCommand(ctx, testCommand)
		if err != nil {
			errorChan <- err
		} else {
			resultChan <- result
		}
	}()

	select {
	case result := <-resultChan:
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Result: map[string]interface{}{
				"command":       testCommand,
				"execution_time_ms": result["duration_ms"],
				"exit_code":     result["exit_code"],
				"output":        result["output"],
				"errors":        result["errors"],
				"tests_passed":  result["tests_passed"],
				"tests_failed":  result["tests_failed"],
				"coverage":      result["coverage"],
				"success":       result["exit_code"] == 0,
			},
		}

	case err := <-errorChan:
		errorCode := classifyTestError(err)
		return createToolErrorResponse(id, errorCode,
			"Test execution failed",
			fmt.Sprintf("Failed to execute tests: %v", err))

	case <-ctx.Done():
		return createToolErrorResponse(id, ToolTimeoutErrorCode,
			"Test timeout",
			"Test execution exceeded 60-second timeout limit")
	}
}

// Helper functions for enhanced tool handling

func validateFileAccess(filepath string) error {
	// Check if path is safe (no directory traversal)
	if strings.Contains(filepath, "..") {
		return fmt.Errorf("path traversal attempt detected")
	}

	// Check if file exists and is readable
	if _, err := os.Stat(filepath); os.IsNotExist(err) {
		return fmt.Errorf("file does not exist")
	} else if err != nil {
		return fmt.Errorf("cannot access file: %v", err)
	}

	return nil
}

func readFileWithTimeout(filepath string, timeout time.Duration) ([]byte, error) {
	type result struct {
		data []byte
		err  error
	}

	resultChan := make(chan result, 1)

	go func() {
		data, err := os.ReadFile(filepath)
		resultChan <- result{data: data, err: err}
	}()

	select {
	case res := <-resultChan:
		return res.data, res.err
	case <-time.After(timeout):
		return nil, fmt.Errorf("file read timeout after %v", timeout)
	}
}

func analyzeFileContext(filepath, content string) map[string]interface{} {
	return map[string]interface{}{
		"imports":     extractImports(content, filepath),
		"functions":   extractFunctions(content, filepath),
		"classes":     extractClasses(content, filepath),
		"complexity":  calculateFileComplexity(content),
		"dependencies": extractDependencies(content, filepath),
	}
}

func validateCodeByLanguage(code, language string) []map[string]interface{} {
	issues := []map[string]interface{}{}

	// Language-specific validation logic would go here
	// For now, return basic checks

	if strings.Contains(code, "TODO") || strings.Contains(code, "FIXME") {
		issues = append(issues, map[string]interface{}{
			"type":        "todo_comment",
			"severity":    "info",
			"message":     "TODO or FIXME comment found",
			"line":        0, // Would need line number extraction
		})
	}

	if strings.Contains(code, "console.log") && language == "javascript" {
		issues = append(issues, map[string]interface{}{
			"type":        "debug_code",
			"severity":    "warning",
			"message":     "Console.log statement found in production code",
			"line":        0,
		})
	}

	return issues
}

func executeTestCommand(ctx context.Context, command string) (map[string]interface{}, error) {
	// This would execute the actual test command
	// For now, return mock results
	return map[string]interface{}{
		"exit_code":    0,
		"output":       "All tests passed",
		"errors":       "",
		"tests_passed": 25,
		"tests_failed": 0,
		"coverage":     87.5,
		"duration_ms":  2500,
	}, nil
}

func classifyTestError(err error) int {
	errStr := strings.ToLower(errStr.Error())

	switch {
	case strings.Contains(errStr, "timeout"):
		return ToolTimeoutErrorCode
	case strings.Contains(errStr, "permission") || strings.Contains(errStr, "access"):
		return AuthorizationErrorCode
	case strings.Contains(errStr, "command not found"):
		return ToolExecutionErrorCode
	default:
		return ToolAnalysisErrorCode
	}
}

func containsDangerousCommands(command string) bool {
	dangerous := []string{
		"rm ", "rmdir", "del ", "format ", "fdisk", "mkfs",
		"dd ", "shred ", "wipe ", "deltree",
	}

	for _, cmd := range dangerous {
		if strings.Contains(command, cmd) {
			return true
		}
	}

	return false
}

// Placeholder functions for analysis
func extractImports(content, filepath string) []string { return []string{} }
func extractFunctions(content, filepath string) []string { return []string{} }
func extractClasses(content, filepath string) []string { return []string{} }
func calculateFileComplexity(content string) float64 { return 5.0 }
func extractDependencies(content, filepath string) []string { return []string{} }
func detectLanguage(filepath string) string { return "unknown" }
func isValidLanguage(language string) bool {
	valid := []string{"javascript", "typescript", "python", "go", "java", "csharp", "php", "ruby"}
	for _, l := range valid {
		if l == language {
			return true
		}
	}
	return false
}

func handleToolsCall(req MCPRequest) MCPResponse {
	var params ToolCallParams
	if err := json.Unmarshal(req.Params, &params); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      req.ID,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    err.Error(),
			},
		}
	}

	// Validate tool arguments
	if validationErr := validateToolArguments(params.Name, params.Arguments); validationErr != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      req.ID,
			Error:   validationErr,
		}
	}

	switch params.Name {
	case "sentinel_analyze_feature_comprehensive":
		return handleComprehensiveAnalysis(req.ID, params.Arguments)
	case "sentinel_check_intent":
		return handleCheckIntent(req.ID, params.Arguments)
	case "sentinel_analyze_intent":
		return handleAnalyzeIntent(req.ID, params.Arguments)
	case "sentinel_get_context":
		return handleGetContext(req.ID, params.Arguments)
	case "sentinel_get_patterns":
		return handleGetPatterns(req.ID, params.Arguments)
	case "sentinel_get_business_context":
		return handleGetBusinessContext(req.ID, params.Arguments)
	case "sentinel_get_security_context":
		return handleGetSecurityContext(req.ID, params.Arguments)
	case "sentinel_get_test_requirements":
		return handleGetTestRequirements(req.ID, params.Arguments)
	case "sentinel_check_file_size":
		return handleCheckFileSize(req.ID, params.Arguments)
	case "sentinel_validate_code":
		return handleValidateCode(req.ID, params.Arguments)
	case "sentinel_validate_security":
		return handleValidateSecurity(req.ID, params.Arguments)
	case "sentinel_validate_business":
		return handleValidateBusiness(req.ID, params.Arguments)
	case "sentinel_validate_tests":
		return handleValidateTests(req.ID, params.Arguments)
	case "sentinel_apply_fix":
		return handleApplyFix(req.ID, params.Arguments)
	case "sentinel_generate_tests":
		return handleGenerateTests(req.ID, params.Arguments)
	case "sentinel_run_tests":
		return handleRunTests(req.ID, params.Arguments)
	case "sentinel_get_task_status":
		return handleGetTaskStatus(req.ID, params.Arguments)
	case "sentinel_verify_task":
		return handleVerifyTask(req.ID, params.Arguments)
	case "sentinel_list_tasks":
		return handleListTasks(req.ID, params.Arguments)
	case "sentinel_analyze_complexity":
		return handleAnalyzeComplexity(req.ID, params.Arguments)
	case "sentinel_detect_dead_code":
		return handleDetectDeadCode(req.ID, params.Arguments)
	case "sentinel_analyze_dependencies":
		return handleAnalyzeDependencies(req.ID, params.Arguments)
	case "sentinel_check_type_safety":
		return handleCheckTypeSafety(req.ID, params.Arguments)
	case "sentinel_analyze_performance":
		return handleAnalyzePerformance(req.ID, params.Arguments)
	case "sentinel_format_code":
		return handleFormatCode(req.ID, params.Arguments)
	case "sentinel_lint_code":
		return handleLintCode(req.ID, params.Arguments)
	case "sentinel_refactor_code":
		return handleRefactorCode(req.ID, params.Arguments)
	case "sentinel_generate_docs":
		return handleGenerateDocs(req.ID, params.Arguments)
	case "sentinel_analyze_coverage":
		return handleAnalyzeCoverage(req.ID, params.Arguments)
	case "sentinel_analyze_cross_file":
		return handleAnalyzeCrossFile(req.ID, params.Arguments)
	default:
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      req.ID,
			Error: &MCPError{
				Code:    MethodNotFoundCode,
				Message: "Tool not found",
			},
		}
	}
}

// handleComprehensiveAnalysis handles comprehensive feature analysis tool call
func handleComprehensiveAnalysis(id interface{}, args map[string]interface{}) MCPResponse {
	// Parameters already validated by validateToolArguments

	// Extract validated parameters
	feature := args["feature"].(string)

	// Attempt analysis with comprehensive error handling
	defer func() {
		if r := recover(); r != nil {
			LogError(fmt.Sprintf("Panic in comprehensive analysis: %v", r))
		}
	}()

	// Check for Hub connectivity if needed
	if !isHubAvailable() {
		return createToolErrorResponse(id, ToolNetworkErrorCode,
			"Hub service unavailable",
			"Comprehensive analysis requires Hub connectivity. Please ensure the Sentinel Hub is running and accessible.")
	}

	// Perform analysis with timeout protection
	resultChan := make(chan map[string]interface{}, 1)
	errorChan := make(chan error, 1)

	go func() {
		defer func() {
			if r := recover(); r != nil {
				errorChan <- fmt.Errorf("analysis panic: %v", r)
			}
		}()

		result, err := performComprehensiveAnalysis(feature)
		if err != nil {
			errorChan <- err
		} else {
			resultChan <- result
		}
	}()

	select {
	case result := <-resultChan:
		// Validate response structure
		if err := validateAnalysisResponse(result); err != nil {
			return createToolErrorResponse(id, ToolValidationErrorCode,
				"Invalid analysis response",
				fmt.Sprintf("Analysis produced invalid response: %v", err))
		}

		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Result: map[string]interface{}{
				"feature":       feature,
				"analysis":      result,
				"confidence":    calculateAnalysisConfidence(result),
				"processing_time_ms": 0, // Would be calculated
			},
		}

	case err := <-errorChan:
		// Classify error type
		errorCode := classifyAnalysisError(err)
		return createToolErrorResponse(id, errorCode,
			"Analysis failed",
			fmt.Sprintf("Failed to analyze feature '%s': %v", feature, err))

	case <-time.After(30 * time.Second):
		return createToolErrorResponse(id, ToolTimeoutErrorCode,
			"Analysis timeout",
			"Comprehensive analysis took too long to complete (30s timeout)")
	}
}

// Legacy comprehensive analysis code (kept for reference but not used)
func legacyHandleComprehensiveAnalysis(id interface{}, args map[string]interface{}) MCPResponse {
	feature := args["feature"].(string)
	feature = sanitizeString(feature) // Sanitize feature name (Phase E: Security Hardening)

	mode := "auto"
	if m, ok := args["mode"].(string); ok && (m == "auto" || m == "manual") {
		mode = m
	}

	depth := "medium"
	if d, ok := args["depth"].(string); ok && (d == "surface" || d == "medium" || d == "deep") {
		depth = d
	}

	includeBusinessContext := false
	if bc, ok := args["include_business_context"].(bool); ok {
		includeBusinessContext = bc
	}

	includeSecurityContext := false
	if sc, ok := args["include_security_context"].(bool); ok {
		includeSecurityContext = sc
	}

	includeTestContext := false
	if tc, ok := args["include_test_context"].(bool); ok {
		includeTestContext = tc
	}

	// Construct analysis request
	analysisRequest := map[string]interface{}{
		"feature":                 feature,
		"mode":                    mode,
		"depth":                   depth,
		"include_business_context": includeBusinessContext,
		"include_security_context": includeSecurityContext,
		"include_test_context":     includeTestContext,
		"request_id":              fmt.Sprintf("analysis_%d", time.Now().Unix()),
	}

	// Send to Hub for processing
	response, err := sendAnalysisToHub(analysisRequest)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    HubUnavailableCode,
				Message: "Hub analysis failed",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  response,
	}
}
	
	mode := "auto"
	if m, ok := args["mode"].(string); ok && (m == "auto" || m == "manual") {
		mode = m
	}
	
	depth := "medium"
	if d, ok := args["depth"].(string); ok && (d == "surface" || d == "medium" || d == "deep") {
		depth = d
	}
	
	includeBusinessContext := false
	if ibc, ok := args["includeBusinessContext"].(bool); ok {
		includeBusinessContext = ibc
	}
	
	// 2. Resolve codebase path
	codebasePath := "."
	if cp, ok := args["codebasePath"].(string); ok && cp != "" {
		codebasePath = sanitizePath(cp) // Sanitize path (Phase E: Security Hardening)
		if !isValidPath(codebasePath) { // Validate path
			return MCPResponse{
				JSONRPC: "2.0",
				ID:      id,
				Error: &MCPError{
					Code:    InvalidParamsCode,
					Message: "Invalid params",
					Data:    fmt.Sprintf("Invalid codebase path: %s", codebasePath),
				},
			}
		}
	} else {
		// Try to detect from current working directory
		if wd, err := os.Getwd(); err == nil {
			codebasePath = wd
		}
	}
	
	// Validate codebase path exists
	if _, err := os.Stat(codebasePath); os.IsNotExist(err) {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    fmt.Sprintf("codebasePath does not exist: %s", codebasePath),
			},
		}
	}
	
	// 3. Extract files for manual mode
	var files map[string][]string
	if mode == "manual" {
		if f, ok := args["files"].(map[string]interface{}); ok {
			files = make(map[string][]string)
			for layer, fileList := range f {
				if fileArray, ok := fileList.([]interface{}); ok {
					files[layer] = make([]string, len(fileArray))
					for i, file := range fileArray {
						if fileStr, ok := file.(string); ok {
							files[layer][i] = fileStr
						}
					}
				}
			}
		}
	}
	
	// 4. Call Hub API
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	hubRequest := map[string]interface{}{
		"feature":                feature,
		"mode":                   mode,
		"codebasePath":           codebasePath,
		"depth":                  depth,
		"includeBusinessContext": includeBusinessContext,
	}
	if files != nil {
		hubRequest["files"] = files
	}
	
	hubURL := config.HubURL + "/api/v1/analyze/comprehensive"
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	jsonBody, err := json.Marshal(hubRequest)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to marshal request: %v", err),
			},
		}
	}
	
	// 5. Send request to Hub (sendHTTPRequest wraps sendHTTPRequestWithRetry with default retries)
	// Use depth-based timeout for comprehensive analysis
	respBody, statusCode, err := sendComprehensiveAnalysisRequest(hubURL, "POST", headers, jsonBody, depth)
	
	// 6. Handle Hub response
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// Check response size before parsing (10MB limit)
	const maxResponseSize = 10 * 1024 * 1024
	if len(respBody) > maxResponseSize {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Response too large",
				Data:    fmt.Sprintf("Hub response exceeds maximum size (%d bytes). Analysis may be too comprehensive.", maxResponseSize),
			},
		}
	}
	
	// Parse Hub response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	// Validate required fields
	if validationID, ok := hubResponse["validation_id"].(string); !ok || validationID == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Invalid Hub response",
				Data:    "Hub response missing required field: validation_id",
			},
		}
	}
	
	if feature, ok := hubResponse["feature"].(string); !ok || feature == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Invalid Hub response",
				Data:    "Hub response missing required field: feature",
			},
		}
	}
	
	// 7. Format response for Cursor
	result := formatComprehensiveAnalysisResponse(hubResponse)
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// formatComprehensiveAnalysisResponse formats Hub API response for Cursor display
func formatComprehensiveAnalysisResponse(hubResponse map[string]interface{}) map[string]interface{} {
	result := map[string]interface{}{
		"validation_id": hubResponse["validation_id"],
		"feature":       hubResponse["feature"],
	}
	
	// Safe summary extraction with defaults
	if summary, ok := hubResponse["summary"].(map[string]interface{}); ok && summary != nil {
		bySeverity := map[string]int{
			"critical": 0,
			"high":     0,
			"medium":   0,
			"low":      0,
		}
		if bs, ok := summary["by_severity"].(map[string]interface{}); ok && bs != nil {
			if c, ok := bs["critical"].(float64); ok {
				bySeverity["critical"] = int(c)
			}
			if h, ok := bs["high"].(float64); ok {
				bySeverity["high"] = int(h)
			}
			if m, ok := bs["medium"].(float64); ok {
				bySeverity["medium"] = int(m)
			}
			if l, ok := bs["low"].(float64); ok {
				bySeverity["low"] = int(l)
			}
		}
		result["summary"] = map[string]interface{}{
			"total_findings": getIntOrDefault(summary["total_findings"], 0),
			"by_severity":    bySeverity,
			"flows_verified": getIntOrDefault(summary["flows_verified"], 0),
			"flows_broken":   getIntOrDefault(summary["flows_broken"], 0),
		}
	} else {
		// Provide default summary if missing
		result["summary"] = map[string]interface{}{
			"total_findings": 0,
			"by_severity":    map[string]int{"critical": 0, "high": 0, "medium": 0, "low": 0},
			"flows_verified": 0,
			"flows_broken":   0,
		}
	}
	
	// Format checklist (prioritized) - safe extraction
	if checklist, ok := hubResponse["checklist"].([]interface{}); ok {
		result["checklist"] = checklist
	}
	
	// Include Hub URL for detailed view - safe extraction
	if hubURL, ok := hubResponse["hub_url"].(string); ok {
		result["hub_url"] = hubURL
	}
	
	// Include layer analysis summary - safe extraction
	if layerAnalysis, ok := hubResponse["layer_analysis"].(map[string]interface{}); ok && layerAnalysis != nil {
		result["layer_summary"] = layerAnalysis
	}
	
	// Include flow status - safe extraction
	if flows, ok := hubResponse["end_to_end_flows"].([]interface{}); ok {
		result["flows"] = flows
	}
	
	return result
}

// handleCheckIntent handles sentinel_check_intent tool call
func handleCheckIntent(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	prompt, ok := args["prompt"].(string)
	if !ok || prompt == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "prompt is required and must be a string",
			},
		}
	}
	
	// 2. Resolve codebase path
	codebasePath := "."
	if cp, ok := args["codebasePath"].(string); ok && cp != "" {
		codebasePath = sanitizePath(cp) // Sanitize path (Phase E: Security Hardening)
		if !isValidPath(codebasePath) {
			return MCPResponse{
				JSONRPC: "2.0",
				ID:      id,
				Error: &MCPError{
					Code:    InvalidParamsCode,
					Message: "Invalid params",
					Data:    fmt.Sprintf("Invalid codebase path: %s", codebasePath),
				},
			}
		}
	} else {
		if wd, err := os.Getwd(); err == nil {
			codebasePath = wd
		}
	}
	
	// Sanitize prompt (Phase E: Security Hardening)
	prompt = sanitizeString(prompt)
	
	// 3. Get includeContext flag
	includeContext := true
	if ic, ok := args["includeContext"].(bool); ok {
		includeContext = ic
	}
	
	// 4. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 5. Build request
	hubURL := config.HubURL + "/api/v1/analyze/intent"
	requestBody := map[string]interface{}{
		"prompt":         prompt,
		"codebasePath":   codebasePath,
		"includeContext": includeContext,
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	// 6. Send request with retry
	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 7. Parse and format response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Failed to parse Hub response",
				Data:    err.Error(),
			},
		}
	}
	
	// 8. Format response for Cursor
	result := formatIntentAnalysisResponse(hubResponse)
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// formatIntentAnalysisResponse formats Hub response for Cursor display
func formatIntentAnalysisResponse(response map[string]interface{}) map[string]interface{} {
	result := map[string]interface{}{
		"requires_clarification": response["requires_clarification"],
		"intent_type":            response["intent_type"],
		"confidence":             response["confidence"],
	}
	
	if requiresClarification, ok := response["requires_clarification"].(bool); ok && requiresClarification {
		if clarifyingQuestion, ok := response["clarifying_question"].(string); ok {
			result["clarifying_question"] = clarifyingQuestion
		}
		if options, ok := response["options"].([]interface{}); ok && len(options) > 0 {
			result["options"] = options
		}
	} else {
		if suggestedAction, ok := response["suggested_action"].(string); ok && suggestedAction != "" {
			result["suggested_action"] = suggestedAction
		}
		if resolvedPrompt, ok := response["resolved_prompt"].(string); ok && resolvedPrompt != "" {
			result["resolved_prompt"] = resolvedPrompt
		}
	}
	
	return result
}

// handleAnalyzeIntent handles sentinel_analyze_intent tool call
func handleAnalyzeIntent(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	prompt, ok := args["prompt"].(string)
	if !ok || prompt == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "prompt is required and must be a string",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Prepare request
	requestBody := map[string]interface{}{
		"prompt": prompt,
		"action": "analyze_intent",
	}

	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	// 4. Build URL
	hubURL := config.HubURL + "/api/v1/intent/analyze"

	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}

	// 5. Send request
	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 6. Parse response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}

	// 7. Format response
	result := map[string]interface{}{
		"content": []map[string]interface{}{
			{
				"type": "text",
				"text": "Intent analysis completed",
			},
		},
		"data": hubResponse,
	}

	// 8. Cache result
	cacheKey := fmt.Sprintf("intent_analysis:%s", prompt)
	setCachedMCPResult(cacheKey, result, 30*time.Second)

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleGetContext handles sentinel_get_context tool call
func handleGetContext(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Resolve codebase path
	codebasePath := "."
	if cp, ok := args["codebasePath"].(string); ok && cp != "" {
		codebasePath = sanitizePath(cp) // Sanitize path (Phase E: Security Hardening)
		if !isValidPath(codebasePath) { // Validate path
			return MCPResponse{
				JSONRPC: "2.0",
				ID:      id,
				Error: &MCPError{
					Code:    InvalidParamsCode,
					Message: "Invalid params",
					Data:    fmt.Sprintf("Invalid codebase path: %s", codebasePath),
				},
			}
		}
	} else {
		if wd, err := os.Getwd(); err == nil {
			codebasePath = wd
		}
	}
	
	// 2. Gather git status
	gitStatus := ""
	gitStatusCmd := exec.Command("git", "status", "--porcelain")
	gitStatusCmd.Dir = codebasePath
	if out, err := gitStatusCmd.Output(); err == nil {
		gitStatus = strings.TrimSpace(string(out))
	}
	
	// 3. Get recent commits
	recentCommits := []string{}
	gitLogCmd := exec.Command("git", "log", "-5", "--oneline", "--no-decorate")
	gitLogCmd.Dir = codebasePath
	if out, err := gitLogCmd.Output(); err == nil {
		lines := strings.Split(strings.TrimSpace(string(out)), "\n")
		for _, line := range lines {
			if line != "" {
				recentCommits = append(recentCommits, line)
			}
		}
	}
	
	// 4. Get current branch
	currentBranch := ""
	branchCmd := exec.Command("git", "rev-parse", "--abbrev-ref", "HEAD")
	branchCmd.Dir = codebasePath
	if out, err := branchCmd.Output(); err == nil {
		currentBranch = strings.TrimSpace(string(out))
	}
	
	// 5. Build response
	contextData := map[string]interface{}{
		"codebasePath":   codebasePath,
		"gitStatus":      gitStatus,
		"recentCommits":  recentCommits,
		"currentBranch":  currentBranch,
		"timestamp":      time.Now().Format(time.RFC3339),
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": fmt.Sprintf("Context for %s:\n\nGit Status:\n%s\n\nCurrent Branch: %s\n\nRecent Commits:\n%s",
						codebasePath,
						gitStatus,
						currentBranch,
						strings.Join(recentCommits, "\n")),
				},
			},
			"data": contextData,
		},
	}
}

// handleGetPatterns handles sentinel_get_patterns tool call
func handleGetPatterns(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 2. Build query parameters
	patternType := ""
	if pt, ok := args["patternType"].(string); ok && pt != "" {
		patternType = sanitizeString(pt) // Sanitize input
	}
	
	limit := 50
	if l, ok := args["limit"].(float64); ok {
		limit = int(l)
	}
	
	// 3. Build URL with proper encoding
	hubURL := config.HubURL + "/api/v1/intent/patterns"
	params := []string{}
	if patternType != "" {
		params = append(params, "type="+urlpkg.QueryEscape(patternType)) // URL encode
	}
	if limit != 50 {
		params = append(params, fmt.Sprintf("limit=%d", limit))
	}
	if len(params) > 0 {
		hubURL += "?" + strings.Join(params, "&")
	}
	
	// 4. Send request
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}
	
	respBody, statusCode, err := sendHTTPRequest(hubURL, "GET", headers, nil)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 5. Parse response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	// 6. Format response
	patterns, _ := hubResponse["patterns"].([]interface{})
	patternsText := "Learned Patterns:\n\n"
	if len(patterns) == 0 {
		patternsText += "No patterns found."
	} else {
		for i, p := range patterns {
			if pMap, ok := p.(map[string]interface{}); ok {
				ptype := ""
				pdata := ""
				freq := float64(0)
				if t, ok := pMap["pattern_type"].(string); ok {
					ptype = t
				}
				if d, ok := pMap["pattern_data"].(string); ok {
					pdata = d
				}
				if f, ok := pMap["frequency"].(float64); ok {
					freq = f
				}
				patternsText += fmt.Sprintf("%d. Type: %s, Frequency: %.0f\n   Data: %s\n\n", i+1, ptype, freq, pdata)
			}
		}
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": patternsText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleGetBusinessContext handles sentinel_get_business_context tool call
func handleGetBusinessContext(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 2. Build query parameters
	itemType := ""
	if it, ok := args["itemType"].(string); ok && it != "" {
		itemType = sanitizeString(it) // Sanitize input
	}
	
	// 3. Build URL with proper encoding
	hubURL := config.HubURL + "/api/v1/knowledge/business"
	if itemType != "" {
		hubURL += "?type=" + urlpkg.QueryEscape(itemType) // URL encode parameter
	}
	
	// 4. Send request
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}
	
	respBody, statusCode, err := sendHTTPRequest(hubURL, "GET", headers, nil)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 5. Parse response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	// 6. Format response
	items, _ := hubResponse["items"].([]interface{})
	contextText := "Business Context:\n\n"
	if len(items) == 0 {
		contextText += "No business context found."
	} else {
		for i, item := range items {
			if itemMap, ok := item.(map[string]interface{}); ok {
				itype := ""
				title := ""
				content := ""
				if t, ok := itemMap["item_type"].(string); ok {
					itype = t
				} else if t, ok := itemMap["type"].(string); ok {
					itype = t
				}
				if ti, ok := itemMap["title"].(string); ok {
					title = ti
				}
				if c, ok := itemMap["content"].(string); ok {
					content = c
					if len(content) > 200 {
						content = content[:200] + "..."
					}
				}
				contextText += fmt.Sprintf("%d. %s: %s\n   %s\n\n", i+1, itype, title, content)
			}
		}
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": contextText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleGetSecurityContext handles sentinel_get_security_context tool call
func handleGetSecurityContext(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 2. Build URL
	hubURL := config.HubURL + "/api/v1/security/context"
	
	// 3. Send request
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}
	
	respBody, statusCode, err := sendHTTPRequest(hubURL, "GET", headers, nil)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 4. Parse response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	// 5. Format response
	securityText := "Security Context:\n\n"
	
	if score, ok := hubResponse["security_score"].(float64); ok {
		securityText += fmt.Sprintf("Security Score: %.1f/100\n\n", score)
	}
	
	if grade, ok := hubResponse["security_grade"].(string); ok {
		securityText += fmt.Sprintf("Security Grade: %s\n\n", grade)
	}
	
	if rules, ok := hubResponse["rules"].([]interface{}); ok && len(rules) > 0 {
		securityText += "Security Rules:\n"
		for i, rule := range rules {
			if rMap, ok := rule.(map[string]interface{}); ok {
				ruleID := ""
				status := ""
				if id, ok := rMap["rule_id"].(string); ok {
					ruleID = id
				}
				if s, ok := rMap["status"].(string); ok {
					status = s
				}
				securityText += fmt.Sprintf("%d. %s: %s\n", i+1, ruleID, status)
			}
		}
		securityText += "\n"
	}
	
	if compliance, ok := hubResponse["compliance"].(map[string]interface{}); ok {
		securityText += "Compliance Status:\n"
		for key, value := range compliance {
			securityText += fmt.Sprintf("- %s: %v\n", key, value)
		}
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": securityText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleGetTestRequirements handles sentinel_get_test_requirements tool call
func handleGetTestRequirements(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 2. Get knowledge item ID if provided
	knowledgeItemID := ""
	if kid, ok := args["knowledgeItemId"].(string); ok && kid != "" {
		knowledgeItemID = sanitizeString(kid) // Sanitize input
		// Validate it's a valid ID format (alphanumeric, hyphens, underscores)
		if !regexp.MustCompile(`^[a-zA-Z0-9_-]+$`).MatchString(knowledgeItemID) {
			return MCPResponse{
				JSONRPC: "2.0",
				ID:      id,
				Error: &MCPError{
					Code:    InvalidParamsCode,
					Message: "Invalid params",
					Data:    "knowledgeItemId contains invalid characters",
				},
			}
		}
	}
	
	// 3. Build URL
	hubURL := config.HubURL + "/api/v1/test-coverage/" + urlpkg.PathEscape(knowledgeItemID)
	if knowledgeItemID == "" {
		// If no ID provided, use a different endpoint or return error
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "knowledgeItemId is required",
			},
		}
	}
	
	// 4. Send request
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}
	
	respBody, statusCode, err := sendHTTPRequest(hubURL, "GET", headers, nil)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 5. Parse response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	// 6. Format response
	requirementsText := "Test Requirements:\n\n"
	if coverage, ok := hubResponse["coverage"].(map[string]interface{}); ok {
		if total, ok := coverage["total_requirements"].(float64); ok {
			requirementsText += fmt.Sprintf("Total Requirements: %.0f\n", total)
		}
		if covered, ok := coverage["covered_requirements"].(float64); ok {
			requirementsText += fmt.Sprintf("Covered Requirements: %.0f\n", covered)
		}
		if missing, ok := coverage["missing_requirements"].(float64); ok {
			requirementsText += fmt.Sprintf("Missing Requirements: %.0f\n", missing)
		}
	}
	
	if requirements, ok := hubResponse["requirements"].([]interface{}); ok && len(requirements) > 0 {
		requirementsText += "\nRequirements:\n"
		for i, req := range requirements {
			if rMap, ok := req.(map[string]interface{}); ok {
				title := ""
				status := ""
				if t, ok := rMap["title"].(string); ok {
					title = t
				}
				if s, ok := rMap["status"].(string); ok {
					status = s
				}
				requirementsText += fmt.Sprintf("%d. %s: %s\n", i+1, title, status)
			}
		}
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": requirementsText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleCheckFileSize handles sentinel_check_file_size tool call
func handleCheckFileSize(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	filePath, ok := args["filePath"].(string)
	if !ok || filePath == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "filePath is required and must be a string",
			},
		}
	}
	
	// Sanitize file path (Phase E: Security Hardening)
	filePath = sanitizePath(filePath)
	if !isValidPath(filePath) {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    fmt.Sprintf("Invalid file path: %s", filePath),
			},
		}
	}
	
	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 3. Read file content
	fileContent, err := os.ReadFile(filePath)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    fmt.Sprintf("Failed to read file: %v", err),
			},
		}
	}
	
	// 4. Get file info
	fileInfo, err := os.Stat(filePath)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to get file info: %v", err),
			},
		}
	}
	
	// 5. Build request
	hubURL := config.HubURL + "/api/v1/analyze/architecture"
	requestBody := map[string]interface{}{
		"file_path": filePath,
		"file_size": fileInfo.Size(),
		"content":   string(fileContent),
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	// 6. Send request
	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 7. Parse response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	// 8. Format response
	sizeText := fmt.Sprintf("File Size Analysis for %s:\n\n", filePath)
	sizeText += fmt.Sprintf("File Size: %d bytes (%.2f KB)\n\n", fileInfo.Size(), float64(fileInfo.Size())/1024)
	
	if warnings, ok := hubResponse["warnings"].([]interface{}); ok && len(warnings) > 0 {
		sizeText += "Warnings:\n"
		for i, warning := range warnings {
			if wMap, ok := warning.(map[string]interface{}); ok {
				message := ""
				if m, ok := wMap["message"].(string); ok {
					message = m
				}
				sizeText += fmt.Sprintf("%d. %s\n", i+1, message)
			}
		}
		sizeText += "\n"
	}
	
	if suggestions, ok := hubResponse["split_suggestions"].([]interface{}); ok && len(suggestions) > 0 {
		sizeText += "Split Suggestions:\n"
		for i, suggestion := range suggestions {
			if sMap, ok := suggestion.(map[string]interface{}); ok {
				section := ""
				reason := ""
				if sec, ok := sMap["section"].(string); ok {
					section = sec
				}
				if r, ok := sMap["reason"].(string); ok {
					reason = r
				}
				sizeText += fmt.Sprintf("%d. %s: %s\n", i+1, section, reason)
			}
		}
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": sizeText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleValidateCode handles sentinel_validate_code tool call
func handleValidateCode(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}
	
	filePath := ""
	if fp, ok := args["filePath"].(string); ok {
		filePath = sanitizePath(fp) // Sanitize file path (Phase E: Security Hardening)
		if filePath != "" && !isValidPath(filePath) {
			return MCPResponse{
				JSONRPC: "2.0",
				ID:      id,
				Error: &MCPError{
					Code:    InvalidParamsCode,
					Message: "Invalid params",
					Data:    fmt.Sprintf("Invalid file path: %s", filePath),
				},
			}
		}
	}
	
	language := ""
	if lang, ok := args["language"].(string); ok {
		language = sanitizeString(lang) // Sanitize language string (Phase E: Security Hardening)
	} else if filePath != "" {
		// Infer language from file extension
		ext := filepath.Ext(filePath)
		langMap := map[string]string{
			".js": "javascript", ".ts": "typescript", ".jsx": "javascript",
			".py": "python", ".go": "go", ".java": "java",
			".cs": "csharp", ".php": "php", ".rb": "ruby",
		}
		if lang, ok := langMap[ext]; ok {
			language = lang
		}
	}
	
	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 3. Build request
	hubURL := config.HubURL + "/api/v1/validate/code"
	requestBody := map[string]interface{}{
		"code":     code,
		"file_path": filePath,
		"language": language,
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	// 4. Send request
	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 5. Parse and format response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	validationText := "Code Validation Results:\n\n"
	if violations, ok := hubResponse["violations"].([]interface{}); ok && len(violations) > 0 {
		validationText += fmt.Sprintf("Found %d violations:\n\n", len(violations))
		for i, violation := range violations {
			if vMap, ok := violation.(map[string]interface{}); ok {
				rule := ""
				message := ""
				line := float64(0)
				if r, ok := vMap["rule"].(string); ok {
					rule = r
				}
				if m, ok := vMap["message"].(string); ok {
					message = m
				}
				if l, ok := vMap["line"].(float64); ok {
					line = l
				}
				validationText += fmt.Sprintf("%d. Line %.0f: %s - %s\n", i+1, line, rule, message)
			}
		}
	} else {
		validationText += "‚úÖ No violations found. Code is valid."
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": validationText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleValidateSecurity handles sentinel_validate_security tool call
func handleValidateSecurity(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}
	
	// Sanitize code input (Phase E: Security Hardening)
	code = sanitizeString(code)
	
	filePath := ""
	if fp, ok := args["filePath"].(string); ok {
		filePath = sanitizePath(fp) // Sanitize file path
		if filePath != "" && !isValidPath(filePath) {
			return MCPResponse{
				JSONRPC: "2.0",
				ID:      id,
				Error: &MCPError{
					Code:    InvalidParamsCode,
					Message: "Invalid params",
					Data:    fmt.Sprintf("Invalid file path: %s", filePath),
				},
			}
		}
	}
	
	language := ""
	if lang, ok := args["language"].(string); ok {
		language = sanitizeString(lang) // Sanitize language string
	} else if filePath != "" {
		ext := filepath.Ext(filePath)
		langMap := map[string]string{
			".js": "javascript", ".ts": "typescript", ".py": "python",
			".go": "go", ".java": "java", ".cs": "csharp",
		}
		if lang, ok := langMap[ext]; ok {
			language = lang
		}
	}
	
	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 3. Build request (use existing security analysis endpoint)
	hubURL := config.HubURL + "/api/v1/analyze/security"
	requestBody := map[string]interface{}{
		"code":     code,
		"filename": filePath,
		"language": language,
		"rules":    []string{}, // Empty means check all rules
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	// 4. Send request
	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 5. Parse and format response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	securityText := "Security Validation Results:\n\n"
	if score, ok := hubResponse["score"].(float64); ok {
		securityText += fmt.Sprintf("Security Score: %.1f/100\n", score)
	}
	if grade, ok := hubResponse["grade"].(string); ok {
		securityText += fmt.Sprintf("Security Grade: %s\n\n", grade)
	}
	
	if findings, ok := hubResponse["findings"].([]interface{}); ok && len(findings) > 0 {
		securityText += fmt.Sprintf("Found %d security issues:\n\n", len(findings))
		for i, finding := range findings {
			if fMap, ok := finding.(map[string]interface{}); ok {
				rule := ""
				severity := ""
				message := ""
				if r, ok := fMap["rule"].(string); ok {
					rule = r
				}
				if s, ok := fMap["severity"].(string); ok {
					severity = s
				}
				if m, ok := fMap["message"].(string); ok {
					message = m
				}
				securityText += fmt.Sprintf("%d. [%s] %s: %s\n", i+1, severity, rule, message)
			}
		}
	} else {
		securityText += "‚úÖ No security issues found."
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": securityText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleValidateBusiness handles sentinel_validate_business tool call
func handleValidateBusiness(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	feature, ok := args["feature"].(string)
	if !ok || feature == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "feature is required and must be a string",
			},
		}
	}
	
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}
	
	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 3. Build request
	hubURL := config.HubURL + "/api/v1/validate/business"
	requestBody := map[string]interface{}{
		"feature": feature,
		"code":    code,
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	// 4. Send request
	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 5. Parse and format response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	businessText := fmt.Sprintf("Business Rule Validation for: %s\n\n", feature)
	if violations, ok := hubResponse["violations"].([]interface{}); ok && len(violations) > 0 {
		businessText += fmt.Sprintf("Found %d business rule violations:\n\n", len(violations))
		for i, violation := range violations {
			if vMap, ok := violation.(map[string]interface{}); ok {
				rule := ""
				message := ""
				if r, ok := vMap["rule"].(string); ok {
					rule = r
				}
				if m, ok := vMap["message"].(string); ok {
					message = m
				}
				businessText += fmt.Sprintf("%d. %s: %s\n", i+1, rule, message)
			}
		}
	} else {
		businessText += "‚úÖ No business rule violations found."
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": businessText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleValidateTests handles sentinel_validate_tests tool call
func handleValidateTests(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	testFilePath, ok := args["testFilePath"].(string)
	if !ok || testFilePath == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "testFilePath is required and must be a string",
			},
		}
	}
	
	// Sanitize file path (Phase E: Security Hardening)
	testFilePath = sanitizePath(testFilePath)
	if !isValidPath(testFilePath) {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    fmt.Sprintf("Invalid test file path: %s", testFilePath),
			},
		}
	}
	
	// 2. Read test file
	testContent, err := os.ReadFile(testFilePath)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    fmt.Sprintf("Failed to read test file: %v", err),
			},
		}
	}
	
	// 3. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 4. Build request (use existing test validation endpoint)
	hubURL := config.HubURL + "/api/v1/test-validations/validate"
	requestBody := map[string]interface{}{
		"test_file_path": testFilePath,
		"test_content":   string(testContent),
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	// 5. Send request
	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 6. Parse and format response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	testText := fmt.Sprintf("Test Validation Results for: %s\n\n", testFilePath)
	if score, ok := hubResponse["quality_score"].(float64); ok {
		testText += fmt.Sprintf("Quality Score: %.1f/100\n\n", score)
	}
	if coverage, ok := hubResponse["coverage"].(float64); ok {
		testText += fmt.Sprintf("Coverage: %.1f%%\n\n", coverage)
	}
	if issues, ok := hubResponse["issues"].([]interface{}); ok && len(issues) > 0 {
		testText += fmt.Sprintf("Found %d issues:\n\n", len(issues))
		for i, issue := range issues {
			if iMap, ok := issue.(map[string]interface{}); ok {
				issueType := ""
				message := ""
				if t, ok := iMap["type"].(string); ok {
					issueType = t
				}
				if m, ok := iMap["message"].(string); ok {
					message = m
				}
				testText += fmt.Sprintf("%d. [%s] %s\n", i+1, issueType, message)
			}
		}
	} else {
		testText += "‚úÖ No issues found. Tests are valid."
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": testText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleApplyFix handles sentinel_apply_fix tool call
func handleApplyFix(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	filePath, ok := args["filePath"].(string)
	if !ok || filePath == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "filePath is required and must be a string",
			},
		}
	}
	
	// Sanitize file path (Phase E: Security Hardening)
	filePath = sanitizePath(filePath)
	if !isValidPath(filePath) {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    fmt.Sprintf("Invalid file path: %s", filePath),
			},
		}
	}
	
	fixType, ok := args["fixType"].(string)
	if !ok || fixType == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "fixType is required and must be a string",
			},
		}
	}
	
	// Sanitize fix type (Phase E: Security Hardening)
	fixType = sanitizeString(fixType)
	
	// 2. Read file content
	fileContent, err := os.ReadFile(filePath)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    fmt.Sprintf("Failed to read file: %v", err),
			},
		}
	}
	
	// 3. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 4. Build request
	hubURL := config.HubURL + "/api/v1/fixes/apply"
	requestBody := map[string]interface{}{
		"file_path": filePath,
		"fix_type":  fixType,
		"content":   string(fileContent),
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	// 5. Send request
	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 6. Parse and format response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	fixText := fmt.Sprintf("Fix Applied to: %s\n\n", filePath)
	if fixedCode, ok := hubResponse["fixed_code"].(string); ok {
		fixText += "Fixed Code:\n" + fixedCode + "\n\n"
	}
	if changes, ok := hubResponse["changes"].([]interface{}); ok && len(changes) > 0 {
		fixText += fmt.Sprintf("Applied %d changes:\n", len(changes))
		for i, change := range changes {
			if cMap, ok := change.(map[string]interface{}); ok {
				changeType := ""
				description := ""
				if ct, ok := cMap["type"].(string); ok {
					changeType = ct
				}
				if d, ok := cMap["description"].(string); ok {
					description = d
				}
				fixText += fmt.Sprintf("%d. [%s] %s\n", i+1, changeType, description)
			}
		}
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": fixText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleGenerateTests handles sentinel_generate_tests tool call
func handleGenerateTests(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	feature, ok := args["feature"].(string)
	if !ok || feature == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "feature is required and must be a string",
			},
		}
	}
	
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}
	
	// Sanitize inputs (Phase E: Security Hardening)
	feature = sanitizeString(feature)
	code = sanitizeString(code)
	
	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 3. Build request (use existing test requirements generation endpoint)
	hubURL := config.HubURL + "/api/v1/test-requirements/generate"
	requestBody := map[string]interface{}{
		"feature": feature,
		"code":    code,
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	// 4. Send request
	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 5. Parse and format response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	testText := fmt.Sprintf("Generated Tests for: %s\n\n", feature)
	if testCode, ok := hubResponse["test_code"].(string); ok {
		testText += "Test Code:\n" + testCode
	} else if requirements, ok := hubResponse["requirements"].([]interface{}); ok && len(requirements) > 0 {
		testText += fmt.Sprintf("Generated %d test requirements:\n\n", len(requirements))
		for i, req := range requirements {
			if rMap, ok := req.(map[string]interface{}); ok {
				title := ""
				if t, ok := rMap["title"].(string); ok {
					title = t
				}
				testText += fmt.Sprintf("%d. %s\n", i+1, title)
			}
		}
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": testText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleRunTests handles sentinel_run_tests tool call
func handleRunTests(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	testFilePath, ok := args["testFilePath"].(string)
	if !ok || testFilePath == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "testFilePath is required and must be a string",
			},
		}
	}
	
	language := ""
	if lang, ok := args["language"].(string); ok {
		language = lang
	} else {
		// Infer from file extension
		ext := filepath.Ext(testFilePath)
		langMap := map[string]string{
			".js": "javascript", ".ts": "typescript", ".py": "python",
			".go": "go", ".java": "java", ".cs": "csharp",
		}
		if lang, ok := langMap[ext]; ok {
			language = lang
		}
	}
	
	// 2. Read test file
	testContent, err := os.ReadFile(testFilePath)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    fmt.Sprintf("Failed to read test file: %v", err),
			},
		}
	}
	
	// 3. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}
	
	// 4. Build request (use existing test execution endpoint)
	hubURL := config.HubURL + "/api/v1/test-execution/run"
	requestBody := map[string]interface{}{
		"test_file_path": testFilePath,
		"test_content":   string(testContent),
		"language":       language,
	}
	
	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}
	
	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}
	
	// 5. Send request
	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}
	
	// 6. Parse and format response
	var hubResponse map[string]interface{}
	if err := json.Unmarshal(respBody, &hubResponse); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}
	
	testText := fmt.Sprintf("Test Execution Results for: %s\n\n", testFilePath)
	if status, ok := hubResponse["status"].(string); ok {
		testText += fmt.Sprintf("Status: %s\n\n", status)
	}
	if passed, ok := hubResponse["passed"].(float64); ok {
		if failed, ok := hubResponse["failed"].(float64); ok {
			testText += fmt.Sprintf("Passed: %.0f, Failed: %.0f\n\n", passed, failed)
		}
	}
	if coverage, ok := hubResponse["coverage"].(float64); ok {
		testText += fmt.Sprintf("Coverage: %.1f%%\n\n", coverage)
	}
	if output, ok := hubResponse["output"].(string); ok {
		testText += "Output:\n" + output
	}
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": testText,
				},
			},
			"data": hubResponse,
		},
	}
}

// handleGetTaskStatus handles sentinel_get_task_status tool call (Phase 14E)
func handleGetTaskStatus(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	taskID, ok := args["taskId"].(string)
	if !ok || taskID == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "taskId is required and must be a string",
			},
		}
	}

	// Sanitize input
	taskID = sanitizeString(taskID)

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Get task status from Hub
	hubURL := config.HubURL + "/api/v1/tasks/" + taskID
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "GET", headers, nil)
	if err != nil || statusCode != http.StatusOK {
		LogError("Failed to get task status", map[string]interface{}{
			"task_id":     taskID,
			"status_code": statusCode,
			"error":       err,
		})
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 4. Parse response
	var task map[string]interface{}
	if err := json.Unmarshal(respBody, &task); err != nil {
		LogError("Failed to parse task response", map[string]interface{}{
			"task_id": taskID,
			"error":   err,
		})
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}

	// 5. Get codebase path (optional)
	codebasePath := "."
	if cp, ok := args["codebasePath"].(string); ok && cp != "" {
		codebasePath = sanitizePath(cp)
		if !isValidPath(codebasePath) {
			return MCPResponse{
				JSONRPC: "2.0",
				ID:      id,
				Error: &MCPError{
					Code:    InvalidParamsCode,
					Message: "Invalid params",
					Data:    fmt.Sprintf("Invalid codebase path: %s", codebasePath),
				},
			}
		}
	} else {
		if wd, err := os.Getwd(); err == nil {
			codebasePath = wd
		}
	}

	// 6. Get dependencies (with timeout)
	depsURL := config.HubURL + "/api/v1/tasks/" + taskID + "/dependencies"
	if codebasePath != "." {
		depsURL += "?codebasePath=" + urlpkg.QueryEscape(codebasePath)
	}
	depsBody, depsStatus, depsErr := sendHTTPRequestWithTimeout(depsURL, "GET", headers, nil, 3, TaskGetTimeout)
	
	var dependencies map[string]interface{}
	if depsErr == nil && depsStatus == http.StatusOK {
		json.Unmarshal(depsBody, &dependencies)
	}

	// 7. Format response (using safe type assertions)
	status := getString(task, "status", "unknown")
	confidence := getFloat(task, "verification_confidence", 0.0)
	title := getString(task, "title", "")
	priority := getString(task, "priority", "medium")
	filePath := getString(task, "file_path", "")
	lineNumber := getInt(task, "line_number", 0)
	description := getString(task, "description", "")

	statusText := fmt.Sprintf("üìã Task: %s\n\n", title)
	statusText += fmt.Sprintf("üÜî ID: %s\n", taskID)
	statusText += fmt.Sprintf("üìä Status: %s\n", status)
	statusText += fmt.Sprintf("‚≠ê Priority: %s\n", priority)
	statusText += fmt.Sprintf("‚úÖ Verification Confidence: %.0f%%\n", confidence*100)
	
	if filePath != "" {
		statusText += fmt.Sprintf("üìÅ File: %s", filePath)
		if lineNumber > 0 {
			statusText += fmt.Sprintf(":%d", lineNumber)
		}
		statusText += "\n"
	}
	
	if description != "" {
		statusText += fmt.Sprintf("\nüìù Description: %s\n", description)
	}
	
	if dependencies != nil {
		blockedBy, ok := dependencies["blocked_by"].([]interface{})
		if !ok {
			blockedBy = []interface{}{}
		}
		blocks, ok := dependencies["blocks"].([]interface{})
		if !ok {
			blocks = []interface{}{}
		}
		if len(blockedBy) > 0 {
			statusText += fmt.Sprintf("\nüö´ Blocked by: %v\n", blockedBy)
		}
		if len(blocks) > 0 {
			statusText += fmt.Sprintf("üîó Blocks: %v\n", blocks)
		}
	}

	result := map[string]interface{}{
		"content": []map[string]interface{}{
			{
				"type": "text",
				"text": statusText,
			},
		},
		"data": map[string]interface{}{
			"task":        task,
			"dependencies": dependencies,
		},
	}
	
	// Cache the result
	cacheKey := fmt.Sprintf("task_status:%s", taskID)
	setCachedMCPResult(cacheKey, result, 30*time.Second)
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleVerifyTask handles sentinel_verify_task tool call (Phase 14E)
func handleVerifyTask(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	taskID, ok := args["taskId"].(string)
	if !ok || taskID == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "taskId is required and must be a string",
			},
		}
	}

	force := false
	if f, ok := args["force"].(bool); ok {
		force = f
	}

	// Sanitize input
	taskID = sanitizeString(taskID)

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Get codebase path
	codebasePath := "."
	if cp, ok := args["codebasePath"].(string); ok && cp != "" {
		codebasePath = sanitizePath(cp)
		if !isValidPath(codebasePath) {
			return MCPResponse{
				JSONRPC: "2.0",
				ID:      id,
				Error: &MCPError{
					Code:    InvalidParamsCode,
					Message: "Invalid params",
					Data:    fmt.Sprintf("Invalid codebase path: %s", codebasePath),
				},
			}
		}
	} else {
		if wd, err := os.Getwd(); err == nil {
			codebasePath = wd
		}
	}

	// 4. Verify task
	hubURL := config.HubURL + "/api/v1/tasks/" + taskID + "/verify?codebasePath=" + urlpkg.QueryEscape(codebasePath)
	requestBody := map[string]interface{}{
		"force": force,
	}

	jsonBody, err := json.Marshal(requestBody)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Content-Type":  "application/json",
		"Authorization": "Bearer " + config.APIKey,
	}

	respBody, statusCode, err := sendHTTPRequestWithTimeout(hubURL, "POST", headers, jsonBody, 3, TaskVerifyTimeout)
	if err != nil || statusCode != http.StatusOK {
		LogError("Failed to verify task", map[string]interface{}{
			"task_id":     taskID,
			"status_code": statusCode,
			"error":       err,
		})
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 5. Parse response
	var verification map[string]interface{}
	if err := json.Unmarshal(respBody, &verification); err != nil {
		LogError("Failed to parse verification response", map[string]interface{}{
			"task_id": taskID,
			"error":   err,
		})
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}

	// 6. Format response (using safe type assertions)
	confidence := getFloat(verification, "overall_confidence", 0.0)
	status := getString(verification, "status", "unknown")

	verifyText := fmt.Sprintf("üîç Task Verification Results\n\n")
	verifyText += fmt.Sprintf("üÜî Task ID: %s\n", taskID)
	verifyText += fmt.Sprintf("‚úÖ Overall Confidence: %.0f%%\n", confidence*100)
	verifyText += fmt.Sprintf("üìä Status: %s\n\n", status)

	if verifications, ok := verification["verifications"].([]interface{}); ok {
		verifyText += "üìã Verification Factors:\n"
		for _, v := range verifications {
			if vMap, ok := v.(map[string]interface{}); ok {
				vType := getString(vMap, "verification_type", "unknown")
				vStatus := getString(vMap, "status", "unknown")
				vConf := getFloat(vMap, "confidence", 0.0)
				icon := "‚úÖ"
				if vStatus == "failed" {
					icon = "‚ùå"
				} else if vStatus == "pending" {
					icon = "‚è≥"
				}
				verifyText += fmt.Sprintf("  %s %s: %s (%.0f%%)\n", icon, vType, vStatus, vConf*100)
			}
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result: map[string]interface{}{
			"content": []map[string]interface{}{
				{
					"type": "text",
					"text": verifyText,
				},
			},
			"data": verification,
		},
	}
}

// handleListTasks handles sentinel_list_tasks tool call (Phase 14E)
func handleListTasks(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 2. Build query parameters
	statusFilter := ""
	if s, ok := args["status"].(string); ok && s != "" {
		statusFilter = sanitizeString(s)
	}

	priorityFilter := ""
	if p, ok := args["priority"].(string); ok && p != "" {
		priorityFilter = sanitizeString(p)
	}

	limit := 50
	if l, ok := args["limit"].(float64); ok {
		limit = int(l)
		if limit > 100 {
			limit = 100
		}
	}

	offset := 0
	if o, ok := args["offset"].(float64); ok {
		offset = int(o)
		if offset < 0 {
			offset = 0
		}
	}

	// 3. Build query parameters for additional filters
	sourceFilter := ""
	if source, ok := args["source"].(string); ok && source != "" {
		sourceFilter = sanitizeString(source)
		validSources := map[string]bool{
			"cursor": true, "manual": true, "change_request": true, "comprehensive_analysis": true,
		}
		if !validSources[sourceFilter] {
			return MCPResponse{
				JSONRPC: "2.0",
				ID:      id,
				Error: &MCPError{
					Code:    InvalidParamsCode,
					Message: "Invalid params",
					Data:    fmt.Sprintf("Invalid source: %s. Must be one of: cursor, manual, change_request, comprehensive_analysis", sourceFilter),
				},
			}
		}
	}

	assignedToFilter := ""
	if assignedTo, ok := args["assigned_to"].(string); ok && assignedTo != "" {
		assignedToFilter = sanitizeString(assignedTo)
	}

	tagsFilter := []string{}
	if tags, ok := args["tags"].([]interface{}); ok && len(tags) > 0 {
		for _, tag := range tags {
			if tagStr, ok := tag.(string); ok && tagStr != "" {
				tagsFilter = append(tagsFilter, sanitizeString(tagStr))
			}
		}
	}

	includeArchived := false
	if ia, ok := args["include_archived"].(bool); ok {
		includeArchived = ia
	}

	// 4. Build URL with all query parameters
	hubURL := config.HubURL + "/api/v1/tasks"
	params := []string{}
	if statusFilter != "" {
		params = append(params, "status="+urlpkg.QueryEscape(statusFilter))
	}
	if priorityFilter != "" {
		params = append(params, "priority="+urlpkg.QueryEscape(priorityFilter))
	}
	if sourceFilter != "" {
		params = append(params, "source="+urlpkg.QueryEscape(sourceFilter))
	}
	if assignedToFilter != "" {
		params = append(params, "assigned_to="+urlpkg.QueryEscape(assignedToFilter))
	}
	if len(tagsFilter) > 0 {
		params = append(params, "tags="+urlpkg.QueryEscape(strings.Join(tagsFilter, ",")))
	}
	if includeArchived {
		params = append(params, "include_archived=true")
	}
	if limit != 50 {
		params = append(params, fmt.Sprintf("limit=%d", limit))
	}
	if offset > 0 {
		params = append(params, fmt.Sprintf("offset=%d", offset))
	}
	if len(params) > 0 {
		hubURL += "?" + strings.Join(params, "&")
	}

	// 5. Send request
	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
	}

	respBody, statusCode, err := sendHTTPRequestWithTimeout(hubURL, "GET", headers, nil, 3, TaskListTimeout)
	if err != nil || statusCode != http.StatusOK {
		LogError("Failed to list tasks", map[string]interface{}{
			"status_code": statusCode,
			"error":       err,
		})
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 6. Parse response
	var response map[string]interface{}
	if err := json.Unmarshal(respBody, &response); err != nil {
		LogError("Failed to parse tasks response", map[string]interface{}{
			"error": err,
		})
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to parse Hub response: %v", err),
			},
		}
	}

	// 7. Format response (using safe type assertions)
	var tasks []interface{}
	if t, ok := response["tasks"].([]interface{}); ok {
		tasks = t
	}
	total := getFloat(response, "total", 0.0)

	tasksText := fmt.Sprintf("üìã Tasks (%d total)\n\n", int(total))
	
	if len(tasks) == 0 {
		tasksText += "No tasks found.\n"
	} else {
		for i, taskInterface := range tasks {
			if task, ok := taskInterface.(map[string]interface{}); ok {
				taskID := getString(task, "id", "")
				title := getString(task, "title", "")
				status := getString(task, "status", "unknown")
				priority := getString(task, "priority", "medium")
				confidence := getFloat(task, "verification_confidence", 0.0)
				
				statusIcon := getStatusIcon(status)
				priorityIcon := getPriorityIcon(priority)
				
				tasksText += fmt.Sprintf("%d. %s %s [%s] %s\n", 
					i+1, statusIcon, priorityIcon, status, title)
				tasksText += fmt.Sprintf("   üÜî %s | ‚úÖ %.0f%% confidence\n\n", taskID, confidence*100)
			}
		}
	}

	result := map[string]interface{}{
		"content": []map[string]interface{}{
			{
				"type": "text",
				"text": tasksText,
			},
		},
		"data": response,
	}
	
	// Cache the result
	cacheKey := fmt.Sprintf("list_tasks:%s_%d_%d", statusFilter, limit, offset)
	setCachedMCPResult(cacheKey, result, 10*time.Second)
	
	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleHubError categorizes and formats Hub API errors
// handleHubError creates structured MCP error responses for Hub communication failures
func handleHubError(err error, statusCode int, id interface{}, hubURL string) MCPResponse {
	var errorCode int
	var errorMessage string
	var errorData map[string]interface{}

	// Initialize error data structure
	errorData = map[string]interface{}{
		"hub_url":       hubURL,
		"http_status":   statusCode,
		"timestamp":     time.Now().Format(time.RFC3339),
		"error_category": "hub_communication",
	}

	if err != nil {
		errStr := strings.ToLower(err.Error())
		errorData["original_error"] = err.Error()

		// Categorize network and timeout errors
		if strings.Contains(errStr, "timeout") || strings.Contains(errStr, "deadline exceeded") {
			errorCode = HubTimeoutCode
			errorMessage = "Hub request timeout"
			errorData["fallback"] = "Analysis timed out. Try with 'depth: surface' for faster results."
			errorData["retry_after_seconds"] = 30
		} else if strings.Contains(errStr, "connection refused") || strings.Contains(errStr, "no such host") ||
		          strings.Contains(errStr, "network unreachable") {
			errorCode = HubUnavailableCode
			errorMessage = "Hub service unreachable"
			errorData["fallback"] = "Hub is not reachable. Check SENTINEL_HUB_URL and network connectivity."
			errorData["suggestion"] = "Use Cursor's default analysis or verify Hub configuration."
			errorData["troubleshooting"] = []string{
				"Check if Hub service is running",
				"Verify SENTINEL_HUB_URL configuration",
				"Check network connectivity to Hub",
				"Review Hub API key configuration",
			}
		} else if strings.Contains(errStr, "tls") || strings.Contains(errStr, "certificate") {
			errorCode = AuthenticationErrorCode
			errorMessage = "Hub TLS/SSL error"
			errorData["fallback"] = "TLS certificate validation failed. Check Hub SSL configuration."
			errorData["suggestion"] = "Verify Hub SSL certificate or use HTTP for local development."
		} else if strings.Contains(errStr, "dial tcp") || strings.Contains(errStr, "connection reset") {
			errorCode = ServiceUnavailableCode
			errorMessage = "Hub connection failed"
			errorData["fallback"] = "Network connection to Hub failed. Service may be temporarily unavailable."
			errorData["retry_after_seconds"] = 60
		} else {
			errorCode = InternalErrorCode
			errorMessage = "Hub communication error"
			errorData["fallback"] = "Unexpected error communicating with Hub. Check Hub service status."
		}
	} else {
		// Handle HTTP status code errors
		errorData["http_status_category"] = getHTTPStatusCategory(statusCode)

		if statusCode == 401 || statusCode == 403 {
			errorCode = AuthenticationErrorCode
			errorMessage = "Hub authentication failed"
			errorData["fallback"] = "Invalid API key or insufficient permissions."
			errorData["suggestion"] = "Verify SENTINEL_API_KEY configuration."
		} else if statusCode == 429 {
			errorCode = RateLimitExceededCode
			errorMessage = "Hub rate limit exceeded"
			errorData["fallback"] = "Too many requests. Please wait before retrying."
			errorData["retry_after_seconds"] = 60
		} else if statusCode >= 400 && statusCode < 500 {
			errorCode = InvalidParamsCode
			errorMessage = "Invalid request to Hub"
			errorData["fallback"] = "Request parameters rejected by Hub. Check input validation."
			errorData["suggestion"] = "Review request parameters and Hub API documentation."
		} else if statusCode >= 500 {
			errorCode = HubUnavailableCode
			errorMessage = "Hub server error"
			errorData["fallback"] = "Hub service encountered an internal error."
			errorData["suggestion"] = "Contact Hub administrator or try again later."
			errorData["retry_after_seconds"] = 120
		} else if statusCode == 0 {
			// No status code (network error)
			errorCode = HubUnavailableCode
			errorMessage = "Hub unreachable"
			errorData["fallback"] = "Cannot reach Hub service. Check network connectivity."
		} else {
			errorCode = InternalErrorCode
			errorMessage = "Unexpected Hub response"
			errorData["fallback"] = fmt.Sprintf("Unexpected HTTP status: %d", statusCode)
		}
	}

	// Add retry information for retryable errors
	if isRetryableError(errorCode) {
		errorData["is_retryable"] = true
		if retryAfter, exists := errorData["retry_after_seconds"]; exists {
			errorData["retry_after"] = fmt.Sprintf("%ds", retryAfter)
		}
	} else {
		errorData["is_retryable"] = false
	}

	// Structured logging for debugging
	LogError("MCP Hub Error", map[string]interface{}{
		"error_code":     errorCode,
		"error_message":  errorMessage,
		"http_status":    statusCode,
		"hub_url":        hubURL,
		"error_category": errorData["error_category"],
		"is_retryable":   errorData["is_retryable"],
	})

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Error:   createMCPError(errorCode, errorMessage, errorData),
	}
}

// getHTTPStatusCategory categorizes HTTP status codes
func getHTTPStatusCategory(statusCode int) string {
	if statusCode >= 100 && statusCode < 200 {
		return "informational"
	} else if statusCode >= 200 && statusCode < 300 {
		return "success"
	} else if statusCode >= 300 && statusCode < 400 {
		return "redirection"
	} else if statusCode >= 400 && statusCode < 500 {
		return "client_error"
	} else if statusCode >= 500 {
		return "server_error"
	}
	return "unknown"
}

// sendMCPError is a helper to send MCP error responses
// sendMCPError sends a structured MCP error response with enhanced error information
func sendMCPError(encoder *json.Encoder, id interface{}, code int, message string, data interface{}) {
	// Enhance error with additional context
	enhancedData := data
	if dataMap, ok := data.(map[string]interface{}); ok {
		// Add error timestamp and server context
		if dataMap["timestamp"] == nil {
			dataMap["timestamp"] = time.Now().Format(time.RFC3339)
		}
		if dataMap["server_version"] == nil {
			dataMap["server_version"] = "2.0"
		}
		enhancedData = dataMap
	} else if data != nil {
		// Wrap non-map data in structured format
		enhancedData = map[string]interface{}{
			"details":     data,
			"timestamp":   time.Now().Format(time.RFC3339),
			"server_version": "2.0",
		}
	}

	resp := MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Error: &MCPError{
			Code:    code,
			Message: message,
			Data:    enhancedData,
		},
	}

	if err := encoder.Encode(resp); err != nil {
		// Fallback error logging if encoding fails
		LogError("Failed to encode MCP error response", map[string]interface{}{
			"original_error_code": code,
			"original_message":    message,
			"encoding_error":      err.Error(),
		})
	}
}

// createMCPError creates a structured MCP error with consistent formatting
func createMCPError(code int, message string, details interface{}) *MCPError {
	return &MCPError{
		Code:    code,
		Message: message,
		Data: map[string]interface{}{
			"details":       details,
			"timestamp":     time.Now().Format(time.RFC3339),
			"error_category": getErrorCategory(code),
			"retryable":     isRetryableError(code),
		},
	}
}

// getErrorCategory categorizes errors for better client handling
func getErrorCategory(code int) string {
	switch {
	case code >= -32768 && code <= -32000:
		return "protocol_error"
	case code >= -32000 && code <= -31000:
		return "server_error"
	case code == -32601:
		return "method_not_found"
	case code == -32602:
		return "invalid_params"
	case code == -32603:
		return "internal_error"
	default:
		return "application_error"
	}
}

// isRetryableError determines if an error is safe to retry
func isRetryableError(code int) bool {
	switch code {
	case HubUnavailableCode, HubTimeoutCode, ServerOverloadedCode,
		 RequestTimeoutCode, ServiceUnavailableCode, RateLimitExceededCode:
		return true
	default:
		return false
	}
}

// --- UTILS ---

func writeFile(path string, content string) {
	os.WriteFile(path, []byte(content), DefaultFilePerm)
}

func secureGitIgnore() {
	content := "\n# Sentinel Rules\n.cursor/rules/*.md\n!.cursor/rules/00-constitution.md\nsentinel\n"
	f, _ := os.OpenFile(".gitignore", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	f.WriteString(content)
	f.Close()
}

func createCI() {
	// Generates a CI file that runs Sentinel audit
	content := `name: Sentinel Gate
on: [push, pull_request]
jobs:
  audit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Go
        uses: actions/setup-go@v4
        with:
          go-version: '1.21'
      - name: Build Sentinel
        run: chmod +x synapsevibsentinel.sh && ./synapsevibsentinel.sh
      - name: Run Audit
        run: ./sentinel audit --ci
        continue-on-error: false
`
	writeFile(".github/workflows/sentinel.yml", content)
}

// handleAnalyzeComplexity handles sentinel_analyze_complexity tool call
func handleAnalyzeComplexity(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Extract thresholds
	thresholds := map[string]interface{}{
		"cyclomatic": 10.0,
		"cognitive":  15.0,
		"nesting":    4.0,
	}
	if t, ok := args["thresholds"].(map[string]interface{}); ok {
		if c, ok := t["cyclomatic"].(float64); ok {
			thresholds["cyclomatic"] = c
		}
		if cog, ok := t["cognitive"].(float64); ok {
			thresholds["cognitive"] = cog
		}
		if n, ok := t["nesting"].(float64); ok {
			thresholds["nesting"] = n
		}
	}

	// 4. Build request payload
	payload := map[string]interface{}{
		"code":       code,
		"language":   language,
		"thresholds": thresholds,
	}
	if filePath, ok := args["filePath"].(string); ok && filePath != "" {
		payload["filePath"] = filePath
	}

	// 5. Send to Hub
	hubURL := config.HubURL + "/api/v1/analyze/complexity"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 6. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleDetectDeadCode handles sentinel_detect_dead_code tool call
func handleDetectDeadCode(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	codebase, ok := args["codebase"].([]interface{})
	if !ok || len(codebase) == 0 {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "codebase is required and must be an array of file paths",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Convert codebase to string array
	filePaths := make([]string, len(codebase))
	for i, path := range codebase {
		if str, ok := path.(string); ok {
			filePaths[i] = str
		}
	}

	// 4. Build request payload
	payload := map[string]interface{}{
		"codebase":   filePaths,
		"language":   language,
	}
	if entryPoints, ok := args["entryPoints"].([]interface{}); ok && len(entryPoints) > 0 {
		entryPointStrings := make([]string, len(entryPoints))
		for i, ep := range entryPoints {
			if str, ok := ep.(string); ok {
				entryPointStrings[i] = str
			}
		}
		payload["entryPoints"] = entryPointStrings
	}

	// 5. Send to Hub
	hubURL := config.HubURL + "/api/v1/analyze/dead-code"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 6. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleAnalyzeDependencies handles sentinel_analyze_dependencies tool call
func handleAnalyzeDependencies(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	files, ok := args["files"].([]interface{})
	if !ok || len(files) == 0 {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "files is required and must be an array of file paths",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Convert files to string array
	filePaths := make([]string, len(files))
	for i, file := range files {
		if str, ok := file.(string); ok {
			filePaths[i] = str
		}
	}

	// 4. Build request payload
	payload := map[string]interface{}{
		"files":     filePaths,
		"language":  language,
	}
	if includeExternal, ok := args["includeExternal"].(bool); ok {
		payload["includeExternal"] = includeExternal
	}

	// 5. Send to Hub
	hubURL := config.HubURL + "/api/v1/analyze/dependencies"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 6. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleCheckTypeSafety handles sentinel_check_type_safety tool call
func handleCheckTypeSafety(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Build request payload
	payload := map[string]interface{}{
		"code":     code,
		"language": language,
	}
	if strict, ok := args["strict"].(bool); ok {
		payload["strict"] = strict
	}

	// 4. Send to Hub
	hubURL := config.HubURL + "/api/v1/analyze/type-safety"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 5. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleAnalyzePerformance handles sentinel_analyze_performance tool call
func handleAnalyzePerformance(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Build request payload
	payload := map[string]interface{}{
		"code":     code,
		"language": language,
	}
	if context, ok := args["context"].(map[string]interface{}); ok {
		payload["context"] = context
	}

	// 4. Send to Hub
	hubURL := config.HubURL + "/api/v1/analyze/performance"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 5. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleFormatCode handles sentinel_format_code tool call
func handleFormatCode(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Build request payload
	payload := map[string]interface{}{
		"code":     code,
		"language": language,
	}
	if options, ok := args["options"].(map[string]interface{}); ok {
		payload["options"] = options
	}

	// 4. Send to Hub
	hubURL := config.HubURL + "/api/v1/format/code"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 5. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleLintCode handles sentinel_lint_code tool call
func handleLintCode(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Build request payload
	payload := map[string]interface{}{
		"code":     code,
		"language": language,
	}
	if rules, ok := args["rules"].([]interface{}); ok && len(rules) > 0 {
		ruleStrings := make([]string, len(rules))
		for i, rule := range rules {
			if str, ok := rule.(string); ok {
				ruleStrings[i] = str
			}
		}
		payload["rules"] = ruleStrings
	}
	if strict, ok := args["strict"].(bool); ok {
		payload["strict"] = strict
	}

	// 4. Send to Hub
	hubURL := config.HubURL + "/api/v1/lint/code"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 5. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleRefactorCode handles sentinel_refactor_code tool call
func handleRefactorCode(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	refactoringType, ok := args["refactoringType"].(string)
	if !ok || refactoringType == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "refactoringType is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Build request payload
	payload := map[string]interface{}{
		"code":            code,
		"language":        language,
		"refactoringType": refactoringType,
	}
	if selection, ok := args["selection"].(map[string]interface{}); ok {
		payload["selection"] = selection
	}

	// 4. Send to Hub
	hubURL := config.HubURL + "/api/v1/refactor/code"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 5. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleGenerateDocs handles sentinel_generate_docs tool call
func handleGenerateDocs(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	code, ok := args["code"].(string)
	if !ok || code == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "code is required and must be a string",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Build request payload
	payload := map[string]interface{}{
		"code":     code,
		"language": language,
	}
	if format, ok := args["format"].(string); ok && format != "" {
		payload["format"] = format
	}
	if includeExamples, ok := args["includeExamples"].(bool); ok {
		payload["includeExamples"] = includeExamples
	}

	// 4. Send to Hub
	hubURL := config.HubURL + "/api/v1/generate/docs"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 5. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleAnalyzeCoverage handles sentinel_analyze_coverage tool call
func handleAnalyzeCoverage(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	codebase, ok := args["codebase"].([]interface{})
	if !ok || len(codebase) == 0 {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "codebase is required and must be an array of file paths",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Convert codebase to string array
	filePaths := make([]string, len(codebase))
	for i, path := range codebase {
		if str, ok := path.(string); ok {
			filePaths[i] = str
		}
	}

	// 4. Build request payload
	payload := map[string]interface{}{
		"codebase": filePaths,
		"language": language,
	}
	if testFiles, ok := args["testFiles"].([]interface{}); ok && len(testFiles) > 0 {
		testFileStrings := make([]string, len(testFiles))
		for i, tf := range testFiles {
			if str, ok := tf.(string); ok {
				testFileStrings[i] = str
			}
		}
		payload["testFiles"] = testFileStrings
	}
	if coverageData, ok := args["coverageData"].(map[string]interface{}); ok {
		payload["coverageData"] = coverageData
	}

	// 5. Send to Hub
	hubURL := config.HubURL + "/api/v1/analyze/coverage"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 6. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}

// handleAnalyzeCrossFile handles sentinel_analyze_cross_file tool call
func handleAnalyzeCrossFile(id interface{}, args map[string]interface{}) MCPResponse {
	// 1. Validate parameters
	files, ok := args["files"].([]interface{})
	if !ok || len(files) == 0 {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "files is required and must be an array of file paths",
			},
		}
	}

	language, ok := args["language"].(string)
	if !ok || language == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InvalidParamsCode,
				Message: "Invalid params",
				Data:    "language is required",
			},
		}
	}

	// 2. Load config
	config := loadConfig()
	if config.HubURL == "" || config.APIKey == "" {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ConfigErrorCode,
				Message: "Server error",
				Data:    "Hub not configured. Set SENTINEL_HUB_URL and SENTINEL_API_KEY",
			},
		}
	}

	// 3. Convert files to string array
	filePaths := make([]string, len(files))
	for i, file := range files {
		if str, ok := file.(string); ok {
			filePaths[i] = str
		}
	}

	// 4. Build request payload
	payload := map[string]interface{}{
		"files":   filePaths,
		"language": language,
	}
	if entryPoints, ok := args["entryPoints"].([]interface{}); ok && len(entryPoints) > 0 {
		entryPointStrings := make([]string, len(entryPoints))
		for i, ep := range entryPoints {
			if str, ok := ep.(string); ok {
				entryPointStrings[i] = str
			}
		}
		payload["entryPoints"] = entryPointStrings
	}
	if analysisDepth, ok := args["analysisDepth"].(string); ok && analysisDepth != "" {
		payload["analysisDepth"] = analysisDepth
	}
	if detectCircular, ok := args["detectCircular"].(bool); ok {
		payload["detectCircular"] = detectCircular
	}
	if findUnused, ok := args["findUnused"].(bool); ok {
		payload["findUnused"] = findUnused
	}

	// 5. Send to Hub
	hubURL := config.HubURL + "/api/v1/analyze/cross-file"
	jsonBody, err := json.Marshal(payload)
	if err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    InternalErrorCode,
				Message: "Internal error",
				Data:    fmt.Sprintf("Failed to prepare request: %v", err),
			},
		}
	}

	headers := map[string]string{
		"Authorization": "Bearer " + config.APIKey,
		"Content-Type":  "application/json",
	}

	respBody, statusCode, err := sendHTTPRequest(hubURL, "POST", headers, jsonBody)
	if err != nil || statusCode != http.StatusOK {
		return handleHubError(err, statusCode, id, config.HubURL)
	}

	// 6. Parse response
	var result map[string]interface{}
	if err := json.Unmarshal(respBody, &result); err != nil {
		return MCPResponse{
			JSONRPC: "2.0",
			ID:      id,
			Error: &MCPError{
				Code:    ParseErrorCode,
				Message: "Parse error",
				Data:    err.Error(),
			},
		}
	}

	return MCPResponse{
		JSONRPC: "2.0",
		ID:      id,
		Result:  result,
	}
}
